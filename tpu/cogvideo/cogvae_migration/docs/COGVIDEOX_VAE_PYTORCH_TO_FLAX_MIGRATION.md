# CogVideoX VAE PyTorch åˆ° Flax è¿ç§»è¯¦è§£

> **æ–‡æ¡£ç›®æ ‡**ï¼šè¯¦ç»†è®²è§£ CogVideoX VAE ä» PyTorch å®ç°åˆ° JAX/Flax å®ç°çš„å®Œæ•´è¿ç§»è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ¯ä¸ªå‡½æ•°çš„å¯¹ç…§è®²è§£ã€è®¾è®¡æ€è·¯å’Œå®ç°ç»†èŠ‚ã€‚

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

æœ¬æ–‡æ¡£æ˜¯ CogVideoX VAE è¿ç§»ç³»åˆ—æ–‡æ¡£ä¹‹ä¸€ï¼Œå»ºè®®é…åˆä»¥ä¸‹æ–‡æ¡£é˜…è¯»ï¼š

### ğŸ¯ è¿ç§»æŒ‡å—ç³»åˆ—
- **[PyTorch åˆ° JAX è¿ç§»åœ£ç»](./PYTORCH_TO_JAX_MIGRATION_BIBLE_ZH.md)** - å®Œæ•´çš„ PyTorch â†’ JAX è¿ç§»æŒ‡å—
- **[PyTorch åˆ° JAX èŒƒå¼è½¬æ¢](./PYTORCH_TO_JAX_PARADIGM_SHIFT_ZH.md)** - ç†è§£ä¸¤ä¸ªæ¡†æ¶çš„æ€ç»´æ–¹å¼å·®å¼‚
- **[PyTorch-JAX å®ç°å¯¹æ¯”](./PYTORCH_JAX_IMPLEMENTATION_COMPARISON.md)** - å¸¸è§æ¨¡å¼çš„å¯¹æ¯”å®ç°

### ğŸ”§ æŠ€æœ¯ä¸“é¢˜
- **[JAX å†…å­˜è°ƒè¯•æŒ‡å—](./JAX_MEMORY_DEBUGGING_GUIDE.md)** - TPU å†…å­˜é—®é¢˜çš„è¯Šæ–­å’Œè§£å†³
- **[JAX å¹¶è¡Œç¼–ç¨‹è¯¦è§£](./JAX_PARALLEL_PROGRAMMING_GUIDE.md)** - JAX çš„å¹¶è¡ŒåŒ–ç­–ç•¥å’Œæœ€ä½³å®è·µ

### ğŸ“– æ¡ˆä¾‹ç ”ç©¶
- **[CogVideoX VAE OOM ä¿®å¤æ¡ˆä¾‹](./CASE_STUDY_COGVIDEOX_VAE_OOM_FIX.md)** - é€å¸§è§£ç æ–¹æ¡ˆçš„è¯¦ç»†è®¾è®¡
- **[BF16 ä¼˜åŒ–å°è¯•è®°å½•](./BF16_OPTIMIZATION_ATTEMPTS.md)** - æ··åˆç²¾åº¦è®­ç»ƒçš„å®è·µç»éªŒ
- **[CogVideoX VAE Flax è¯´æ˜](./COGVIDEOX_VAE_FLAX_README.md)** - Flax å®ç°çš„å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

---

## ğŸ“‘ ç›®å½•

1. [æ•´ä½“æ¶æ„æ¦‚è¿°](#1-æ•´ä½“æ¶æ„æ¦‚è¿°)
2. [è°ƒç”¨æµç¨‹è¯¦è§£](#2-è°ƒç”¨æµç¨‹è¯¦è§£)
3. [åŸºç¡€ç»„ä»¶è¿ç§»](#3-åŸºç¡€ç»„ä»¶è¿ç§»)
4. [æ ¸å¿ƒæ¨¡å—è¿ç§»](#4-æ ¸å¿ƒæ¨¡å—è¿ç§»)
5. [ä¸» VAE ç±»è¿ç§»](#5-ä¸»-vae-ç±»è¿ç§»)
6. [é«˜çº§åŠŸèƒ½è¿ç§»](#6-é«˜çº§åŠŸèƒ½è¿ç§»)
7. [å…³é”®å·®å¼‚æ€»ç»“](#7-å…³é”®å·®å¼‚æ€»ç»“)

---

## 1. æ•´ä½“æ¶æ„æ¦‚è¿°

### 1.1 CogVideoX VAE ç®€ä»‹

CogVideoX VAE æ˜¯ä¸€ä¸ªä¸“ä¸ºè§†é¢‘æ•°æ®è®¾è®¡çš„å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVariational Autoencoderï¼‰ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š

- **3D å·ç§¯æ¶æ„**ï¼šå¤„ç†æ—¶ç©ºæ•°æ®ï¼ˆè§†é¢‘ï¼‰
- **å› æœå·ç§¯**ï¼šæ—¶é—´ç»´åº¦ä¸Šçš„å› æœæ€§ï¼ˆcausalï¼‰å¡«å……
- **ç©ºé—´å½’ä¸€åŒ–**ï¼šè§£ç å™¨ä½¿ç”¨ Spatial Normalization
- **åˆ†å—å¤„ç†**ï¼šæ”¯æŒ tiling å’Œ frame batching ä»¥èŠ‚çœå†…å­˜
- **æ—¶åºå‹ç¼©**ï¼šå°†è§†é¢‘å‹ç¼©åˆ°æ½œåœ¨ç©ºé—´ï¼Œé»˜è®¤æ—¶åºå‹ç¼©æ¯”ä¸º 4

### 1.2 æ–‡ä»¶å¯¹åº”å…³ç³»

```
PyTorch ç‰ˆæœ¬:  autoencoder_kl_cogvideox.py (1423 è¡Œ)
Flax ç‰ˆæœ¬:     autoencoder_kl_cogvideox_flax.py (2433 è¡Œ)
```

### 1.3 ä¸»è¦ç»„ä»¶å±‚æ¬¡ç»“æ„

```
FlaxAutoencoderKLCogVideoX (ä¸» VAE ç±»)
â”œâ”€â”€ FlaxCogVideoXEncoder3D (ç¼–ç å™¨)
â”‚   â”œâ”€â”€ FlaxCogVideoXCausalConv3d (è¾“å…¥å·ç§¯)
â”‚   â”œâ”€â”€ FlaxCogVideoXDownBlock3D Ã— 4 (ä¸‹é‡‡æ ·å—)
â”‚   â”‚   â”œâ”€â”€ FlaxCogVideoXResnetBlock3D Ã— 3 (ResNet å—)
â”‚   â”‚   â””â”€â”€ FlaxConv2d (ç©ºé—´ä¸‹é‡‡æ ·)
â”‚   â”œâ”€â”€ FlaxCogVideoXMidBlock3D (ä¸­é—´å—)
â”‚   â”‚   â””â”€â”€ FlaxCogVideoXResnetBlock3D Ã— 2
â”‚   â””â”€â”€ FlaxCogVideoXCausalConv3d (è¾“å‡ºå·ç§¯)
â”‚
â””â”€â”€ FlaxCogVideoXDecoder3D (è§£ç å™¨)
    â”œâ”€â”€ FlaxCogVideoXCausalConv3d (è¾“å…¥å·ç§¯)
    â”œâ”€â”€ FlaxCogVideoXMidBlock3D (ä¸­é—´å—)
    â”‚   â””â”€â”€ FlaxCogVideoXResnetBlock3D Ã— 2 (å¸¦ SpatialNorm)
    â”œâ”€â”€ FlaxCogVideoXUpBlock3D Ã— 4 (ä¸Šé‡‡æ ·å—)
    â”‚   â”œâ”€â”€ FlaxCogVideoXResnetBlock3D Ã— 4 (å¸¦ SpatialNorm)
    â”‚   â””â”€â”€ FlaxConv2d (ç©ºé—´ä¸Šé‡‡æ ·)
    â””â”€â”€ FlaxCogVideoXCausalConv3d (è¾“å‡ºå·ç§¯)
```

### 1.4 æ•°æ®æ ¼å¼çº¦å®š

| æ¡†æ¶ | æ•°æ®æ ¼å¼ | è¯´æ˜ |
|------|----------|------|
| PyTorch | `(B, C, T, H, W)` | æ‰¹æ¬¡ã€é€šé“ã€æ—¶é—´ã€é«˜åº¦ã€å®½åº¦ï¼ˆchannel-firstï¼‰|
| JAX/Flax | `(B, T, H, W, C)` | æ‰¹æ¬¡ã€æ—¶é—´ã€é«˜åº¦ã€å®½åº¦ã€é€šé“ï¼ˆchannel-lastï¼‰|

**å…³é”®ç‚¹**ï¼šæ‰€æœ‰ PyTorch çš„ channel-first æ•°æ®éƒ½éœ€è¦è½¬æ¢ä¸º JAX çš„ channel-last æ ¼å¼ã€‚

---

## 2. è°ƒç”¨æµç¨‹è¯¦è§£

### 2.1 ç¼–ç æµç¨‹ (Encode)

#### PyTorch ç‰ˆæœ¬è°ƒç”¨æ ˆ

```python
# å…¥å£ï¼šautoencoder_kl_cogvideox.py ç¬¬ 1154-1179 è¡Œ
AutoencoderKLCogVideoX.encode(x: Tensor) -> AutoencoderKLOutput
  â””â”€> _encode(x: Tensor) -> Tensor
       â”œâ”€> åˆ†å¸§å¤„ç†å¾ªç¯ (frame_batch_size = 8)
       â”‚    â””â”€> CogVideoXEncoder3D.forward(x_intermediate, conv_cache)
       â”‚         â”œâ”€> conv_in: CausalConv3d (3 -> 128 é€šé“)
       â”‚         â”œâ”€> down_blocks[0-3]: DownBlock3D
       â”‚         â”‚    â”œâ”€> resnets Ã— 3: ResnetBlock3D
       â”‚         â”‚    â””â”€> downsampler: Downsample3D (ç©ºé—´ 2x ä¸‹é‡‡æ ·)
       â”‚         â”œâ”€> mid_block: MidBlock3D
       â”‚         â”‚    â””â”€> resnets Ã— 2: ResnetBlock3D
       â”‚         â””â”€> conv_out: CausalConv3d (512 -> 32 é€šé“ï¼Œè¾“å‡º mean+logvar)
       â”‚
       â””â”€> quant_conv (å¯é€‰): Conv3d (32 -> 32)
  
  â””â”€> DiagonalGaussianDistribution(h)  # åˆ†ç¦» mean å’Œ logvar
```

**è¾“å…¥**ï¼šè§†é¢‘å¼ é‡ `x: (B, C, T, H, W)` ä¾‹å¦‚ `(1, 3, 49, 480, 720)`
**è¾“å‡º**ï¼šæ½œåœ¨åˆ†å¸ƒ `posterior: DiagonalGaussianDistribution`ï¼ŒåŒ…å« mean å’Œ logvar

#### Flax ç‰ˆæœ¬è°ƒç”¨æ ˆ

```python
# å…¥å£ï¼šautoencoder_kl_cogvideox_flax.py ç¬¬ 1936-1953 è¡Œ
FlaxAutoencoderKLCogVideoX.encode(x: Array) -> Tuple[Array, Array]
  â””â”€> _encode(x: Array) -> Array
       â”œâ”€> åˆ†å¸§å¤„ç†å¾ªç¯ (frame_batch_size = 8)
       â”‚    â””â”€> FlaxCogVideoXEncoder3D.__call__(x_intermediate, conv_cache)
       â”‚         â”œâ”€> conv_in: FlaxCogVideoXCausalConv3d (3 -> 128 é€šé“)
       â”‚         â”œâ”€> down_blocks[0-3]: FlaxCogVideoXDownBlock3D
       â”‚         â”‚    â”œâ”€> resnets Ã— 3: FlaxCogVideoXResnetBlock3D
       â”‚         â”‚    â””â”€> downsampler: FlaxConv2d (ç©ºé—´ 2x ä¸‹é‡‡æ ·)
       â”‚         â”œâ”€> mid_block: FlaxCogVideoXMidBlock3D
       â”‚         â”‚    â””â”€> resnets Ã— 2: FlaxCogVideoXResnetBlock3D
       â”‚         â””â”€> conv_out: FlaxCogVideoXCausalConv3d (512 -> 32 é€šé“)
       â”‚
       â””â”€> quant_conv (å¯é€‰): FlaxConv3d (32 -> 32)
  
  â””â”€> jnp.split(h, 2, axis=-1)  # åˆ†ç¦» mean å’Œ logvar
```

**è¾“å…¥**ï¼šè§†é¢‘å¼ é‡ `x: (B, T, H, W, C)` ä¾‹å¦‚ `(1, 49, 480, 720, 3)`
**è¾“å‡º**ï¼š`(mean, logvar)` å…ƒç»„ï¼Œshape å‡ä¸º `(B, T//4, H//8, W//8, 16)`

**å…³é”®å·®å¼‚**ï¼š
1. âœ… æ•°æ®æ ¼å¼ï¼šPyTorch `BCTHW` â†’ Flax `BTHWC`
2. âœ… è¾“å‡ºæ ¼å¼ï¼šPyTorch è¿”å› `DiagonalGaussianDistribution` å¯¹è±¡ â†’ Flax ç›´æ¥è¿”å› `(mean, logvar)` å…ƒç»„
3. âœ… Frame batchingï¼šä¸¤è€…éƒ½æ”¯æŒï¼Œé»˜è®¤ 8 å¸§ä¸€æ‰¹

### 2.2 è§£ç æµç¨‹ (Decode)

#### PyTorch ç‰ˆæœ¬è°ƒç”¨æ ˆ

```python
# å…¥å£ï¼šautoencoder_kl_cogvideox.py ç¬¬ 1210-1232 è¡Œ
AutoencoderKLCogVideoX.decode(z: Tensor) -> DecoderOutput
  â””â”€> _decode(z: Tensor) -> Union[DecoderOutput, Tensor]
       â”œâ”€> åˆ†å¸§å¤„ç†å¾ªç¯ (frame_batch_size = 2)
       â”‚    â”œâ”€> post_quant_conv (å¯é€‰): Conv3d
       â”‚    â””â”€> CogVideoXDecoder3D.forward(z_intermediate, conv_cache)
       â”‚         â”œâ”€> conv_in: CausalConv3d (16 -> 512 é€šé“)
       â”‚         â”œâ”€> mid_block: MidBlock3D (å¸¦ SpatialNorm)
       â”‚         â”‚    â””â”€> resnets Ã— 2: ResnetBlock3D (spatial_norm_dim=16)
       â”‚         â”œâ”€> up_blocks[0-3]: UpBlock3D
       â”‚         â”‚    â”œâ”€> resnets Ã— 4: ResnetBlock3D (å¸¦ SpatialNorm)
       â”‚         â”‚    â””â”€> upsampler: Upsample3D (ç©ºé—´/æ—¶åºä¸Šé‡‡æ ·)
       â”‚         â””â”€> conv_out: CausalConv3d (128 -> 3 é€šé“)
       â”‚
       â””â”€> torch.cat(dec, dim=2)  # æ‹¼æ¥æ—¶é—´ç»´åº¦
  
  â””â”€> DecoderOutput(sample=dec)
```

**è¾“å…¥**ï¼šæ½œåœ¨å¼ é‡ `z: (B, C, T, H, W)` ä¾‹å¦‚ `(1, 16, 13, 60, 90)`
**è¾“å‡º**ï¼šé‡å»ºè§†é¢‘ `(B, 3, 49, 480, 720)` (æ—¶åºä¸Šé‡‡æ · 4 å€)

#### Flax ç‰ˆæœ¬è°ƒç”¨æ ˆ

```python
# å…¥å£ï¼šautoencoder_kl_cogvideox_flax.py ç¬¬ 2070-2086 è¡Œ
FlaxAutoencoderKLCogVideoX.decode(z: Array, zq: Array) -> Array
  â””â”€> _decode(z: Array, zq: Array) -> Array
       â”œâ”€> FlaxCogVideoXCache(decoder) åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
       â”œâ”€> post_quant_conv (å¯é€‰): FlaxConv3d
       â”œâ”€> é€å¸§è§£ç å¾ªç¯ (æ¯æ¬¡ 1 å¸§)
       â”‚    â”œâ”€> é‡ç½®ç´¢å¼•ï¼šfeat_cache_manager._conv_idx = [0]
       â”‚    â”œâ”€> æå–å½“å‰å¸§ï¼šz_frame = z[:, i:i+1, ...]
       â”‚    â””â”€> FlaxCogVideoXDecoder3D.__call__(z_frame, zq_frame, feat_cache, feat_idx)
       â”‚         â”œâ”€> conv_in: FlaxCogVideoXCausalConv3d
       â”‚         â”œâ”€> mid_block: FlaxCogVideoXMidBlock3D (å¸¦ SpatialNorm)
       â”‚         â”œâ”€> up_blocks[0-3]: FlaxCogVideoXUpBlock3D
       â”‚         â”‚    â”œâ”€> resnets Ã— 4: FlaxCogVideoXResnetBlock3D
       â”‚         â”‚    â””â”€> upsampler: FlaxConv2d + jax.image.resize
       â”‚         â””â”€> conv_out: FlaxCogVideoXCausalConv3d
       â”‚
       â””â”€> jnp.concatenate(decoded_frames_list, axis=1)  # æ‹¼æ¥æ—¶é—´ç»´åº¦
```

**è¾“å…¥**ï¼šæ½œåœ¨å¼ é‡ `z: (B, T, H, W, C)` ä¾‹å¦‚ `(1, 13, 60, 90, 16)`
**è¾“å‡º**ï¼šé‡å»ºè§†é¢‘ `(B, 49, 480, 720, 3)` (æ—¶åºä¸Šé‡‡æ · 4 å€)

**å…³é”®å·®å¼‚**ï¼š
1. âœ… æ•°æ®æ ¼å¼ï¼šPyTorch `BCTHW` â†’ Flax `BTHWC`
2. âš ï¸ **æ‰¹å¤„ç†å¤§å°**ï¼šPyTorch æ¯æ‰¹ 2 å¸§ â†’ Flax æ¯æ‰¹ **1 å¸§**ï¼ˆé¿å… OOMï¼‰
3. âœ… **ç¼“å­˜æœºåˆ¶**ï¼š
   - PyTorch: ä½¿ç”¨ `conv_cache` å­—å…¸å­˜å‚¨æ¯å±‚çš„ç¼“å­˜
   - Flax: ä½¿ç”¨ `FlaxCogVideoXCache` ç±»ç®¡ç† `feat_cache` åˆ—è¡¨å’Œ `feat_idx` ç´¢å¼•
4. âœ… è¾“å‡ºæ ¼å¼ï¼šPyTorch è¿”å› `DecoderOutput` å¯¹è±¡ â†’ Flax ç›´æ¥è¿”å›æ•°ç»„

### 2.3 å®Œæ•´çš„å‰å‘ä¼ æ’­æµç¨‹

#### PyTorch ç‰ˆæœ¬

```python
# autoencoder_kl_cogvideox.py ç¬¬ 1407-1423 è¡Œ
def forward(sample, sample_posterior=False, generator=None):
    # 1. ç¼–ç 
    posterior = self.encode(sample).latent_dist
    
    # 2. é‡‡æ ·æˆ–å–æ¨¡å¼
    if sample_posterior:
        z = posterior.sample(generator=generator)
    else:
        z = posterior.mode()  # ç­‰äº mean
    
    # 3. è§£ç 
    dec = self.decode(z).sample
    
    return DecoderOutput(sample=dec)
```

#### Flax ç‰ˆæœ¬

```python
# autoencoder_kl_cogvideox_flax.py ç¬¬ 2232-2263 è¡Œ
def __call__(x, sample_posterior=False, rng=None):
    # 1. ç¼–ç 
    mean, logvar = self.encode(x, deterministic=True)
    
    # 2. é‡‡æ ·æˆ–å–æ¨¡å¼
    if sample_posterior:
        std = jnp.exp(0.5 * logvar)
        z = mean + std * jax.random.normal(rng, mean.shape)
    else:
        z = mean  # mode
    
    # 3. è§£ç  (z åŒæ—¶ä½œä¸ºæ½œåœ¨è¡¨ç¤ºå’Œç©ºé—´æ¡ä»¶)
    dec = self.decode(z, zq=z, deterministic=True)
    
    return dec
```

**å…³é”®ç‚¹**ï¼š
- PyTorch çš„ `DiagonalGaussianDistribution.mode()` ç­‰ä»·äº Flax ç›´æ¥ä½¿ç”¨ `mean`
- PyTorch çš„ `DiagonalGaussianDistribution.sample()` ç­‰ä»·äº Flax çš„é‡å‚æ•°åŒ–æŠ€å·§
- Flax è§£ç æ—¶éœ€è¦åŒæ—¶ä¼ å…¥ `z` å’Œ `zq`ï¼ˆç©ºé—´æ¡ä»¶ï¼‰ï¼ŒPyTorch åœ¨å†…éƒ¨å¤„ç†

#### ğŸ” ä»€ä¹ˆæ˜¯ `zq` (Spatial Conditioning)ï¼Ÿ

`zq` æ˜¯ **Spatial Conditioning**ï¼ˆç©ºé—´æ¡ä»¶ï¼‰çš„ç¼©å†™ï¼Œåœ¨ CogVideoX VAE è§£ç å™¨ä¸­æ‰®æ¼”é‡è¦è§’è‰²ï¼š

**1. åŸºæœ¬æ¦‚å¿µ**
- `zq` ä»£è¡¨æ½œåœ¨è¡¨ç¤º (latent representation)ï¼Œç”¨äº **Spatially Adaptive Normalization**
- åœ¨ CogVideoX ä¸­ï¼Œ`zq` å®é™…ä¸Šå°±æ˜¯ `z` æœ¬èº«ï¼ˆå³ç¼–ç å¾—åˆ°çš„æ½œåœ¨å‘é‡ï¼‰
- å®ƒé€šè¿‡ SpatialNorm3D å±‚ä¸ºè§£ç å™¨æä¾›ç©ºé—´è‡ªé€‚åº”çš„å½’ä¸€åŒ–

**2. å·¥ä½œåŸç†**ï¼ˆå‚è€ƒ [SpatialNorm3D](#41-spatialnorm3d-ç©ºé—´å½’ä¸€åŒ–)ï¼‰
```python
# åœ¨ SpatialNorm3D ä¸­çš„ä½¿ç”¨
def forward(f, zq):
    # 1. å°† zq ä¸Šé‡‡æ ·åˆ°ç‰¹å¾å›¾ f çš„ç©ºé—´å°ºå¯¸
    zq_upsampled = resize(zq, size=f.shape)
    
    # 2. é€šè¿‡ä¸¤ä¸ª 1x1x1 å·ç§¯ç”Ÿæˆå½’ä¸€åŒ–å‚æ•°
    gamma = conv_y(zq_upsampled)  # ç¼©æ”¾å› å­
    beta = conv_b(zq_upsampled)   # åç§»
    
    # 3. åº”ç”¨ç©ºé—´è‡ªé€‚åº”å½’ä¸€åŒ–
    normalized_f = GroupNorm(f)
    output = normalized_f * gamma + beta  # æ¯ä¸ªç©ºé—´ä½ç½®æœ‰ä¸åŒçš„ gamma å’Œ beta
```

**3. ä¸ºä»€ä¹ˆéœ€è¦ `zq`ï¼Ÿ**
- **ä¼ ç»Ÿ GroupNorm**ï¼šæ‰€æœ‰ç©ºé—´ä½ç½®å…±äº«ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°ï¼ˆgamma å’Œ betaï¼‰
- **SpatialNorm3D**ï¼šæ¯ä¸ªç©ºé—´ä½ç½®æœ‰ä¸åŒçš„å‚æ•°ï¼Œè¿™äº›å‚æ•°ç”± `zq` ç”Ÿæˆ
- **ä¼˜åŠ¿**ï¼šè§£ç å™¨å¯ä»¥æ ¹æ®æ½œåœ¨è¡¨ç¤ºçš„å†…å®¹ï¼Œä¸ºä¸åŒåŒºåŸŸç”Ÿæˆä¸åŒçš„å½’ä¸€åŒ–ç­–ç•¥

**4. PyTorch vs Flax çš„å·®å¼‚**

| æ–¹é¢ | PyTorch | Flax |
|------|---------|------|
| å‚æ•°ä¼ é€’ | `decode(z)` - å†…éƒ¨è‡ªåŠ¨ä½¿ç”¨ `z` ä½œä¸º `zq` | `decode(z, zq=z)` - æ˜¾å¼ä¼ å…¥ |
| å®ç°ä½ç½® | `decoder.forward(sample, ...)` å†…éƒ¨å¤„ç† | è°ƒç”¨è€…éœ€è¦æ˜¾å¼ä¼ å…¥ |
| åŸå›  | API è®¾è®¡éšè—å®ç°ç»†èŠ‚ | Flax æ›´å€¾å‘äºæ˜¾å¼å‚æ•°ä¼ é€’ |

**5. å®é™…ä»£ç ç¤ºä¾‹**

PyTorch:
```python
# autoencoder_kl_cogvideox.py
def decode(self, z):
    return self._decode(z)

def _decode(self, z):
    # å†…éƒ¨è‡ªåŠ¨ä½¿ç”¨ z ä½œä¸º spatial conditioning
    z_intermediate, conv_cache = self.decoder(z_intermediate, conv_cache=conv_cache)
    # decoder å†…éƒ¨ä¼šå°† z_intermediate ä½œä¸º zq ä½¿ç”¨
```

Flax:
```python
# autoencoder_kl_cogvideox_flax.py
def decode(self, z, zq=None):
    if zq is None:
        zq = z  # é»˜è®¤ä½¿ç”¨ z ä½œä¸º zq
    return self._decode(z, zq)

def _decode(self, z, zq):
    # æ˜¾å¼ä¼ é€’ z å’Œ zq ç»™ decoder
    decoded_frame, _ = self.decoder(z_frame, zq_frame, ...)
```

**6. ä½¿ç”¨åœºæ™¯**
```python
# æ ‡å‡†ç”¨æ³•ï¼šzq = zï¼ˆæœ€å¸¸è§ï¼‰
decoded = vae.decode(z, zq=z)

# ç†è®ºä¸Šå¯ä»¥ç”¨ä¸åŒçš„æ¡ä»¶ï¼ˆå®éªŒæ€§ï¼‰
# decoded = vae.decode(z, zq=other_conditioning)
# ä½†åœ¨ CogVideoX ä¸­ï¼Œå§‹ç»ˆä½¿ç”¨ z æœ¬èº«ä½œä¸ºæ¡ä»¶
```

**æ€»ç»“**ï¼š`zq` æ˜¯è§£ç å™¨ä¸­ SpatialNorm3D å±‚çš„ç©ºé—´æ¡ä»¶ä¿¡å·ï¼Œå®ƒä½¿è§£ç å™¨èƒ½å¤Ÿä¸ºä¸åŒç©ºé—´ä½ç½®ç”Ÿæˆè‡ªé€‚åº”çš„å½’ä¸€åŒ–å‚æ•°ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡ã€‚åœ¨å®è·µä¸­ï¼Œ`zq` æ€»æ˜¯ç­‰äº `z`ã€‚

---

## 3. åŸºç¡€ç»„ä»¶è¿ç§»

### 3.1 Conv3d åŸºç¡€å·ç§¯

#### PyTorch: `CogVideoXSafeConv3d`

```python
# autoencoder_kl_cogvideox.py ç¬¬ 38-66 è¡Œ
class CogVideoXSafeConv3d(nn.Conv3d):
    """
    é¿å… OOM çš„ 3D å·ç§¯ï¼Œé€šè¿‡åˆ†å—å¤„ç†å¤§å¼ é‡
    """
    def forward(self, input: torch.Tensor) -> torch.Tensor:
        memory_count = (input.shape[0] * ... * input.shape[4]) * 2 / 1024**3
        
        if memory_count > 2:  # > 2GB
            # åˆ†å—å¤„ç†
            part_num = int(memory_count / 2) + 1
            input_chunks = torch.chunk(input, part_num, dim=2)
            
            # å¤„ç† kernel overlap
            if kernel_size > 1:
                input_chunks = [input_chunks[0]] + [
                    torch.cat((input_chunks[i-1][:, :, -kernel_size+1:], 
                              input_chunks[i]), dim=2)
                    for i in range(1, len(input_chunks))
                ]
            
            # åˆ†å—å·ç§¯
            output_chunks = [super().forward(chunk) for chunk in input_chunks]
            return torch.cat(output_chunks, dim=2)
        else:
            return super().forward(input)
```

**åŠŸèƒ½**ï¼š
- è¾“å…¥ï¼š`(B, C, T, H, W)` æ ¼å¼
- è‡ªåŠ¨æ£€æµ‹å†…å­˜ä½¿ç”¨ï¼Œè¶…è¿‡ 2GB æ—¶åˆ†å—å¤„ç†
- å¤„ç†æ—¶é—´ç»´åº¦çš„å·ç§¯æ ¸é‡å 

#### Flax: `FlaxConv3d`

```python
# autoencoder_kl_cogvideox_flax.py ç¬¬ 182-219 è¡Œ
class FlaxConv3d(nnx.Module):
    """åŸºç¡€ 3D å·ç§¯å°è£…"""
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, rngs):
        if isinstance(kernel_size, int):
            kernel_size = (kernel_size,) * 3
        if isinstance(stride, int):
            stride = (stride,) * 3
        
        # å¤„ç† padding
        if isinstance(padding, int):
            if padding == 0:
                padding_mode = ((0, 0), (0, 0), (0, 0))
            else:
                padding_mode = ((padding, padding), (padding, padding), (padding, padding))
        
        self.conv = nnx.Conv(
            in_channels, out_channels,
            kernel_size=kernel_size,
            strides=stride,
            padding=padding_mode,
            rngs=rngs
        )
    
    def __call__(self, x):
        return self.conv(x)
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **è¾“å…¥æ ¼å¼**ï¼šFlax çš„ `nnx.Conv` æœŸæœ› `(B, T, H, W, C)` channel-last æ ¼å¼
2. âœ… **Padding æ ¼å¼**ï¼š
   - PyTorch: `padding=1` è¡¨ç¤ºæ¯ä¸ªç»´åº¦å¡«å…… 1
   - Flax: `padding=((1,1), (1,1), (1,1))` æ˜¾å¼æŒ‡å®šå‰åå¡«å……
3. âŒ **å†…å­˜ä¼˜åŒ–**ï¼šFlax ç‰ˆæœ¬**æœªå®ç°**åˆ†å—å¤„ç†ï¼Œä¾èµ– JAX çš„è‡ªåŠ¨å†…å­˜ç®¡ç†
   - åŸå› ï¼šJAX çš„ XLA ç¼–è¯‘å™¨ä¼šè‡ªåŠ¨ä¼˜åŒ–å†…å­˜ä½¿ç”¨
   - TPU ä¸Šé€šå¸¸ä¸ä¼šé‡åˆ°å•ä¸ªå·ç§¯è¶…è¿‡ 2GB çš„æƒ…å†µ

### 3.2 CausalConv3d å› æœå·ç§¯

è¿™æ˜¯ CogVideoX çš„æ ¸å¿ƒç»„ä»¶ï¼Œç¡®ä¿æ—¶é—´ç»´åº¦çš„å› æœæ€§ã€‚

#### PyTorch: `CogVideoXCausalConv3d`

```python
# autoencoder_kl_cogvideox.py ç¬¬ 69-147 è¡Œ
class CogVideoXCausalConv3d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, 
                 dilation=1, pad_mode="constant"):
        super().__init__()
        
        # è®¡ç®—å¡«å……
        time_pad = time_kernel_size - 1
        height_pad = (height_kernel_size - 1) // 2
        width_pad = (width_kernel_size - 1) // 2
        
        self.pad_mode = pad_mode
        self.time_causal_padding = (width_pad, width_pad, height_pad, height_pad, time_pad, 0)
        
        # åˆ›å»ºåº•å±‚å·ç§¯
        self.conv = CogVideoXSafeConv3d(
            in_channels, out_channels,
            kernel_size=kernel_size,
            stride=(stride, 1, 1),
            padding=0 if pad_mode == "replicate" else (0, height_pad, width_pad),
        )
    
    def forward(self, inputs, conv_cache=None):
        # å› æœå¡«å……
        if self.pad_mode == "replicate":
            inputs = F.pad(inputs, self.time_causal_padding, mode="replicate")
        else:
            # ä½¿ç”¨ conv_cache
            if self.time_kernel_size > 1:
                if conv_cache is not None:
                    cached_inputs = conv_cache
                else:
                    cached_inputs = inputs[:, :, :1].repeat(1, 1, self.time_kernel_size-1, 1, 1)
                inputs = torch.cat([cached_inputs, inputs], dim=2)
        
        # å·ç§¯
        output = self.conv(inputs)
        
        # æ›´æ–°ç¼“å­˜
        if self.pad_mode != "replicate":
            conv_cache = inputs[:, :, -(self.time_kernel_size-1):].clone()
        
        return output, conv_cache
```

**æ ¸å¿ƒé€»è¾‘**ï¼š
1. **æ—¶é—´å› æœæ€§**ï¼šåªåœ¨æ—¶é—´ç»´åº¦å‰é¢å¡«å……ï¼ˆ`time_pad, 0`ï¼‰ï¼Œä¸åœ¨åé¢
2. **ç©ºé—´å¯¹ç§°**ï¼šé«˜åº¦å’Œå®½åº¦å¯¹ç§°å¡«å……
3. **ä¸¤ç§æ¨¡å¼**ï¼š
   - `replicate`ï¼šç›´æ¥å¤åˆ¶è¾¹ç¼˜å€¼å¡«å……
   - `constant`ï¼šä½¿ç”¨ `conv_cache` ç¼“å­˜å‰å‡ å¸§

#### Flax: `FlaxCogVideoXCausalConv3d`

```python
# autoencoder_kl_cogvideox_flax.py ç¬¬ 260-494 è¡Œ
class FlaxCogVideoXCausalConv3d(nnx.Module):
    CACHE_T = 2  # ç¼“å­˜å¸§æ•°
    
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, 
                 dilation=1, pad_mode="constant", rngs=None):
        # è®¡ç®—å¡«å……
        self.time_pad = time_kernel_size - 1
        self.height_pad = (height_kernel_size - 1) // 2
        self.width_pad = (width_kernel_size - 1) // 2
        
        self.pad_mode = pad_mode
        self.time_kernel_size = time_kernel_size
        self.temporal_dim = 1  # JAX ä¸­æ—¶é—´ç»´åº¦æ˜¯ 1
        
        # åˆ›å»ºå·ç§¯
        self.conv = FlaxConv3d(
            in_channels, out_channels,
            kernel_size=kernel_size,
            stride=(stride, 1, 1),
            padding=0 if pad_mode == "replicate" else (0, height_pad, width_pad),
            rngs=rngs
        )
    
    def __call__(self, inputs, conv_cache=None, feat_cache=None, feat_idx=None):
        # æ”¯æŒä¸¤ç§ç¼“å­˜æ¨¡å¼
        if feat_cache is not None and feat_idx is not None:
            return self._call_with_feat_cache(inputs, feat_cache, feat_idx)
        return self._call_with_conv_cache(inputs, conv_cache)
```

**æ–°å¢åŠŸèƒ½**ï¼šåŒç¼“å­˜æ¨¡å¼

1. **æ—§æ¨¡å¼** `_call_with_conv_cache`ï¼ˆå…¼å®¹æ€§ï¼‰ï¼š

```python
def _call_with_conv_cache(self, inputs, conv_cache):
    # ç±»ä¼¼ PyTorch çš„å®ç°
    if self.pad_mode == "replicate":
        pad_width = [(0,0), (self.time_pad, 0), (self.height_pad, self.height_pad), 
                     (self.width_pad, self.width_pad), (0,0)]
        inputs = jnp.pad(inputs, pad_width, mode='edge')
        conv_cache = None
    else:
        if self.time_kernel_size > 1:
            if conv_cache is not None:
                cached_inputs = conv_cache
            else:
                cached_inputs = jnp.tile(inputs[:, :1, :, :, :], 
                                        (1, self.time_kernel_size-1, 1, 1, 1))
            inputs = jnp.concatenate([cached_inputs, inputs], axis=1)
    
    output = self.conv(inputs)
    
    if self.pad_mode != "replicate":
        new_cache = inputs[:, -(self.time_kernel_size-1):, :, :, :]
    else:
        new_cache = None
    
    return output, new_cache
```

2. **æ–°æ¨¡å¼** `_call_with_feat_cache`ï¼ˆé€å¸§è§£ç ï¼‰ï¼š

```python
def _call_with_feat_cache(self, inputs, feat_cache, feat_idx):
    """
    å‚è€ƒ WAN VAE çš„è®¾è®¡ï¼Œæ”¯æŒé€å¸§å¤„ç†
    """
    idx = feat_idx[0]
    
    if self.pad_mode == "replicate":
        # Replicate æ¨¡å¼
        pad_width = [(0,0), (self.time_pad, 0), ...]
        x = jnp.pad(inputs, pad_width, mode='edge')
    else:
        # Constant æ¨¡å¼ï¼šä½¿ç”¨ feat_cache
        if self.time_kernel_size > 1:
            padding_needed = self.time_kernel_size - 1
            
            if feat_cache[idx] is not None:
                # æ‹¼æ¥ç¼“å­˜å’Œå½“å‰è¾“å…¥
                x = jnp.concatenate([feat_cache[idx], inputs], axis=1)
                
                # è°ƒæ•´ padding
                cache_len = feat_cache[idx].shape[1]
                padding_needed -= cache_len
                if padding_needed > 0:
                    extra_padding = jnp.tile(x[:, :1, ...], (1, padding_needed, 1, 1, 1))
                    x = jnp.concatenate([extra_padding, x], axis=1)
            else:
                # ç¬¬ä¸€æ¬¡ï¼šé‡å¤ç¬¬ä¸€å¸§
                padding_frames = jnp.tile(inputs[:, :1, ...], (1, padding_needed, 1, 1, 1))
                x = jnp.concatenate([padding_frames, inputs], axis=1)
            
            # æ‰§è¡Œå·ç§¯
            x2 = self.conv(x)
            
            # âš ï¸ å…³é”®ï¼šæ›´æ–°ç¼“å­˜ï¼ˆä½¿ç”¨ inputs è€Œé x2ï¼‰
            if inputs.shape[1] < self.CACHE_T and feat_cache[idx] is not None:
                feat_cache[idx] = jnp.concatenate([
                    jnp.expand_dims(feat_cache[idx][:, -1, ...], axis=1),
                    inputs[:, -self.CACHE_T:, ...]
                ], axis=1)
            else:
                feat_cache[idx] = inputs[:, -self.CACHE_T:, ...]
            
            feat_idx[0] += 1
            return x2, None
        else:
            x = inputs
    
    output = self.conv(x)
    feat_idx[0] += 1
    return output, None
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **ç»´åº¦è°ƒæ•´**ï¼š`temporal_dim = 2` (PyTorch) â†’ `temporal_dim = 1` (Flax)
2. âœ… **åŒç¼“å­˜æ”¯æŒ**ï¼š
   - `conv_cache`ï¼šå‘åå…¼å®¹ PyTorch çš„æ–¹å¼
   - `feat_cache + feat_idx`ï¼šæ–°çš„é€å¸§è§£ç æ–¹å¼ï¼ˆå‚è€ƒ WAN VAEï¼‰
3. âœ… **ç¼“å­˜æ›´æ–°é€»è¾‘**ï¼š
   - PyTorch: `conv_cache = inputs[:, :, -k+1:].clone()`
   - Flax: ä½¿ç”¨åˆ—è¡¨ `feat_cache[idx]` å¹¶æ”¯æŒåŠ¨æ€æ›´æ–°

### 3.3 GroupNorm ç»„å½’ä¸€åŒ–

GroupNorm æ˜¯ VAE ä¸­çš„å…³é”®å½’ä¸€åŒ–å±‚ã€‚

#### PyTorch: `nn.GroupNorm`

```python
# PyTorch å†…ç½®ï¼Œä½¿ç”¨æ–¹å¼ï¼š
self.norm1 = nn.GroupNorm(num_channels=in_channels, num_groups=groups, eps=eps)

# å‰å‘ä¼ æ’­
hidden_states = self.norm1(hidden_states)  # (B, C, T, H, W)
```

**è®¡ç®—é€»è¾‘**ï¼š
1. å°†é€šé“åˆ†ç»„ï¼š`C` â†’ `num_groups Ã— (C // num_groups)`
2. è®¡ç®—æ¯ç»„çš„å‡å€¼å’Œæ–¹å·®ï¼ˆåœ¨ T, H, W ç»´åº¦ä¸Šï¼‰
3. å½’ä¸€åŒ–ï¼š`(x - mean) / sqrt(var + eps)`
4. ä»¿å°„å˜æ¢ï¼š`x * gamma + beta`

#### Flax: `FlaxGroupNorm`

```python
# autoencoder_kl_cogvideox_flax.py ç¬¬ 497-589 è¡Œ
class FlaxGroupNorm(nnx.Module):
    def __init__(self, num_groups, num_channels, epsilon=1e-6, rngs=None):
        self.num_groups = num_groups
        self.num_channels = num_channels
        self.epsilon = epsilon
        
        # å¯å­¦ä¹ å‚æ•°
        self.scale = nnx.Param(jnp.ones((num_channels,)))
        self.bias = nnx.Param(jnp.zeros((num_channels,)))
    
    def __call__(self, x):
        if len(x.shape) == 5:  # 5D: (B, T, H, W, C)
            B, T, H, W, C = x.shape
            channels_per_group = C // self.num_groups
            
            # Reshape æš´éœ²ç»„: (B, T, H, W, num_groups, C//num_groups)
            x_grouped = x.reshape(B, T, H, W, self.num_groups, channels_per_group)
            
            # è®¡ç®—ç»Ÿè®¡é‡ï¼ˆåœ¨ T, H, W, C//num_groups ç»´åº¦ä¸Šï¼‰
            mean = jnp.mean(x_grouped, axis=(1, 2, 3, 5), keepdims=True)
            var = jnp.var(x_grouped, axis=(1, 2, 3, 5), keepdims=True)
            
            # å½’ä¸€åŒ–
            x_norm = (x_grouped - mean) / jnp.sqrt(var + self.epsilon)
            x_norm = x_norm.reshape(B, T, H, W, C)
            
            # ä»¿å°„å˜æ¢
            x_out = x_norm * self.scale.value.reshape(1, 1, 1, 1, C) + \
                    self.bias.value.reshape(1, 1, 1, 1, C)
        else:  # 4D: (B, H, W, C)
            # ç±»ä¼¼é€»è¾‘...
        
        return x_out
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **æ ¼å¼è½¬æ¢**ï¼šç›´æ¥åœ¨ channel-last æ ¼å¼è®¡ç®—ï¼Œé¿å…è½¬ç½®å¼€é”€
2. âœ… **æ•°å­¦ç­‰ä»·**ï¼š
   - PyTorch åœ¨ channel-first æ ¼å¼è®¡ç®—ç»Ÿè®¡é‡
   - Flax ç›´æ¥åœ¨ channel-last æ ¼å¼è®¡ç®—ï¼Œæ•°å­¦ä¸Šå®Œå…¨ç­‰ä»·
3. âœ… **å‚æ•°å‘½å**ï¼š
   - PyTorch: `weight`, `bias`
   - Flax: `scale`, `bias` (æ›´æ¸…æ™°çš„è¯­ä¹‰)

---

*ï¼ˆç¬¬ä¸€éƒ¨åˆ†å®Œæˆï¼Œæ¥ä¸‹æ¥ç»§ç»­...ï¼‰*


## 4. æ ¸å¿ƒæ¨¡å—è¿ç§»

### 4.1 SpatialNorm3D ç©ºé—´å½’ä¸€åŒ–

SpatialNorm3D æ˜¯è§£ç å™¨ä¸“ç”¨çš„æ¡ä»¶å½’ä¸€åŒ–å±‚ï¼Œä½¿ç”¨æ½œåœ¨è¡¨ç¤ºä½œä¸ºæ¡ä»¶ä¿¡å·ã€‚

#### PyTorch: `CogVideoXSpatialNorm3D`

```python
# autoencoder_kl_cogvideox.py ç¬¬ 149-197 è¡Œ
class CogVideoXSpatialNorm3D(nn.Module):
    def __init__(self, f_channels, zq_channels, groups=32):
        super().__init__()
        self.norm_layer = nn.GroupNorm(num_channels=f_channels, num_groups=groups, eps=1e-6)
        self.conv_y = CogVideoXCausalConv3d(zq_channels, f_channels, kernel_size=1)
        self.conv_b = CogVideoXCausalConv3d(zq_channels, f_channels, kernel_size=1)
    
    def forward(self, f, zq, conv_cache=None):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        # å¤„ç†å¥‡æ•°å¸§ç‰¹æ®Šæƒ…å†µ
        if f.shape[2] > 1 and f.shape[2] % 2 == 1:
            f_first, f_rest = f[:, :, :1], f[:, :, 1:]
            z_first, z_rest = zq[:, :, :1], zq[:, :, 1:]
            z_first = F.interpolate(z_first, size=f_first.shape[-3:])
            z_rest = F.interpolate(z_rest, size=f_rest.shape[-3:])
            zq = torch.cat([z_first, z_rest], dim=2)
        else:
            zq = F.interpolate(zq, size=f.shape[-3:])
        
        # åº”ç”¨æ¡ä»¶å·ç§¯
        conv_y, new_conv_cache["conv_y"] = self.conv_y(zq, conv_cache=conv_cache.get("conv_y"))
        conv_b, new_conv_cache["conv_b"] = self.conv_b(zq, conv_cache=conv_cache.get("conv_b"))
        
        # å½’ä¸€åŒ– + æ¡ä»¶
        norm_f = self.norm_layer(f)
        new_f = norm_f * conv_y + conv_b
        
        return new_f, new_conv_cache
```

**åŠŸèƒ½**ï¼š
1. å¯¹ç‰¹å¾ `f` è¿›è¡Œ GroupNorm å½’ä¸€åŒ–
2. å°†æ½œåœ¨è¡¨ç¤º `zq` ä¸Šé‡‡æ ·åˆ° `f` çš„ç©ºé—´å°ºå¯¸
3. ä½¿ç”¨ä¸¤ä¸ª 1x1x1 å·ç§¯ç”Ÿæˆç¼©æ”¾å› å­ `conv_y` å’Œåç§» `conv_b`
4. åº”ç”¨ä»¿å°„å˜æ¢ï¼š`norm_f * conv_y + conv_b`

**è¾“å…¥**ï¼š
- `f`: ç‰¹å¾å›¾ `(B, C, T, H, W)`
- `zq`: æ½œåœ¨æ¡ä»¶ `(B, C', T', H', W')`

**è¾“å‡º**ï¼š
- æ¡ä»¶å½’ä¸€åŒ–åçš„ç‰¹å¾

#### Flax: `FlaxCogVideoXSpatialNorm3D`

```python
# autoencoder_kl_cogvideox_flax.py ç¬¬ 592-727 è¡Œ
class FlaxCogVideoXSpatialNorm3D(nnx.Module):
    def __init__(self, f_channels, zq_channels, groups=32, rngs=None):
        self.norm_layer = FlaxGroupNorm(
            num_groups=groups, num_channels=f_channels, epsilon=1e-6, rngs=rngs
        )
        self.conv_y = FlaxCogVideoXCausalConv3d(
            zq_channels, f_channels, kernel_size=1, stride=1, pad_mode="constant", rngs=rngs
        )
        self.conv_b = FlaxCogVideoXCausalConv3d(
            zq_channels, f_channels, kernel_size=1, stride=1, pad_mode="constant", rngs=rngs
        )
    
    def __call__(self, f, zq, conv_cache=None, feat_cache=None, feat_idx=None):
        # æ”¯æŒä¸¤ç§ç¼“å­˜æ¨¡å¼
        if feat_cache is not None and feat_idx is not None:
            return self._call_with_feat_cache(f, zq, feat_cache, feat_idx)
        return self._call_with_conv_cache(f, zq, conv_cache)
    
    def _call_with_conv_cache(self, f, zq, conv_cache):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        # å¤„ç†å¥‡æ•°å¸§ï¼ˆä¸ PyTorch å®Œå…¨ä¸€è‡´ï¼‰
        B, T, H, W, C = f.shape
        if T > 1 and T % 2 == 1:
            f_first = f[:, :1, :, :, :]
            f_rest = f[:, 1:, :, :, :]
            z_first = zq[:, :1, :, :, :]
            z_rest = zq[:, 1:, :, :, :]
            
            # åˆ†åˆ« resize
            z_first = jax.image.resize(z_first, (B, 1, H, W, zq.shape[-1]), method='nearest')
            z_rest = jax.image.resize(z_rest, (B, T-1, H, W, zq.shape[-1]), method='nearest')
            
            zq = jnp.concatenate([z_first, z_rest], axis=1)
        else:
            zq = jax.image.resize(zq, (B, T, H, W, zq.shape[-1]), method='nearest')
        
        # åº”ç”¨æ¡ä»¶å·ç§¯
        conv_y, new_conv_cache["conv_y"] = self.conv_y(zq, conv_cache=conv_cache.get("conv_y"))
        conv_b, new_conv_cache["conv_b"] = self.conv_b(zq, conv_cache=conv_cache.get("conv_b"))
        
        # å½’ä¸€åŒ– + æ¡ä»¶
        norm_f = self.norm_layer(f)
        new_f = norm_f * conv_y + conv_b
        
        return new_f, new_conv_cache
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **æ’å€¼æ–¹æ³•**ï¼š
   - PyTorch: `F.interpolate(...)` é»˜è®¤åŒçº¿æ€§æ’å€¼
   - Flax: `jax.image.resize(..., method='nearest')` æœ€è¿‘é‚»æ’å€¼
   - ä½¿ç”¨æœ€è¿‘é‚»æ˜¯ä¸ºäº†ä¸ PyTorch çš„é»˜è®¤è¡Œä¸ºåŒ¹é…
2. âœ… **å¥‡æ•°å¸§å¤„ç†**ï¼šå®Œå…¨ä¿ç•™ PyTorch çš„é€»è¾‘
   - åŸå› ï¼šé¿å…ç¬¬ä¸€å¸§å’Œå…¶ä½™å¸§çš„ä¸ä¸€è‡´
3. âœ… **åŒç¼“å­˜æ¨¡å¼**ï¼šåŒæ ·æ”¯æŒ `conv_cache` å’Œ `feat_cache` ä¸¤ç§æ¨¡å¼

### 4.2 ResnetBlock3D æ®‹å·®å—

ResNet å—æ˜¯ VAE çš„åŸºç¡€æ„å»ºå•å…ƒã€‚

#### PyTorch: `CogVideoXResnetBlock3D`

```python
# autoencoder_kl_cogvideox.py ç¬¬ 200-328 è¡Œ
class CogVideoXResnetBlock3D(nn.Module):
    def __init__(self, in_channels, out_channels=None, dropout=0.0, temb_channels=512,
                 groups=32, eps=1e-6, non_linearity="swish", conv_shortcut=False,
                 spatial_norm_dim=None, pad_mode="first"):
        super().__init__()
        out_channels = out_channels or in_channels
        
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.nonlinearity = get_activation(non_linearity)
        self.use_conv_shortcut = conv_shortcut
        
        # å½’ä¸€åŒ–å±‚
        if spatial_norm_dim is None:
            # ç¼–ç å™¨ï¼šä½¿ç”¨ GroupNorm
            self.norm1 = nn.GroupNorm(num_channels=in_channels, num_groups=groups, eps=eps)
            self.norm2 = nn.GroupNorm(num_channels=out_channels, num_groups=groups, eps=eps)
        else:
            # è§£ç å™¨ï¼šä½¿ç”¨ SpatialNorm3D
            self.norm1 = CogVideoXSpatialNorm3D(
                f_channels=in_channels, zq_channels=spatial_norm_dim, groups=groups
            )
            self.norm2 = CogVideoXSpatialNorm3D(
                f_channels=out_channels, zq_channels=spatial_norm_dim, groups=groups
            )
        
        # å·ç§¯å±‚
        self.conv1 = CogVideoXCausalConv3d(in_channels, out_channels, kernel_size=3, pad_mode=pad_mode)
        
        # æ—¶é—´åµŒå…¥æŠ•å½±
        if temb_channels > 0:
            self.temb_proj = nn.Linear(in_features=temb_channels, out_features=out_channels)
        
        self.dropout = nn.Dropout(dropout)
        self.conv2 = CogVideoXCausalConv3d(out_channels, out_channels, kernel_size=3, pad_mode=pad_mode)
        
        # å¿«æ·è¿æ¥
        if self.in_channels != self.out_channels:
            if self.use_conv_shortcut:
                self.conv_shortcut = CogVideoXCausalConv3d(in_channels, out_channels, kernel_size=3, pad_mode=pad_mode)
            else:
                self.conv_shortcut = CogVideoXSafeConv3d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)
    
    def forward(self, inputs, temb=None, zq=None, conv_cache=None):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        hidden_states = inputs
        
        # ç¬¬ä¸€ä¸ªå½’ä¸€åŒ– + å·ç§¯
        if zq is not None:
            hidden_states, new_conv_cache["norm1"] = self.norm1(
                hidden_states, zq, conv_cache=conv_cache.get("norm1")
            )
        else:
            hidden_states = self.norm1(hidden_states)
        
        hidden_states = self.nonlinearity(hidden_states)
        hidden_states, new_conv_cache["conv1"] = self.conv1(
            hidden_states, conv_cache=conv_cache.get("conv1")
        )
        
        # æ—¶é—´åµŒå…¥
        if temb is not None:
            hidden_states = hidden_states + self.temb_proj(self.nonlinearity(temb))[:, :, None, None, None]
        
        # ç¬¬äºŒä¸ªå½’ä¸€åŒ– + å·ç§¯
        if zq is not None:
            hidden_states, new_conv_cache["norm2"] = self.norm2(
                hidden_states, zq, conv_cache=conv_cache.get("norm2")
            )
        else:
            hidden_states = self.norm2(hidden_states)
        
        hidden_states = self.nonlinearity(hidden_states)
        hidden_states = self.dropout(hidden_states)
        hidden_states, new_conv_cache["conv2"] = self.conv2(
            hidden_states, conv_cache=conv_cache.get("conv2")
        )
        
        # å¿«æ·è¿æ¥
        if self.in_channels != self.out_channels:
            if self.use_conv_shortcut:
                inputs, new_conv_cache["conv_shortcut"] = self.conv_shortcut(
                    inputs, conv_cache=conv_cache.get("conv_shortcut")
                )
            else:
                inputs = self.conv_shortcut(inputs)
        
        # æ®‹å·®è¿æ¥
        hidden_states = hidden_states + inputs
        
        return hidden_states, new_conv_cache
```

**ç»“æ„**ï¼š
```
è¾“å…¥ â”€â”€â”¬â”€â”€> Norm1 -> Act -> Conv1 -> (+temb) -> Norm2 -> Act -> Dropout -> Conv2 â”€â”€â”¬â”€â”€> è¾“å‡º
       â”‚                                                                             â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Conv_shortcut (å¦‚æœé€šé“æ•°æ”¹å˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è¾“å…¥**ï¼š
- `inputs`: `(B, C, T, H, W)`
- `temb`: æ—¶é—´åµŒå…¥ `(B, temb_channels)` (å¯é€‰)
- `zq`: ç©ºé—´æ¡ä»¶ `(B, C', T', H', W')` (è§£ç å™¨)

**è¾“å‡º**ï¼š
- æ®‹å·®è¿æ¥åçš„ç‰¹å¾

#### Flax: `FlaxCogVideoXResnetBlock3D`

```python
# autoencoder_kl_cogvideox_flax.py ç¬¬ 733-980 è¡Œ
class FlaxCogVideoXResnetBlock3D(nnx.Module):
    def __init__(self, in_channels, out_channels=None, dropout=0.0, temb_channels=512,
                 groups=32, eps=1e-6, non_linearity="swish", conv_shortcut=False,
                 spatial_norm_dim=None, pad_mode="first", rngs=None):
        out_channels = out_channels or in_channels
        
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.use_conv_shortcut = conv_shortcut
        self.spatial_norm_dim = spatial_norm_dim
        
        # å½’ä¸€åŒ–å±‚
        if spatial_norm_dim is None:
            self.norm1 = FlaxGroupNorm(num_groups=groups, num_channels=in_channels, epsilon=eps, rngs=rngs)
            self.norm2 = FlaxGroupNorm(num_groups=groups, num_channels=out_channels, epsilon=eps, rngs=rngs)
        else:
            self.norm1 = FlaxCogVideoXSpatialNorm3D(
                f_channels=in_channels, zq_channels=spatial_norm_dim, groups=groups, rngs=rngs
            )
            self.norm2 = FlaxCogVideoXSpatialNorm3D(
                f_channels=out_channels, zq_channels=spatial_norm_dim, groups=groups, rngs=rngs
            )
        
        # å·ç§¯å±‚
        self.conv1 = FlaxCogVideoXCausalConv3d(
            in_channels=in_channels, out_channels=out_channels, kernel_size=3, pad_mode=pad_mode, rngs=rngs
        )
        
        # æ—¶é—´åµŒå…¥æŠ•å½±
        if temb_channels > 0:
            self.temb_proj = nnx.Linear(temb_channels, out_channels, rngs=rngs)
        else:
            self.temb_proj = None
        
        self.dropout_rate = dropout
        self.conv2 = FlaxCogVideoXCausalConv3d(
            in_channels=out_channels, out_channels=out_channels, kernel_size=3, pad_mode=pad_mode, rngs=rngs
        )
        
        # å¿«æ·è¿æ¥
        if self.in_channels != self.out_channels:
            if self.use_conv_shortcut:
                self.conv_shortcut = FlaxCogVideoXCausalConv3d(
                    in_channels=in_channels, out_channels=out_channels, kernel_size=3, pad_mode=pad_mode, rngs=rngs
                )
            else:
                self.conv_shortcut = FlaxConv3d(
                    in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, rngs=rngs
                )
        else:
            self.conv_shortcut = None
    
    def __call__(self, inputs, temb=None, zq=None, conv_cache=None, 
                 feat_cache=None, feat_idx=None, deterministic=True):
        # æ”¯æŒä¸¤ç§ç¼“å­˜æ¨¡å¼
        if feat_cache is not None and feat_idx is not None:
            return self._call_with_feat_cache(inputs, temb, zq, feat_cache, feat_idx, deterministic)
        return self._call_with_conv_cache(inputs, temb, zq, conv_cache, deterministic)
    
    def _call_with_conv_cache(self, inputs, temb, zq, conv_cache, deterministic):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        hidden_states = inputs
        
        # ç¬¬ä¸€ä¸ªå½’ä¸€åŒ– + å·ç§¯
        if zq is not None:
            hidden_states, new_conv_cache["norm1"] = self.norm1(
                hidden_states, zq, conv_cache=conv_cache.get("norm1")
            )
        else:
            hidden_states = self.norm1(hidden_states)
        
        hidden_states = jax.nn.silu(hidden_states)  # swish æ¿€æ´»
        hidden_states, new_conv_cache["conv1"] = self.conv1(
            hidden_states, conv_cache=conv_cache.get("conv1")
        )
        
        # æ—¶é—´åµŒå…¥
        if temb is not None and self.temb_proj is not None:
            temb_proj = self.temb_proj(jax.nn.silu(temb))
            hidden_states = hidden_states + temb_proj[:, None, None, None, :]
        
        # ç¬¬äºŒä¸ªå½’ä¸€åŒ– + å·ç§¯
        if zq is not None:
            hidden_states, new_conv_cache["norm2"] = self.norm2(
                hidden_states, zq, conv_cache=conv_cache.get("norm2")
            )
        else:
            hidden_states = self.norm2(hidden_states)
        
        hidden_states = jax.nn.silu(hidden_states)
        
        # Dropout
        if self.dropout_rate > 0 and not deterministic:
            hidden_states = nnx.Dropout(rate=self.dropout_rate)(hidden_states)
        
        hidden_states, new_conv_cache["conv2"] = self.conv2(
            hidden_states, conv_cache=conv_cache.get("conv2")
        )
        
        # å¿«æ·è¿æ¥
        if self.conv_shortcut is not None:
            if self.use_conv_shortcut:
                inputs, new_conv_cache["conv_shortcut"] = self.conv_shortcut(
                    inputs, conv_cache=conv_cache.get("conv_shortcut")
                )
            else:
                inputs = self.conv_shortcut(inputs)
        
        # æ®‹å·®è¿æ¥
        hidden_states = hidden_states + inputs
        
        return hidden_states, new_conv_cache
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **æ¿€æ´»å‡½æ•°**ï¼š
   - PyTorch: `self.nonlinearity = get_activation(non_linearity)` â†’ ä½¿ç”¨å­—ç¬¦ä¸²é…ç½®
   - Flax: ç›´æ¥ä½¿ç”¨ `jax.nn.silu`ï¼ˆå› ä¸º CogVideoX åªç”¨ swish/siluï¼‰
2. âœ… **Dropout**ï¼š
   - PyTorch: `self.dropout = nn.Dropout(dropout)`
   - Flax: ä½¿ç”¨ `nnx.Dropout` + `deterministic` å‚æ•°æ§åˆ¶
3. âœ… **æ—¶é—´åµŒå…¥ç»´åº¦**ï¼š
   - PyTorch: `[:, :, None, None, None]` â†’ `(B, C, 1, 1, 1)`
   - Flax: `[:, None, None, None, :]` â†’ `(B, 1, 1, 1, C)`
   - åŸå› ï¼šæ•°æ®æ ¼å¼ä¸åŒï¼ˆBCTHW vs BTHWCï¼‰

---

æ–‡æ¡£æŒç»­æ›´æ–°ä¸­ï¼Œç”±äºé•¿åº¦é™åˆ¶ï¼Œå‰©ä½™éƒ¨åˆ†å°†åœ¨ä¸‹ä¸€æ¬¡ç»§ç»­å®Œæˆã€‚å·²å®Œæˆçš„å†…å®¹åŒ…æ‹¬ï¼š

âœ… æ•´ä½“æ¶æ„æ¦‚è¿°
âœ… è°ƒç”¨æµç¨‹è¯¦è§£ï¼ˆEncode/Decodeï¼‰
âœ… åŸºç¡€ç»„ä»¶è¿ç§»ï¼ˆConv3d, GroupNorm, CausalConv3dï¼‰
âœ… æ ¸å¿ƒæ¨¡å—è¿ç§»ï¼ˆSpatialNorm3D, ResnetBlock3Dï¼‰

å¾…å®Œæˆéƒ¨åˆ†ï¼š
- DownBlockã€MidBlockã€UpBlock çš„è¿ç§»
- Encoder3D å’Œ Decoder3D çš„è¿ç§»
- ä¸» VAE ç±»çš„è¿ç§»
- Tiling åŠŸèƒ½çš„è¿ç§»
- Frame batching å’Œ conv_cache æœºåˆ¶
- å…³é”®å·®å¼‚æ€»ç»“


### 4.3 DownBlock3Dã€MidBlock3Dã€UpBlock3D

è¿™ä¸‰ä¸ªæ¨¡å—åˆ†åˆ«è´Ÿè´£ç¼–ç å™¨çš„ä¸‹é‡‡æ ·ã€ä¸­é—´å¤„ç†å’Œè§£ç å™¨çš„ä¸Šé‡‡æ ·ã€‚

#### 4.3.1 DownBlock3D ä¸‹é‡‡æ ·å—

**PyTorch ç‰ˆæœ¬**ï¼ˆç¬¬ 331-441 è¡Œï¼‰ï¼š

```python
class CogVideoXDownBlock3D(nn.Module):
    def __init__(self, in_channels, out_channels, temb_channels, dropout=0.0,
                 num_layers=1, resnet_eps=1e-6, resnet_act_fn="swish",
                 resnet_groups=32, add_downsample=True, downsample_padding=0,
                 compress_time=False, pad_mode="first"):
        super().__init__()
        
        # åˆ›å»ºå¤šä¸ª ResNet å—
        resnets = []
        for i in range(num_layers):
            in_channel = in_channels if i == 0 else out_channels
            resnets.append(
                CogVideoXResnetBlock3D(
                    in_channels=in_channel, out_channels=out_channels,
                    dropout=dropout, temb_channels=temb_channels,
                    groups=resnet_groups, eps=resnet_eps,
                    non_linearity=resnet_act_fn, pad_mode=pad_mode
                )
            )
        self.resnets = nn.ModuleList(resnets)
        
        # ä¸‹é‡‡æ ·å™¨
        if add_downsample:
            self.downsamplers = nn.ModuleList([
                CogVideoXDownsample3D(
                    out_channels, out_channels,
                    padding=downsample_padding, compress_time=compress_time
                )
            ])
        else:
            self.downsamplers = None
    
    def forward(self, hidden_states, temb=None, zq=None, conv_cache=None):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        # ä¾æ¬¡é€šè¿‡æ¯ä¸ª ResNet å—
        for i, resnet in enumerate(self.resnets):
            conv_cache_key = f"resnet_{i}"
            hidden_states, new_conv_cache[conv_cache_key] = resnet(
                hidden_states, temb, zq, conv_cache=conv_cache.get(conv_cache_key)
            )
        
        # ä¸‹é‡‡æ ·
        if self.downsamplers is not None:
            for downsampler in self.downsamplers:
                hidden_states = downsampler(hidden_states)
        
        return hidden_states, new_conv_cache
```

**Flax ç‰ˆæœ¬**ï¼ˆç¬¬ 983-1113 è¡Œï¼‰ï¼š

```python
class FlaxCogVideoXDownBlock3D(nnx.Module):
    def __init__(self, in_channels, out_channels, temb_channels, dropout=0.0,
                 num_layers=1, resnet_eps=1e-6, resnet_act_fn="swish",
                 resnet_groups=32, add_downsample=True, downsample_padding=0,
                 compress_time=False, pad_mode="first", rngs=None):
        # åˆ›å»º ResNet å—åˆ—è¡¨
        resnets = []
        for i in range(num_layers):
            in_channel = in_channels if i == 0 else out_channels
            resnet = FlaxCogVideoXResnetBlock3D(
                in_channels=in_channel, out_channels=out_channels,
                dropout=dropout, temb_channels=temb_channels,
                groups=resnet_groups, eps=resnet_eps,
                non_linearity=resnet_act_fn, pad_mode=pad_mode, rngs=rngs
            )
            resnets.append(resnet)
        self.resnets = nnx.List(resnets)
        
        # ä¸‹é‡‡æ ·å™¨ï¼ˆä½¿ç”¨ 2D Convï¼‰
        if add_downsample:
            downsampler = FlaxConv2d(
                out_channels, out_channels,
                kernel_size=3, stride=2, padding=0, rngs=rngs
            )
            self.downsamplers = nnx.List([downsampler])
            self.compress_time = compress_time
            self.downsample_padding = downsample_padding
        else:
            self.downsamplers = None
    
    def __call__(self, hidden_states, temb=None, zq=None, conv_cache=None, deterministic=True):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        # ResNet å—
        for i, resnet in enumerate(self.resnets):
            conv_cache_key = f"resnet_{i}"
            hidden_states, new_conv_cache[conv_cache_key] = resnet(
                hidden_states, temb, zq,
                conv_cache=conv_cache.get(conv_cache_key),
                deterministic=deterministic
            )
        
        # ä¸‹é‡‡æ ·ï¼ˆåŒ…å«æ—¶é—´å‹ç¼©å’Œç©ºé—´ä¸‹é‡‡æ ·ï¼‰
        if self.downsamplers is not None:
            # æ—¶é—´å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if self.compress_time:
                B, T, H, W, C = hidden_states.shape
                # ä½¿ç”¨å¹³å‡æ± åŒ–å‹ç¼©æ—¶é—´ç»´åº¦
                hidden_states = hidden_states.reshape(B * H * W, T, C)
                hidden_states = hidden_states.transpose(0, 2, 1)  # (B*H*W, C, T)
                
                if T % 2 == 1:
                    # å¥‡æ•°å¸§ï¼šä¿ç•™ç¬¬ä¸€å¸§ï¼Œå‹ç¼©å…¶ä½™å¸§
                    first_frame = hidden_states[:, :, 0:1]
                    rest_frames = hidden_states[:, :, 1:]
                    if rest_frames.shape[2] > 0:
                        rest_frames = jnp.mean(
                            rest_frames.reshape(B*H*W, C, rest_frames.shape[2]//2, 2),
                            axis=-1
                        )
                    hidden_states = jnp.concatenate([first_frame, rest_frames], axis=2)
                else:
                    # å¶æ•°å¸§ï¼šç›´æ¥å‹ç¼©
                    hidden_states = jnp.mean(
                        hidden_states.reshape(B*H*W, C, T//2, 2), axis=-1
                    )
                
                # é‡å¡‘å› 5D
                T_new = hidden_states.shape[2]
                hidden_states = hidden_states.transpose(0, 2, 1)
                hidden_states = hidden_states.reshape(B, H, W, T_new, C)
                hidden_states = hidden_states.transpose(0, 3, 1, 2, 4)  # (B, T_new, H, W, C)
            
            # ç©ºé—´ä¸‹é‡‡æ ·ï¼ˆ2Dï¼‰
            for downsampler in self.downsamplers:
                B, T, H, W, C = hidden_states.shape
                
                # æ·»åŠ æ‰‹åŠ¨å¡«å…… (0, 1, 0, 1) - PyTorch çš„é»˜è®¤è¡Œä¸º
                pad_width = [(0,0), (0,0), (0,1), (0,1), (0,0)]
                hidden_states = jnp.pad(hidden_states, pad_width, mode='constant')
                
                # é‡å¡‘ä¸º 4D åº”ç”¨ 2D å·ç§¯
                _, _, H_padded, W_padded, _ = hidden_states.shape
                hidden_states = hidden_states.reshape(B * T, H_padded, W_padded, C)
                hidden_states = downsampler(hidden_states)
                
                # é‡å¡‘å› 5D
                _, H_new, W_new, _ = hidden_states.shape
                hidden_states = hidden_states.reshape(B, T, H_new, W_new, C)
        
        return hidden_states, new_conv_cache
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **æ—¶é—´å‹ç¼©**ï¼šPyTorch ä½¿ç”¨ `CogVideoXDownsample3D`ï¼ŒFlax ç›´æ¥å®ç°å¹³å‡æ± åŒ–é€»è¾‘
2. âœ… **ç©ºé—´ä¸‹é‡‡æ ·**ï¼š
   - PyTorch: ä½¿ç”¨ `Conv3d` å¯¹ç©ºé—´ç»´åº¦ä¸‹é‡‡æ ·
   - Flax: ä½¿ç”¨ `FlaxConv2d` + reshape å®ç°ï¼ˆæ›´é«˜æ•ˆï¼‰
3. âœ… **æ‰‹åŠ¨å¡«å……**ï¼šFlax éœ€è¦æ‰‹åŠ¨æ·»åŠ  `(0, 1, 0, 1)` å¡«å……ä»¥åŒ¹é… PyTorch

#### 4.3.2 MidBlock3D ä¸­é—´å—

**PyTorch ç‰ˆæœ¬**ï¼ˆç¬¬ 444-528 è¡Œï¼‰ï¼š

```python
class CogVideoXMidBlock3D(nn.Module):
    def __init__(self, in_channels, temb_channels, dropout=0.0, num_layers=1,
                 resnet_eps=1e-6, resnet_act_fn="swish", resnet_groups=32,
                 spatial_norm_dim=None, pad_mode="first"):
        super().__init__()
        
        # åˆ›å»ºå¤šä¸ª ResNet å—
        resnets = []
        for _ in range(num_layers):
            resnets.append(
                CogVideoXResnetBlock3D(
                    in_channels=in_channels, out_channels=in_channels,
                    dropout=dropout, temb_channels=temb_channels,
                    groups=resnet_groups, eps=resnet_eps,
                    spatial_norm_dim=spatial_norm_dim,
                    non_linearity=resnet_act_fn, pad_mode=pad_mode
                )
            )
        self.resnets = nn.ModuleList(resnets)
    
    def forward(self, hidden_states, temb=None, zq=None, conv_cache=None):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        for i, resnet in enumerate(self.resnets):
            conv_cache_key = f"resnet_{i}"
            hidden_states, new_conv_cache[conv_cache_key] = resnet(
                hidden_states, temb, zq, conv_cache=conv_cache.get(conv_cache_key)
            )
        
        return hidden_states, new_conv_cache
```

**Flax ç‰ˆæœ¬**ï¼ˆç¬¬ 1116-1186 è¡Œï¼‰ï¼š

```python
class FlaxCogVideoXMidBlock3D(nnx.Module):
    def __init__(self, in_channels, temb_channels, dropout=0.0, num_layers=1,
                 resnet_eps=1e-6, resnet_act_fn="swish", resnet_groups=32,
                 spatial_norm_dim=None, pad_mode="first", rngs=None):
        resnets = []
        for i in range(num_layers):
            resnet = FlaxCogVideoXResnetBlock3D(
                in_channels=in_channels, out_channels=in_channels,
                dropout=dropout, temb_channels=temb_channels,
                groups=resnet_groups, eps=resnet_eps,
                spatial_norm_dim=spatial_norm_dim,
                non_linearity=resnet_act_fn, pad_mode=pad_mode, rngs=rngs
            )
            resnets.append(resnet)
        self.resnets = nnx.List(resnets)
    
    def __call__(self, hidden_states, temb=None, zq=None, conv_cache=None,
                 feat_cache=None, feat_idx=None, deterministic=True):
        # æ”¯æŒåŒç¼“å­˜æ¨¡å¼
        if feat_cache is not None and feat_idx is not None:
            for resnet in self.resnets:
                hidden_states, _ = resnet(
                    hidden_states, temb, zq,
                    feat_cache=feat_cache, feat_idx=feat_idx,
                    deterministic=deterministic
                )
            return hidden_states, None
        
        # æ—§æ¨¡å¼
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        for i, resnet in enumerate(self.resnets):
            conv_cache_key = f"resnet_{i}"
            hidden_states, new_conv_cache[conv_cache_key] = resnet(
                hidden_states, temb, zq,
                conv_cache=conv_cache.get(conv_cache_key),
                deterministic=deterministic
            )
        
        return hidden_states, new_conv_cache
```

**å…³é”®å·®å¼‚**ï¼š
- âœ… ç»“æ„å®Œå…¨ä¸€è‡´ï¼Œåªæ˜¯ Flax ç‰ˆæœ¬æ”¯æŒåŒç¼“å­˜æ¨¡å¼

#### 4.3.3 UpBlock3D ä¸Šé‡‡æ ·å—

**PyTorch ç‰ˆæœ¬**ï¼ˆç¬¬ 531-643 è¡Œï¼‰ï¼š

```python
class CogVideoXUpBlock3D(nn.Module):
    def __init__(self, in_channels, out_channels, temb_channels, dropout=0.0,
                 num_layers=1, resnet_eps=1e-6, resnet_act_fn="swish",
                 resnet_groups=32, spatial_norm_dim=16, add_upsample=True,
                 upsample_padding=1, compress_time=False, pad_mode="first"):
        super().__init__()
        
        # ResNet å—
        resnets = []
        for i in range(num_layers):
            in_channel = in_channels if i == 0 else out_channels
            resnets.append(
                CogVideoXResnetBlock3D(
                    in_channels=in_channel, out_channels=out_channels,
                    dropout=dropout, temb_channels=temb_channels,
                    groups=resnet_groups, eps=resnet_eps,
                    non_linearity=resnet_act_fn,
                    spatial_norm_dim=spatial_norm_dim, pad_mode=pad_mode
                )
            )
        self.resnets = nn.ModuleList(resnets)
        
        # ä¸Šé‡‡æ ·å™¨
        if add_upsample:
            self.upsamplers = nn.ModuleList([
                CogVideoXUpsample3D(
                    out_channels, out_channels,
                    padding=upsample_padding, compress_time=compress_time
                )
            ])
        else:
            self.upsamplers = None
    
    def forward(self, hidden_states, temb=None, zq=None, conv_cache=None):
        new_conv_cache = {}
        conv_cache = conv_cache or {}
        
        # ResNet å—
        for i, resnet in enumerate(self.resnets):
            conv_cache_key = f"resnet_{i}"
            hidden_states, new_conv_cache[conv_cache_key] = resnet(
                hidden_states, temb, zq, conv_cache=conv_cache.get(conv_cache_key)
            )
        
        # ä¸Šé‡‡æ ·
        if self.upsamplers is not None:
            for upsampler in self.upsamplers:
                hidden_states = upsampler(hidden_states)
        
        return hidden_states, new_conv_cache
```

**Flax ç‰ˆæœ¬**ï¼ˆç¬¬ 1189-1387 è¡Œï¼‰ï¼š

```python
class FlaxCogVideoXUpBlock3D(nnx.Module):
    def __init__(self, in_channels, out_channels, temb_channels, dropout=0.0,
                 num_layers=1, resnet_eps=1e-6, resnet_act_fn="swish",
                 resnet_groups=32, spatial_norm_dim=16, add_upsample=True,
                 upsample_padding=1, compress_time=False, pad_mode="first", rngs=None):
        # ResNet å—
        resnets = []
        for i in range(num_layers):
            in_channel = in_channels if i == 0 else out_channels
            resnet = FlaxCogVideoXResnetBlock3D(
                in_channels=in_channel, out_channels=out_channels,
                dropout=dropout, temb_channels=temb_channels,
                groups=resnet_groups, eps=resnet_eps,
                non_linearity=resnet_act_fn,
                spatial_norm_dim=spatial_norm_dim, pad_mode=pad_mode, rngs=rngs
            )
            resnets.append(resnet)
        self.resnets = nnx.List(resnets)
        
        # ä¸Šé‡‡æ ·å™¨ï¼ˆ2D Convï¼‰
        if add_upsample:
            upsampler = FlaxConv2d(
                out_channels, out_channels,
                kernel_size=3, stride=1, padding=upsample_padding, rngs=rngs
            )
            self.upsamplers = nnx.List([upsampler])
            self.compress_time = compress_time
        else:
            self.upsamplers = None
    
    def __call__(self, hidden_states, temb=None, zq=None, conv_cache=None,
                 feat_cache=None, feat_idx=None, deterministic=True):
        # æ–°æ¨¡å¼ï¼šé€å¸§è§£ç 
        if feat_cache is not None and feat_idx is not None:
            for resnet in self.resnets:
                hidden_states, _ = resnet(
                    hidden_states, temb, zq,
                    feat_cache=feat_cache, feat_idx=feat_idx,
                    deterministic=deterministic
                )
            
            if self.upsamplers is not None:
                for upsampler in self.upsamplers:
                    B, T, H, W, C = hidden_states.shape
                    
                    # compress_timeï¼šæ—¶é—´ + ç©ºé—´ä¸Šé‡‡æ ·
                    if self.compress_time:
                        if T == 1:
                            # å•å¸§ -> 2 å¸§ + 2x ç©ºé—´
                            hidden_states = jax.image.resize(
                                hidden_states, (B, 2, H * 2, W * 2, C), method='nearest'
                            )
                        elif T > 1 and T % 2 == 1:
                            # å¥‡æ•°å¸§ï¼šç‰¹æ®Šå¤„ç†
                            first_frame = hidden_states[:, 0, :, :, :]
                            rest_frames = hidden_states[:, 1:, :, :, :]
                            first_frame = jax.image.resize(
                                first_frame, (B, H * 2, W * 2, C), method='nearest'
                            )
                            first_frame = first_frame[:, None, :, :, :]
                            rest_frames = jax.image.resize(
                                rest_frames, (B, 2 * (T-1), H * 2, W * 2, C), method='nearest'
                            )
                            hidden_states = jnp.concatenate([first_frame, rest_frames], axis=1)
                        else:
                            # å¶æ•°å¸§ï¼šå¸¸è§„ä¸Šé‡‡æ ·
                            hidden_states = jax.image.resize(
                                hidden_states, (B, T * 2, H * 2, W * 2, C), method='nearest'
                            )
                    else:
                        # ä»…ç©ºé—´ä¸Šé‡‡æ ·
                        hidden_states = hidden_states.reshape(B * T, H, W, C)
                        hidden_states = jax.image.resize(
                            hidden_states, (B * T, H * 2, W * 2, C), method='nearest'
                        )
                        hidden_states = hidden_states.reshape(B, T, H * 2, W * 2, C)
                    
                    # åº”ç”¨ 2D å·ç§¯
                    B, T_new, H_new, W_new, C = hidden_states.shape
                    hidden_states = hidden_states.reshape(B * T_new, H_new, W_new, C)
                    hidden_states = upsampler(hidden_states)
                    _, H_final, W_final, _ = hidden_states.shape
                    hidden_states = hidden_states.reshape(B, T_new, H_final, W_final, C)
            
            return hidden_states, None
        
        # æ—§æ¨¡å¼ï¼šï¼ˆç±»ä¼¼ä¸Šé¢çš„é€»è¾‘ï¼Œä½†ä½¿ç”¨ conv_cacheï¼‰
        # ... (çœç•¥ï¼Œä¸ä¸Šé¢ç±»ä¼¼)
```

**å…³é”®å·®å¼‚**ï¼š
1. âœ… **ä¸Šé‡‡æ ·æ–¹æ³•**ï¼š
   - PyTorch: `F.interpolate(scale_factor=2.0)` 
   - Flax: `jax.image.resize(..., method='nearest')` + æ‰‹åŠ¨è®¡ç®—å°ºå¯¸
2. âœ… **æ—¶é—´ä¸Šé‡‡æ ·**ï¼š
   - `compress_time=True`: æ—¶é—´ç»´åº¦ Ã— 2ï¼Œç©ºé—´ç»´åº¦ Ã— 2
   - `compress_time=False`: ä»…ç©ºé—´ç»´åº¦ Ã— 2
3. âœ… **å¥‡æ•°å¸§å¤„ç†**ï¼šå®Œå…¨å¤åˆ¶ PyTorch çš„é€»è¾‘

---

## 5. ä¸» VAE ç±»è¿ç§»

### 5.1 é…ç½®ç±»

**PyTorch ç‰ˆæœ¬**ï¼šä½¿ç”¨ `@register_to_config` è£…é¥°å™¨

```python
@register_to_config
def __init__(
    self,
    in_channels: int = 3,
    out_channels: int = 3,
    # ... æ›´å¤šå‚æ•°
):
    super().__init__()
    # é…ç½®è‡ªåŠ¨å­˜å‚¨åœ¨ self.config
```

**Flax ç‰ˆæœ¬**ï¼šä½¿ç”¨ `@dataclass`

```python
@dataclass
class FlaxAutoencoderKLCogVideoXConfig:
    in_channels: int = 3
    out_channels: int = 3
    # ... æ›´å¤šå‚æ•°
    
    @classmethod
    def from_dict(cls, config_dict: Dict):
        """ä»å­—å…¸åˆ›å»ºé…ç½®"""
        field_names = {f.name for f in dataclasses.fields(cls)}
        filtered_dict = {k: v for k, v in config_dict.items() if k in field_names}
        return cls(**filtered_dict)
```

**å…³é”®å·®å¼‚**ï¼š
- PyTorch: é…ç½®å’Œæ¨¡å‹åˆå¹¶åœ¨ä¸€ä¸ªç±»
- Flax: é…ç½®å’Œæ¨¡å‹åˆ†ç¦»ï¼ˆæ›´æ¸…æ™°ï¼‰

### 5.2 æƒé‡åŠ è½½ï¼šfrom_pretrained

è¿™æ˜¯æœ€å¤æ‚çš„éƒ¨åˆ†ï¼Œéœ€è¦å°† PyTorch æƒé‡è½¬æ¢ä¸º JAX æ ¼å¼ã€‚

**Flax å®ç°**ï¼ˆç¬¬ 2265-2433 è¡Œï¼‰ï¼š

```python
@classmethod
def from_pretrained(cls, pretrained_model_name_or_path, subfolder="vae", dtype=jnp.float32):
    from huggingface_hub import hf_hub_download
    from safetensors import safe_open
    
    # 1. ä¸‹è½½é…ç½®
    config_path = hf_hub_download(pretrained_model_name_or_path, subfolder=subfolder, filename="config.json")
    with open(config_path, 'r') as f:
        config_dict = json.load(f)
    config = cls.config_class.from_dict(config_dict)
    
    # 2. ä¸‹è½½ PyTorch æƒé‡
    ckpt_path = hf_hub_download(
        pretrained_model_name_or_path, subfolder=subfolder,
        filename="diffusion_pytorch_model.safetensors"
    )
    
    # 3. åŠ è½½ PyTorch æƒé‡
    pytorch_weights = {}
    with safe_open(ckpt_path, framework="np") as f:
        for key in f.keys():
            pytorch_weights[key] = f.get_tensor(key)
    
    # 4. è½¬æ¢æƒé‡æ ¼å¼
    jax_weights = {}
    for pt_key, pt_tensor in pytorch_weights.items():
        jax_key = pt_key
        jax_tensor = pt_tensor
        
        # ç§»é™¤ _orig_mod å‰ç¼€
        if jax_key.startswith("_orig_mod."):
            jax_key = jax_key[len("_orig_mod."):]
        
        # è½¬æ¢å·ç§¯æƒé‡ï¼šPyTorch (O,I,T,H,W) -> JAX (T,H,W,I,O)
        if "conv" in jax_key and "weight" in jax_key:
            jax_key = jax_key.replace(".weight", ".kernel")
            
            if len(jax_tensor.shape) == 5:  # 3D conv
                jax_tensor = jax_tensor.transpose(2, 3, 4, 1, 0)
            elif len(jax_tensor.shape) == 4:  # 2D conv
                jax_tensor = jax_tensor.transpose(2, 3, 1, 0)
        
        # è½¬æ¢å½’ä¸€åŒ–æƒé‡
        if ".weight" in jax_key and "norm" in jax_key:
            jax_key = jax_key.replace(".weight", ".scale")
        
        # æ·»åŠ  .conv è·¯å¾„ï¼ˆFlaxConv3d åŒ…è£…ï¼‰
        if needs_conv_wrapper(jax_key):
            parts = jax_key.rsplit('.', 1)
            jax_key = f"{parts[0]}.conv.{parts[1]}"
        
        jax_weights[jax_key] = jnp.array(jax_tensor, dtype=dtype)
    
    # 5. åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    model = cls(config=config, rngs=nnx.Rngs(jax.random.key(0)), dtype=dtype)
    
    # ä½¿ç”¨ NNX çš„æƒé‡åŠ è½½æœºåˆ¶
    from flax.traverse_util import unflatten_dict
    nested_weights = unflatten_dict(jax_weights, sep=".")
    graphdef, _ = nnx.split(model)
    model = nnx.merge(graphdef, nested_weights)
    
    return model
```

**æƒé‡è½¬æ¢è§„åˆ™**ï¼š

| PyTorch | JAX | è¯´æ˜ |
|---------|-----|------|
| `Conv3d.weight` (O,I,T,H,W) | `Conv.kernel` (T,H,W,I,O) | 5D å·ç§¯ |
| `Conv2d.weight` (O,I,H,W) | `Conv.kernel` (H,W,I,O) | 2D å·ç§¯ |
| `GroupNorm.weight` | `GroupNorm.scale` | å½’ä¸€åŒ–ç¼©æ”¾ |
| `Linear.weight` (O,I) | `Linear.kernel` (I,O) | å…¨è¿æ¥å±‚ |

---

## 6. é«˜çº§åŠŸèƒ½è¿ç§»

### 6.1 Tilingï¼ˆåˆ†å—å¤„ç†ï¼‰

Tiling ç”¨äºå¤„ç†å¤§åˆ†è¾¨ç‡è§†é¢‘ï¼Œé¿å… OOMã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼š
1. å°†è§†é¢‘åˆ†å‰²æˆé‡å çš„ç©ºé—´å—ï¼ˆtilesï¼‰
2. ç‹¬ç«‹å¤„ç†æ¯ä¸ªå—
3. èåˆï¼ˆblendï¼‰é‡å åŒºåŸŸ

**PyTorch å®ç°**ï¼ˆç¬¬ 1250-1322 è¡Œï¼‰ï¼š

```python
def tiled_encode(self, x):
    batch_size, num_channels, num_frames, height, width = x.shape
    
    # è®¡ç®— tile å‚æ•°
    overlap_height = int(self.tile_sample_min_height * (1 - self.tile_overlap_factor_height))
    overlap_width = int(self.tile_sample_min_width * (1 - self.tile_overlap_factor_width))
    blend_extent_height = int(self.tile_latent_min_height * self.tile_overlap_factor_height)
    blend_extent_width = int(self.tile_latent_min_width * self.tile_overlap_factor_width)
    
    # åˆ†å—å¤„ç†
    rows = []
    for i in range(0, height, overlap_height):
        row = []
        for j in range(0, width, overlap_width):
            # æå– tile
            tile = x[:, :, :, i:i+self.tile_sample_min_height, j:j+self.tile_sample_min_width]
            
            # ç¼–ç  tile
            tile_encoded = self.encoder(tile)
            row.append(tile_encoded)
        rows.append(row)
    
    # èåˆ tiles
    result_rows = []
    for i, row in enumerate(rows):
        result_row = []
        for j, tile in enumerate(row):
            if i > 0:
                tile = self.blend_v(rows[i-1][j], tile, blend_extent_height)
            if j > 0:
                tile = self.blend_h(row[j-1], tile, blend_extent_width)
            result_row.append(tile[:, :, :, :row_limit_height, :row_limit_width])
        result_rows.append(torch.cat(result_row, dim=4))
    
    return torch.cat(result_rows, dim=3)
```

**Flax å®ç°**ï¼ˆç¬¬ 2088-2154 è¡Œï¼‰ï¼š

```python
def tiled_encode(self, x, deterministic=True):
    # å®Œå…¨ç›¸åŒçš„é€»è¾‘ï¼Œåªæ˜¯æ•°æ®æ ¼å¼ä¸åŒ
    batch_size, num_frames, height, width, num_channels = x.shape
    
    # ... (è®¡ç®— tile å‚æ•°ï¼ŒåŒ PyTorch)
    
    # åˆ†å—å¤„ç†
    rows = []
    for i in range(0, height, overlap_height):
        row = []
        for j in range(0, width, overlap_width):
            tile = x[:, :, i:i+self.tile_sample_min_height, j:j+self.tile_sample_min_width, :]
            tile_encoded = self.encoder(tile, deterministic=deterministic)
            row.append(tile_encoded)
        rows.append(row)
    
    # èåˆï¼ˆblend_v å’Œ blend_h å®Œå…¨ç›¸åŒï¼‰
    # ...
    
    return jnp.concatenate(result_rows, axis=2)
```

**å…³é”®å·®å¼‚**ï¼š
- âœ… ç®—æ³•å®Œå…¨ç›¸åŒ
- âœ… ä»…æ•°æ®æ ¼å¼ä¸åŒï¼ˆBCTHW vs BTHWCï¼‰

### 6.2 Frame Batchingï¼ˆå¸§æ‰¹å¤„ç†ï¼‰

ç”¨äºç¼–ç /è§£ç é•¿è§†é¢‘ï¼Œé¿å…ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰å¸§ã€‚

**PyTorch å®ç°**ï¼ˆencode æ—¶ï¼‰ï¼š

```python
def _encode(self, x):
    frame_batch_size = self.num_sample_frames_batch_size  # 8
    num_batches = max(num_frames // frame_batch_size, 1)
    conv_cache = None
    enc = []
    
    for i in range(num_batches):
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„å¸§èŒƒå›´
        remaining_frames = num_frames % frame_batch_size
        start_frame = frame_batch_size * i + (0 if i == 0 else remaining_frames)
        end_frame = frame_batch_size * (i + 1) + remaining_frames
        
        # æå–å¸§æ‰¹æ¬¡
        x_intermediate = x[:, :, start_frame:end_frame]
        
        # ç¼–ç ï¼ˆæºå¸¦ conv_cacheï¼‰
        x_intermediate, conv_cache = self.encoder(x_intermediate, conv_cache=conv_cache)
        enc.append(x_intermediate)
    
    return torch.cat(enc, dim=2)
```

**Flax å®ç°**ï¼ˆå®Œå…¨ç›¸åŒï¼‰ï¼š

```python
def _encode(self, x, deterministic=True):
    frame_batch_size = self.num_sample_frames_batch_size  # 8
    num_batches = max(num_frames // frame_batch_size, 1)
    conv_cache = None
    enc = []
    
    for i in range(num_batches):
        # ... (åŒ PyTorch)
        x_intermediate = x[:, start_frame:end_frame, :, :, :]
        x_intermediate, conv_cache = self.encoder(
            x_intermediate, conv_cache=conv_cache, deterministic=deterministic
        )
        enc.append(x_intermediate)
    
    return jnp.concatenate(enc, axis=1)
```

### 6.3 é€å¸§è§£ç ï¼ˆFrame-by-Frame Decodingï¼‰

è¿™æ˜¯ Flax ç‰ˆæœ¬çš„**é‡è¦åˆ›æ–°**ï¼Œç”¨äºè§£å†³è§£ç æ—¶çš„ OOM é—®é¢˜ã€‚

**é—®é¢˜**ï¼š
- PyTorch ç‰ˆæœ¬ï¼šæ¯æ‰¹å¤„ç† 2 å¸§æ½œåœ¨è¡¨ç¤º â†’ 8 å¸§è§†é¢‘
- å†…å­˜éœ€æ±‚ï¼š~40GBï¼ˆè¶…è¿‡ TPU v6e çš„ 32GB é™åˆ¶ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
- Flax ç‰ˆæœ¬ï¼šæ¯æ‰¹å¤„ç† **1 å¸§**æ½œåœ¨è¡¨ç¤º â†’ 4 å¸§è§†é¢‘
- ä½¿ç”¨ `FlaxCogVideoXCache` ç®¡ç†æ‰€æœ‰ CausalConv3d å±‚çš„ç¼“å­˜

**å®ç°**ï¼ˆç¬¬ 1955-2069 è¡Œï¼‰ï¼š

```python
def _decode(self, z, zq, deterministic=True):
    batch_size, num_frames, height, width, num_channels = z.shape
    
    # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
    feat_cache_manager = FlaxCogVideoXCache(self.decoder)
    
    # åº”ç”¨ post_quant_convï¼ˆæ•´ä½“ï¼‰
    if self.post_quant_conv is not None:
        z = self.post_quant_conv(z)
    
    # é€å¸§è§£ç 
    decoded_frames_list = []
    
    for i in range(num_frames):
        # æ¯å¸§é‡ç½®ç´¢å¼•ï¼ˆä¸æ¸…ç©ºç¼“å­˜ï¼‰
        feat_cache_manager._conv_idx = [0]
        
        # æå–å½“å‰å¸§
        z_frame = z[:, i:i+1, :, :, :]
        zq_frame = zq[:, i:i+1, :, :, :]
        
        # è§£ç ï¼ˆä½¿ç”¨å…±äº«ç¼“å­˜ï¼‰
        decoded_frame, _ = self.decoder(
            z_frame, zq_frame,
            feat_cache=feat_cache_manager._feat_map,
            feat_idx=feat_cache_manager._conv_idx,
            deterministic=deterministic
        )
        
        decoded_frames_list.append(decoded_frame)
    
    # æ‹¼æ¥æ‰€æœ‰å¸§
    decoded = jnp.concatenate(decoded_frames_list, axis=1)
    
    return decoded
```

**ç¼“å­˜ç®¡ç†**ï¼ˆç¬¬ 1704-1746 è¡Œï¼‰ï¼š

```python
class FlaxCogVideoXCache:
    def __init__(self, decoder_module):
        self.decoder_module = decoder_module
        self.clear_cache()
    
    def clear_cache(self):
        # è®¡ç®— decoder ä¸­çš„ CausalConv3d å±‚æ•°é‡
        self._conv_num = self._count_causal_conv3d(self.decoder_module)
        self._conv_idx = [0]  # å½“å‰ç´¢å¼•
        self._feat_map = [None] * self._conv_num  # ç¼“å­˜åˆ—è¡¨
    
    @staticmethod
    def _count_causal_conv3d(module):
        count = 0
        node_types = nnx.graph.iter_graph([module])
        for _, value in node_types:
            if isinstance(value, FlaxCogVideoXCausalConv3d):
                count += 1
        return count
```

**ä¼˜åŠ¿**ï¼š
- âœ… å†…å­˜å ç”¨å‡åŠï¼ˆ1 å¸§ vs 2 å¸§ï¼‰
- âœ… æ”¯æŒä»»æ„é•¿åº¦çš„è§†é¢‘
- âœ… ç¼“å­˜åœ¨å¸§é—´å…±äº«ï¼Œä¿æŒæ—¶åºè¿ç»­æ€§

---

## 7. å…³é”®å·®å¼‚æ€»ç»“

### 7.1 æ•°æ®æ ¼å¼

| ç»´åº¦ | PyTorch | JAX/Flax | è½¬æ¢ |
|------|---------|----------|------|
| è§†é¢‘ | (B, C, T, H, W) | (B, T, H, W, C) | `x.transpose(0, 2, 3, 4, 1)` |
| å›¾åƒ | (B, C, H, W) | (B, H, W, C) | `x.transpose(0, 2, 3, 1)` |
| æ—¶é—´åµŒå…¥ | (B, C, 1, 1, 1) | (B, 1, 1, 1, C) | å¹¿æ’­ç»´åº¦ä¸åŒ |

### 7.2 å·ç§¯æƒé‡

| ç±»å‹ | PyTorch Shape | JAX Shape | è½¬æ¢ä»£ç  |
|------|---------------|-----------|----------|
| Conv3d | (O, I, T, H, W) | (T, H, W, I, O) | `w.transpose(2,3,4,1,0)` |
| Conv2d | (O, I, H, W) | (H, W, I, O) | `w.transpose(2,3,1,0)` |
| Linear | (O, I) | (I, O) | `w.transpose(1,0)` |

### 7.3 API å·®å¼‚

| åŠŸèƒ½ | PyTorch | JAX/Flax |
|------|---------|----------|
| æ¿€æ´»å‡½æ•° | `F.silu(x)` | `jax.nn.silu(x)` |
| æ’å€¼ | `F.interpolate(x, scale_factor=2)` | `jax.image.resize(x, new_shape, method='nearest')` |
| Padding | `F.pad(x, (w,w,h,h,t,0), mode='replicate')` | `jnp.pad(x, [(0,0),(t,0),(h,h),(w,w),(0,0)], mode='edge')` |
| Concatenate | `torch.cat([a, b], dim=2)` | `jnp.concatenate([a, b], axis=1)` |
| Dropout | `nn.Dropout(rate)` | `nnx.Dropout(rate=rate)` + `deterministic` å‚æ•° |

### 7.4 å†…å­˜ä¼˜åŒ–ç­–ç•¥

| ç­–ç•¥ | PyTorch | Flax |
|------|---------|------|
| ç¼–ç æ‰¹å¤§å° | 8 å¸§/æ‰¹ | 8 å¸§/æ‰¹ âœ… |
| è§£ç æ‰¹å¤§å° | 2 å¸§/æ‰¹ | **1 å¸§/æ‰¹** âš ï¸ |
| ç¼“å­˜æœºåˆ¶ | `conv_cache` å­—å…¸ | `feat_cache` åˆ—è¡¨ + `feat_idx` ç´¢å¼• |
| åˆ†å—å¤„ç† | `CogVideoXSafeConv3d` | ä¾èµ– XLA è‡ªåŠ¨ä¼˜åŒ– |
| Tiling | âœ… æ”¯æŒ | âœ… æ”¯æŒ |

### 7.5 æ¨¡å‹ç»“æ„å¯¹æ¯”

| ç»„ä»¶ | PyTorch ç±» | Flax ç±» | ä¸»è¦å·®å¼‚ |
|------|------------|---------|----------|
| åŸºç¡€å·ç§¯ | `nn.Conv3d` | `nnx.Conv` | æ•°æ®æ ¼å¼ã€padding æ ¼å¼ |
| å› æœå·ç§¯ | `CogVideoXCausalConv3d` | `FlaxCogVideoXCausalConv3d` | åŒç¼“å­˜æ¨¡å¼ |
| ç»„å½’ä¸€åŒ– | `nn.GroupNorm` | `FlaxGroupNorm` | Channel-last è®¡ç®— |
| ç©ºé—´å½’ä¸€åŒ– | `CogVideoXSpatialNorm3D` | `FlaxCogVideoXSpatialNorm3D` | æ’å€¼æ–¹æ³• |
| ResNet å— | `CogVideoXResnetBlock3D` | `FlaxCogVideoXResnetBlock3D` | Dropout æ§åˆ¶ |
| ç¼–ç å™¨ | `CogVideoXEncoder3D` | `FlaxCogVideoXEncoder3D` | å®Œå…¨ä¸€è‡´ |
| è§£ç å™¨ | `CogVideoXDecoder3D` | `FlaxCogVideoXDecoder3D` | é€å¸§è§£ç  |
| ä¸» VAE | `AutoencoderKLCogVideoX` | `FlaxAutoencoderKLCogVideoX` | é…ç½®åˆ†ç¦»ã€æƒé‡è½¬æ¢ |

---

## 8. æ€»ç»“

### 8.1 è¿ç§»è¦ç‚¹

1. **æ•°æ®æ ¼å¼è½¬æ¢**ï¼šæ‰€æœ‰è¾“å…¥/è¾“å‡ºä» `BCTHW` è½¬ä¸º `BTHWC`
2. **æƒé‡è½¬æ¢**ï¼šå·ç§¯æ ¸ä» `(O,I,...)` è½¬ä¸º `(...,I,O)`
3. **API é€‚é…**ï¼šPyTorch â†’ JAX/NNX çš„å‡½æ•°æ˜ å°„
4. **ç¼“å­˜æœºåˆ¶**ï¼šæ”¯æŒåŒæ¨¡å¼ï¼ˆå‘åå…¼å®¹ + æ–°çš„é€å¸§è§£ç ï¼‰
5. **å†…å­˜ä¼˜åŒ–**ï¼šè§£ç æ—¶æ¯æ‰¹ 1 å¸§ï¼ˆè€Œé 2 å¸§ï¼‰

### 8.2 æ€§èƒ½ä¼˜åŒ–

- âœ… ä½¿ç”¨ `jax.image.resize` ä»£æ›¿ `F.interpolate`
- âœ… GroupNorm ç›´æ¥åœ¨ channel-last æ ¼å¼è®¡ç®—ï¼ˆé¿å…è½¬ç½®ï¼‰
- âœ… é€å¸§è§£ç é¿å… OOM
- âœ… ä¾èµ– XLA ç¼–è¯‘å™¨ä¼˜åŒ–å†…å­˜åˆ†é…

### 8.3 åŠŸèƒ½å®Œæ•´æ€§

| åŠŸèƒ½ | PyTorch | Flax | çŠ¶æ€ |
|------|---------|------|------|
| Encode | âœ… | âœ… | å®Œå…¨ä¸€è‡´ |
| Decode | âœ… | âœ… | æ›´ä¼˜ï¼ˆé€å¸§ï¼‰ |
| Tiling | âœ… | âœ… | å®Œå…¨ä¸€è‡´ |
| Frame Batching | âœ… | âœ… | å®Œå…¨ä¸€è‡´ |
| from_pretrained | âœ… | âœ… | è‡ªåŠ¨è½¬æ¢æƒé‡ |
| Gradient Checkpointing | âœ… | âŒ | æœªå®ç° |

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2025-11-06  
**ä½œè€…**ï¼šBased on CogVideoX PyTorch and Flax implementations
