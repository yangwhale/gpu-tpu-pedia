# DeepCache åŸç†è¯¦è§£ï¼šä» GPU åˆ° TPU çš„å®ç°ä¹‹è·¯

æœ¬æ–‡æ¡£ç³»ç»Ÿæ€§åœ°è®²è§£ DeepCache çš„åŸç†ã€è®¾è®¡ç†å¿µï¼Œä»¥åŠå¦‚ä½•åœ¨ TPU/torchax ç¯å¢ƒä¸‹ä»é›¶å®ç°ã€‚

---

## ğŸ“š ç›®å½•

1. [DeepCache æ˜¯ä»€ä¹ˆ](#1-deepcache-æ˜¯ä»€ä¹ˆ)
2. [åŸç†ä¸è®¾è®¡ç†å¿µ](#2-åŸç†ä¸è®¾è®¡ç†å¿µ)
3. [GPU ç‰ˆæœ¬å®ç°åˆ†æ](#3-gpu-ç‰ˆæœ¬å®ç°åˆ†æ)
4. [ä¾èµ–åº“åˆ†æ](#4-ä¾èµ–åº“åˆ†æ)
5. [ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨](#5-ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨)
6. [TPU ç‰ˆæœ¬å®ç°](#6-tpu-ç‰ˆæœ¬å®ç°)
7. [æ€§èƒ½å¯¹æ¯”](#7-æ€§èƒ½å¯¹æ¯”)

---

## 1. DeepCache æ˜¯ä»€ä¹ˆ

### 1.1 èƒŒæ™¯é—®é¢˜

Diffusion æ¨¡å‹æ¨ç†éœ€è¦å¤šæ¬¡è¿­ä»£ï¼ˆé€šå¸¸ 20-50 æ­¥ï¼‰ï¼Œæ¯æ­¥éƒ½è¦å®Œæ•´æ‰§è¡Œ Transformer å‰å‘ä¼ æ’­ï¼Œè®¡ç®—é‡å·¨å¤§ã€‚

```mermaid
flowchart LR
    subgraph æ ‡å‡†æ¨ç†
        A[Step 1] --> B[Step 2]
        B --> C[Step 3]
        C --> D[...]
        D --> E[Step N]
    end
    
    F[æ¯æ­¥éƒ½å®Œæ•´æ‰§è¡Œ<br/>æ‰€æœ‰ Transformer å±‚] --> G[è®¡ç®—é‡ = N Ã— å…¨éƒ¨å±‚]
    
    style F fill:#ffcccc
```

### 1.2 æ ¸å¿ƒè§‚å¯Ÿ

DeepCache è®ºæ–‡å‘ç°ï¼š**ç›¸é‚»å»å™ªæ­¥éª¤çš„é«˜å±‚ç‰¹å¾å˜åŒ–å¾ˆå°**ã€‚

```mermaid
flowchart TB
    subgraph ç‰¹å¾å˜åŒ–åˆ†æ
        direction LR
        A["Step t"] --> B["Step t+1"]
        
        subgraph StepT["Step t ç‰¹å¾"]
            T1[æµ…å±‚ç‰¹å¾<br/>å˜åŒ–å¤§]
            T2[æ·±å±‚ç‰¹å¾<br/>å˜åŒ–å°]
        end
        
        subgraph StepT1["Step t+1 ç‰¹å¾"]
            T3[æµ…å±‚ç‰¹å¾<br/>å˜åŒ–å¤§]
            T4[æ·±å±‚ç‰¹å¾<br/>â‰ˆ Step t]
        end
        
        T1 -.-> T3
        T2 ==> T4
    end
    
    style T2 fill:#ccffcc
    style T4 fill:#ccffcc
```

### 1.3 DeepCache æ€æƒ³

æ—¢ç„¶æ·±å±‚ç‰¹å¾å˜åŒ–å°ï¼Œå¯ä»¥**ç¼“å­˜å¹¶å¤ç”¨**ï¼Œåªè®¡ç®—æµ…å±‚ï¼š

```mermaid
flowchart TB
    subgraph DeepCacheç­–ç•¥
        direction TB
        
        S1["Step 1: å®Œæ•´è®¡ç®— â†’ ç¼“å­˜æ·±å±‚ç‰¹å¾"]
        S2["Step 2: å¤ç”¨ç¼“å­˜ â†’ åªç®—æµ…å±‚"]
        S3["Step 3: å¤ç”¨ç¼“å­˜ â†’ åªç®—æµ…å±‚"]
        S4["Step 4: åˆ·æ–°ç¼“å­˜ â†’ å®Œæ•´è®¡ç®—"]
        S5["Step 5: å¤ç”¨ç¼“å­˜ â†’ åªç®—æµ…å±‚"]
        
        S1 --> S2 --> S3 --> S4 --> S5
    end
    
    S1 -.- |"å®Œæ•´è®¡ç®—"| Full
    S2 -.- |"ç¼“å­˜åŠ é€Ÿ"| Cache
    S3 -.- |"ç¼“å­˜åŠ é€Ÿ"| Cache
    S4 -.- |"åˆ·æ–°ç¼“å­˜"| Full
    
    style S2 fill:#ccffcc
    style S3 fill:#ccffcc
    style S5 fill:#ccffcc
```

---

## 2. åŸç†ä¸è®¾è®¡ç†å¿µ

### 2.1 HunyuanVideo Transformer ç»“æ„

```mermaid
flowchart TB
    subgraph HunyuanVideo["HunyuanVideo Transformer"]
        direction TB
        
        Input[Hidden States] --> DB1
        
        subgraph DoubleBlocks["Double Blocks (20å±‚)"]
            DB1[Double Block 1] --> DB2[Double Block 2]
            DB2 --> DB3[...]
            DB3 --> DB20[Double Block 20]
        end
        
        DB20 --> SB1
        
        subgraph SingleBlocks["Single Blocks (40å±‚)"]
            SB1[Single Block 1] --> SB2[Single Block 2]
            SB2 --> SB3[...]
            SB3 --> SB40[Single Block 40]
        end
        
        SB40 --> FL[Final Layer]
        FL --> Output[Noise Prediction]
    end
    
    style DoubleBlocks fill:#ffcccc
    style SingleBlocks fill:#ccffcc
```

### 2.2 ç¼“å­˜ç­–ç•¥

**ç¼“å­˜ç‚¹é€‰æ‹©**ï¼šDouble Blocks ä¹‹åã€Single Blocks ä¹‹å‰

```mermaid
flowchart LR
    subgraph å®Œæ•´Forward
        A[Input] --> B[Double Blocks<br/>20å±‚]
        B --> C["ç¼“å­˜ç‚¹<br/>(img, txt)"]
        C --> D[Single Blocks<br/>40å±‚]
        D --> E[Final Layer]
        E --> F[Output]
    end
    
    subgraph ç¼“å­˜Forward
        A2[Input] --> C2["ä½¿ç”¨ç¼“å­˜<br/>(img, txt)"]
        C2 --> D2[Single Blocks<br/>40å±‚]
        D2 --> E2[Final Layer]
        E2 --> F2[Output]
    end
    
    style B fill:#ffcccc
    style C fill:#ffffcc
    style C2 fill:#ffffcc
```

### 2.3 ç†è®ºåŠ é€Ÿæ¯”

| è·¯å¾„ | è®¡ç®—å±‚æ•° | å æ¯” |
|------|----------|------|
| å®Œæ•´ Forward | 20 + 40 + 1 = 61 | 100% |
| ç¼“å­˜ Forward | 0 + 40 + 1 = 41 | 67% |

**ç†è®ºåŠ é€Ÿæ¯”**ï¼š61/41 â‰ˆ **1.49x**

### 2.4 ç¼“å­˜åˆ·æ–°ç­–ç•¥

ä¸èƒ½æ°¸è¿œä½¿ç”¨æ—§ç¼“å­˜ï¼Œéœ€è¦å‘¨æœŸæ€§åˆ·æ–°ï¼š

```mermaid
flowchart LR
    subgraph åˆ·æ–°ç­–ç•¥
        direction TB
        
        P1["å‰æœŸ (Step 0-10)"]
        P2["ä¸­æœŸ (Step 11-44)"]
        P3["åæœŸ (Step 45-49)"]
        
        P1 --> |"æ¯æ­¥å®Œæ•´è®¡ç®—<br/>ç‰¹å¾å˜åŒ–å¤§"| N1[ä¸ç¼“å­˜]
        P2 --> |"æ¯4æ­¥åˆ·æ–°ä¸€æ¬¡<br/>ç‰¹å¾ç¨³å®š"| N2[ç¼“å­˜+åˆ·æ–°]
        P3 --> |"æ¯æ­¥å®Œæ•´è®¡ç®—<br/>ç»†èŠ‚é‡è¦"| N3[ä¸ç¼“å­˜]
    end
    
    style N1 fill:#ffcccc
    style N2 fill:#ccffcc
    style N3 fill:#ffcccc
```

**å‚æ•°é…ç½®**ï¼š
- `cache_start_step = 11`ï¼šå¼€å§‹ç¼“å­˜çš„æ­¥æ•°
- `cache_end_step = 45`ï¼šåœæ­¢ç¼“å­˜çš„æ­¥æ•°
- `cache_step_interval = 4`ï¼šåˆ·æ–°é—´éš”

---

## 3. GPU ç‰ˆæœ¬å®ç°åˆ†æ

### 3.1 å…¸å‹ GPU DeepCache æ¶æ„

```mermaid
flowchart TB
    subgraph GPU_DeepCache["GPU DeepCache å®ç°"]
        direction TB
        
        A[angelslim åº“] --> B[infer_state ç¼“å­˜ç®¡ç†]
        C[diffusers Pipeline] --> D[register_cache / update_cache]
        
        B --> E{jax.lax.cond é£æ ¼}
        D --> E
        
        E --> |"condition=True"| F[å®Œæ•´ Forward]
        E --> |"condition=False"| G[ç¼“å­˜ Forward]
        
        F --> H[æ›´æ–°ç¼“å­˜]
        G --> I[ä½¿ç”¨ç¼“å­˜]
    end
```

### 3.2 æ ¸å¿ƒæ•°æ®ç»“æ„

```python
# GPU ç‰ˆæœ¬çš„ infer_state
class InferState:
    def __init__(self):
        self.cached_features = {}      # å±‚ç¼“å­˜
        self.step_index = 0            # å½“å‰æ­¥æ•°
        self.no_cache_steps = set()    # ä¸ä½¿ç”¨ç¼“å­˜çš„æ­¥
        
    def should_cache(self, step):
        return step not in self.no_cache_steps
    
    def get_cache(self, layer_name):
        return self.cached_features.get(layer_name)
    
    def set_cache(self, layer_name, features):
        self.cached_features[layer_name] = features
```

### 3.3 Transformer å±‚å†…çš„æ¡ä»¶åˆ†æ”¯

```python
# GPU ç‰ˆæœ¬åœ¨å±‚å†…åšæ¡ä»¶åˆ†æ”¯
class DoubleBlock(nn.Module):
    def forward(self, x, infer_state=None):
        if infer_state and infer_state.should_use_cache(self.layer_idx):
            # ä½¿ç”¨ç¼“å­˜ï¼Œè·³è¿‡è®¡ç®—
            return infer_state.get_cache(self.layer_idx)
        else:
            # æ­£å¸¸è®¡ç®—
            output = self._forward_impl(x)
            if infer_state:
                infer_state.set_cache(self.layer_idx, output)
            return output
```

---

## 4. ä¾èµ–åº“åˆ†æ

### 4.1 angelslim åº“

```mermaid
flowchart TB
    subgraph angelslim["angelslim åº“åŠŸèƒ½"]
        direction TB
        
        A1[CacheManager] --> A2[ç®¡ç†å±‚çº§ç¼“å­˜]
        A1 --> A3[è‡ªåŠ¨ç¼“å­˜æ›´æ–°]
        A1 --> A4[å†…å­˜ä¼˜åŒ–]
        
        B1[InferState] --> B2[çŠ¶æ€è¿½è¸ª]
        B1 --> B3[æ­¥æ•°ç®¡ç†]
        B1 --> B4[æ¡ä»¶åˆ¤æ–­]
        
        C1[PipelineIntegration] --> C2[diffusers é›†æˆ]
        C1 --> C3[è‡ªåŠ¨ hook æ³¨å…¥]
    end
```

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- è‡ªåŠ¨ç®¡ç†å¤šå±‚ç¼“å­˜çš„ç”Ÿå‘½å‘¨æœŸ
- ä¸ diffusers Pipeline æ·±åº¦é›†æˆ
- æä¾›ç®€æ´çš„ API

### 4.2 ä¾èµ–çš„ PyTorch ç‰¹æ€§

```mermaid
flowchart LR
    subgraph PyTorchç‰¹æ€§
        A[torch.compile] --> A1[å›¾æ¨¡å¼ç¼–è¯‘]
        B[åŠ¨æ€æ¡ä»¶åˆ†æ”¯] --> B1[if/else åœ¨è¿è¡Œæ—¶]
        C[in-place æ“ä½œ] --> C1[ç¼“å­˜åŸåœ°æ›´æ–°]
        D[CUDA å†…å­˜ç®¡ç†] --> D1[è‡ªåŠ¨æ˜¾å­˜å›æ”¶]
    end
```

---

## 5. ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨

### 5.1 torchax é™åˆ¶

```mermaid
flowchart TB
    subgraph é™åˆ¶["torchax/JAX é™åˆ¶"]
        direction TB
        
        L1["âŒ åŠ¨æ€æ¡ä»¶åˆ†æ”¯"]
        L2["âŒ è¿è¡Œæ—¶ if/else"]
        L3["âŒ å¯å˜çŠ¶æ€"]
        L4["âŒ å¸ƒå°”ç´¢å¼•"]
        L5["âŒ ConcretizationTypeError"]
    end
    
    subgraph åŸå› ["åŸå› "]
        R1["XLA éœ€è¦é™æ€è®¡ç®—å›¾"]
        R2["JIT ç¼–è¯‘æ—¶éœ€ç¡®å®šæ‰€æœ‰è·¯å¾„"]
        R3["çº¯å‡½æ•°å¼ç¼–ç¨‹æ¨¡å‹"]
    end
    
    L1 --> R1
    L2 --> R2
    L3 --> R3
```

### 5.2 jax.lax.cond çš„é—®é¢˜

GPU ç‰ˆæœ¬ä½¿ç”¨ç±»ä¼¼ `jax.lax.cond` çš„æ¨¡å¼ï¼Œä½†åœ¨ torchax ä¸­ï¼š

```mermaid
flowchart TB
    subgraph jax_condé—®é¢˜["jax.lax.cond åœ¨ torchax ä¸­çš„é—®é¢˜"]
        direction TB
        
        P1["é—®é¢˜1: PyTree ç»“æ„å¿…é¡»åŒ¹é…"]
        P2["é—®é¢˜2: torchax tensor wrapper ä¸é€æ˜"]
        P3["é—®é¢˜3: JAX tracer æ³„æ¼"]
        P4["é—®é¢˜4: è¿”å›å€¼ç»“æ„ä¸ä¸€è‡´"]
        
        P1 --> E1["ä¸¤ä¸ªåˆ†æ”¯è¿”å›ä¸åŒæ•°é‡çš„ tensor"]
        P2 --> E2["æ— æ³•ç›´æ¥æ¯”è¾ƒ PyTree ç»“æ„"]
        P3 --> E3["traced value é€ƒé€¸å‡º JIT èŒƒå›´"]
        P4 --> E4["ç¼–è¯‘å¤±è´¥æˆ–è¿è¡Œæ—¶é”™è¯¯"]
    end
```

### 5.3 å¤±è´¥çš„å°è¯•

```python
# âŒ å°è¯•1ï¼šç›´æ¥åœ¨ JIT å†…åšæ¡ä»¶åˆ†æ”¯
def forward(self, x, use_cache):
    if use_cache:  # ConcretizationTypeError!
        return self.cached_output
    else:
        return self._compute(x)

# âŒ å°è¯•2ï¼šjax.lax.cond å°è£…
def forward(self, x, use_cache):
    return jax.lax.cond(
        use_cache,
        lambda: (self.cached_output, None, None),  # ç»“æ„ä¸åŒ¹é…
        lambda: self._compute_with_cache(x),        # è¿”å› 3 ä¸ªå€¼
    )
```

### 5.4 Tracer æ³„æ¼é—®é¢˜

```mermaid
flowchart TB
    subgraph TracerLeak["Tracer æ³„æ¼ç¤ºæ„"]
        JIT["JIT ç¼–è¯‘èŒƒå›´"]
        
        subgraph Inside["JIT å†…éƒ¨"]
            T1["åˆ›å»º traced tensor"]
            T2["æ¡ä»¶åˆ†æ”¯"]
            T3["è¿”å›ç»“æœ"]
        end
        
        subgraph Outside["JIT å¤–éƒ¨"]
            O1["æ¥æ”¶ç»“æœ"]
            O2["ç¼“å­˜åˆ° Python å¯¹è±¡"]
            O3["ä¸‹æ¬¡è°ƒç”¨ä½¿ç”¨"]
        end
        
        T1 --> T2 --> T3
        T3 --> O1 --> O2 --> O3
        
        O3 -.-> |"tracer æ³„æ¼!"| T2
    end
    
    style O2 fill:#ffcccc
```

å½“æŠŠ JIT å†…éƒ¨çš„ traced tensor ä¿å­˜åˆ°å¤–éƒ¨ Python å¯¹è±¡ï¼ˆå¦‚ cacheï¼‰ï¼Œå†åœ¨ä¸‹æ¬¡ JIT è°ƒç”¨æ—¶ä½¿ç”¨ï¼Œä¼šå¯¼è‡´ tracer æ³„æ¼é”™è¯¯ã€‚

---

## 6. TPU ç‰ˆæœ¬å®ç°

### 6.1 è§£å†³æ–¹æ¡ˆï¼šåˆ†ç¦»æ¨¡å—

```mermaid
flowchart TB
    subgraph è§£å†³æ–¹æ¡ˆ["åˆ†ç¦»æ¨¡å—æ–¹æ¡ˆ"]
        direction TB
        
        M1["FullForwardModule"]
        M2["CachedForwardModule"]
        
        M1 --> |"ç‹¬ç«‹ç¼–è¯‘"| C1["torchax.compile()"]
        M2 --> |"ç‹¬ç«‹ç¼–è¯‘"| C2["torchax.compile()"]
        
        C1 --> R1["å®Œæ•´ Forward<br/>è¿”å› output + cache"]
        C2 --> R2["ç¼“å­˜ Forward<br/>åªç”¨ cache"]
        
        Python["Python å±‚æ¡ä»¶åˆ†æ”¯"] --> |"if use_cache"| Choice
        Choice --> |"True"| M2
        Choice --> |"False"| M1
    end
    
    style Python fill:#ccffcc
```

### 6.2 FullForwardModule å®ç°

```python
class FullForwardModule(torch.nn.Module):
    """å°è£…å®Œæ•´ transformer forward"""
    
    def __init__(self, transformer, mask_type, extra_kwargs):
        super().__init__()
        self.transformer = transformer
        self.mask_type = mask_type
        self.extra_kwargs = extra_kwargs
    
    def forward(self, hidden_states, timestep, text_states, ...):
        transformer = self.transformer
        
        # === è¾“å…¥å¤„ç† ===
        img = transformer.img_in(hidden_states)
        vec = transformer.time_in(timestep)
        txt = transformer.txt_in(text_states)
        
        # === Double Blocks ===
        for block in transformer.double_blocks:
            img, txt = block(img=img, txt=txt, vec=vec, ...)
        
        # ğŸ”‘ ç¼“å­˜ç‚¹ï¼šä¿å­˜ä¸­é—´çŠ¶æ€
        img_after_double = img
        txt_after_double = txt
        
        # === Single Blocks ===
        x = torch.cat((img, txt), 1)
        for block in transformer.single_blocks:
            x = block(x=x, vec=vec, ...)
        
        # === Final Layer ===
        img = x[:, :img_seq_len, ...]
        output = transformer.final_layer(img, vec)
        
        # è¿”å› output + ç¼“å­˜æ•°æ®
        return (output, img_after_double, txt_after_double, vec, text_mask)
```

### 6.3 CachedForwardModule å®ç°

```python
class CachedForwardModule(torch.nn.Module):
    """å°è£…ä½¿ç”¨ç¼“å­˜çš„ forwardï¼Œè·³è¿‡ double_blocks"""
    
    def __init__(self, transformer):
        super().__init__()
        self.transformer = transformer
    
    def forward(self, cached_img, cached_txt, vec, freqs_cos, freqs_sin, text_mask):
        transformer = self.transformer
        
        # ğŸ”‘ ç›´æ¥ä½¿ç”¨ç¼“å­˜ï¼Œè·³è¿‡ double_blocks
        img = cached_img
        txt = cached_txt
        
        # === Single Blocks ===
        x = torch.cat((img, txt), 1)
        for block in transformer.single_blocks:
            x = block(x=x, vec=vec, ...)
        
        # === Final Layer ===
        img = x[:, :img_seq_len, ...]
        output = transformer.final_layer(img, vec)
        
        return output
```

### 6.4 TPUDeepCache ç¼“å­˜ç®¡ç†

```python
class TPUDeepCache:
    """TPU å‹å¥½çš„ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_start_step, cache_end_step, cache_step_interval, total_steps):
        # è®¡ç®—éœ€è¦å®Œæ•´è®¡ç®—çš„æ­¥éª¤
        self.no_cache_steps = set(
            list(range(0, cache_start_step)) +                        # å‰æœŸ
            list(range(cache_start_step, cache_end_step, cache_step_interval)) +  # åˆ·æ–°ç‚¹
            list(range(cache_end_step, total_steps))                  # åæœŸ
        )
        
        # ç¼“å­˜å­˜å‚¨
        self.cached_img = None
        self.cached_txt = None
        self._cached_vec = None
        self._cached_text_mask = None
    
    def should_use_cache(self, step):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜"""
        return step not in self.no_cache_steps and self.cached_img is not None
    
    def update_cache(self, img, txt, vec, text_mask):
        """æ›´æ–°ç¼“å­˜"""
        self.cached_img = img
        self.cached_txt = txt
        self._cached_vec = vec
        self._cached_text_mask = text_mask
    
    def get_cache(self):
        """è·å–ç¼“å­˜"""
        return self.cached_img, self.cached_txt, self._cached_vec, self._cached_text_mask
```

### 6.5 æ¨ç†å¾ªç¯é›†æˆ

```mermaid
flowchart TB
    subgraph æ¨ç†å¾ªç¯["æ¨ç†å¾ªç¯"]
        Start[Step i] --> Check{should_use_cache?}
        
        Check --> |"False"| Full["FullForwardModule"]
        Check --> |"True"| Cache["CachedForwardModule"]
        
        Full --> Update["update_cache()"]
        Update --> Output1[noise_pred]
        
        Cache --> Get["get_cache()"]
        Get --> Output2[noise_pred]
        
        Output1 --> Scheduler["scheduler.step()"]
        Output2 --> Scheduler
        
        Scheduler --> Next[Step i+1]
    end
```

```python
# æ¨ç†å¾ªç¯
for i in range(num_steps):
    if deep_cache.should_use_cache(i):
        # ğŸš€ ä½¿ç”¨ç¼“å­˜è·¯å¾„
        cached_img, cached_txt, vec, text_mask = deep_cache.get_cache()
        noise_pred = cached_forward_fn(
            cached_img, cached_txt, vec,
            transformer._cached_freqs_cos,
            transformer._cached_freqs_sin,
            text_mask,
        )
    else:
        # ğŸ“¦ å®Œæ•´ forward + æ›´æ–°ç¼“å­˜
        output = full_forward_fn(latent_model_input, timestep, ...)
        noise_pred, img_cache, txt_cache, vec, text_mask = output
        deep_cache.update_cache(img_cache, txt_cache, vec, text_mask)
    
    # Scheduler step
    latents = scheduler.step(noise_pred, t, latents)[0]
```

### 6.6 å…³é”®è®¾è®¡å†³ç­–

```mermaid
flowchart TB
    subgraph è®¾è®¡å†³ç­–
        D1["ä¸ºä»€ä¹ˆåˆ†ç¦»æ¨¡å—ï¼Ÿ"]
        D2["ä¸ºä»€ä¹ˆ Python å±‚åˆ†æ”¯ï¼Ÿ"]
        D3["ä¸ºä»€ä¹ˆç¼“å­˜ freqsï¼Ÿ"]
        D4["ä¸ºä»€ä¹ˆæ¸…é™¤é¢„çƒ­ç¼“å­˜ï¼Ÿ"]
        
        D1 --> A1["é¿å… JIT å†…æ¡ä»¶åˆ†æ”¯<br/>é¿å… PyTree åŒ¹é…é—®é¢˜"]
        D2 --> A2["Python æ¡ä»¶ä¸å‚ä¸ç¼–è¯‘<br/>å®Œå…¨ç»•è¿‡ XLA é™åˆ¶"]
        D3 --> A3["é¿å… tracer æ³„æ¼<br/>freqs ç‹¬ç«‹äº JIT è¿”å›å€¼"]
        D4 --> A4["warmup æ­¥éª¤çš„ç¼“å­˜æ— æ•ˆ<br/>æ­£å¼æ¨ç†éœ€è¦é‡æ–°å¡«å……"]
    end
```

---

## 7. æ€§èƒ½å¯¹æ¯”

### 7.1 æµ‹è¯•ç»“æœ

| é…ç½® | æ—  DeepCache | æœ‰ DeepCache | åŠ é€Ÿæ¯” |
|------|-------------|-------------|--------|
| 121å¸§, 50æ­¥ | ~350s | ~203s | **1.72x** |
| æ¯æ­¥æ—¶é—´ | ~7.0s | ~4.1s (avg) | - |
| Cache Hit | 0 | 25 (50%) | - |

### 7.2 æ—¶é—´åˆ†å¸ƒ

```mermaid
pie title 50æ­¥æ¨ç†æ—¶é—´åˆ†å¸ƒ (DeepCache)
    "å®Œæ•´ Forward (25æ­¥)" : 50
    "ç¼“å­˜ Forward (25æ­¥)" : 33
    "é¢„çƒ­ç¼–è¯‘" : 17
```

### 7.3 è¶…è¶Šç†è®ºåŠ é€Ÿæ¯”

å®æµ‹åŠ é€Ÿ 1.72x > ç†è®º 1.49xï¼Œå¯èƒ½åŸå› ï¼š
- ç¼“å­˜ Forward é¿å…äº†éƒ¨åˆ† XLA ç¼–è¯‘å¼€é”€
- å†…å­˜è®¿é—®æ¨¡å¼æ›´å‹å¥½
- TPU çŸ©é˜µè¿ç®—æ•ˆç‡å·®å¼‚

### 7.4 ä½¿ç”¨æ–¹æ³•

```bash
python stage2_transformer_flax_experimental_deepcache.py \
    --enable_cache \
    --cache_start_step 11 \
    --cache_end_step 45 \
    --cache_step_interval 4 \
    --video_length 121 \
    --num_inference_steps 50
```

---

## ğŸ“‹ æ€»ç»“

### å…³é”®å·®å¼‚å¯¹æ¯”

| æ–¹é¢ | GPU ç‰ˆæœ¬ | TPU ç‰ˆæœ¬ |
|------|----------|----------|
| æ¡ä»¶åˆ†æ”¯ | JIT å†… if/else | Python å±‚ if/else |
| æ¨¡å—ç»“æ„ | å•ä¸€æ¨¡å— + çŠ¶æ€ | ä¸¤ä¸ªç‹¬ç«‹æ¨¡å— |
| ç¼“å­˜ç®¡ç† | angelslim åº“ | è‡ªå®šä¹‰ TPUDeepCache |
| ç¼–è¯‘ | torch.compile | torchax.compile Ã— 2 |
| çŠ¶æ€ä¼ é€’ | infer_state å¯¹è±¡ | æ˜¾å¼å‚æ•°ä¼ é€’ |

### æ ¸å¿ƒç»éªŒ

1. **ä¸è¦åœ¨ JIT å†…åšæ¡ä»¶åˆ†æ”¯** - torchax/XLA ä¸æ”¯æŒ
2. **åˆ†ç¦»ç¼–è¯‘æ˜¯å…³é”®** - ä¸¤ä¸ªæ¨¡å—ç‹¬ç«‹ç¼–è¯‘ï¼Œé¿å… PyTree é—®é¢˜
3. **Python å±‚æ§åˆ¶æµ** - æ¡ä»¶åˆ¤æ–­æ”¾åœ¨ç¼–è¯‘èŒƒå›´å¤–
4. **æ˜¾å¼çŠ¶æ€ç®¡ç†** - ä¸ä¾èµ–å¯å˜çŠ¶æ€ï¼Œä½¿ç”¨å‡½æ•°å‚æ•°ä¼ é€’
5. **é¢„è®¡ç®—å¸¸é‡** - freqs ç­‰åœ¨ JIT å¤–é¢„è®¡ç®—å¹¶ç¼“å­˜

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [DeepCache è®ºæ–‡](https://arxiv.org/abs/2312.00858)
- [angelslim GitHub](https://github.com/horseee/DeepCache)
- [HunyuanVideo-1.5](https://github.com/Tencent/HunyuanVideo)
- [JAX JIT æ–‡æ¡£](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html)