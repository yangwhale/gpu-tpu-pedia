# HunyuanVideo-1.5 DiT å®ç°å¯¹æ¯”åˆ†æ

æœ¬æ–‡æ¡£æ·±å…¥å¯¹æ¯”åˆ†æä¸¤ä¸ª DiT (Diffusion Transformer) å®ç°çš„å¼‚åŒï¼š
1. `dit_gpu.py` - æ€§èƒ½æµ‹è¯•è„šæœ¬
2. `generate_hunyuan_staged/stage2_transformer_explained.py` - å®Œæ•´æ¨ç†å®ç°

---

## ğŸ“‹ ç›®å½•

1. [HunyuanVideo 1.5 æ•´ä½“æ¶æ„è¯¦è§£](#hunyuanvideo-15-æ•´ä½“æ¶æ„è¯¦è§£)
2. [æ¦‚è¿°å¯¹æ¯”](#æ¦‚è¿°å¯¹æ¯”)
3. [æ¶æ„æµç¨‹å›¾](#æ¶æ„æµç¨‹å›¾)
4. [æ ¸å¿ƒç»„ä»¶å¯¹æ¯”](#æ ¸å¿ƒç»„ä»¶å¯¹æ¯”)
5. [è¾“å…¥å‡†å¤‡å¯¹æ¯”](#è¾“å…¥å‡†å¤‡å¯¹æ¯”)
6. [æ‰§è¡Œæµç¨‹å¯¹æ¯”](#æ‰§è¡Œæµç¨‹å¯¹æ¯”)
7. [åŠŸèƒ½å·®å¼‚è¯¦è§£](#åŠŸèƒ½å·®å¼‚è¯¦è§£)
8. [è®¾è®¡ç†å¿µåˆ†æ](#è®¾è®¡ç†å¿µåˆ†æ)

---

## HunyuanVideo 1.5 æ•´ä½“æ¶æ„è¯¦è§£

åŸºäºå®˜æ–¹æ¶æ„å›¾ï¼ŒHunyuanVideo 1.5 é‡‡ç”¨å¤šæ¨¡æ€è¾“å…¥çš„æ‰©æ•£ Transformer æ¶æ„ï¼š

### ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```mermaid
flowchart TB
    subgraph inputs["ğŸ¯ å¤šæ¨¡æ€è¾“å…¥"]
        TEXT["ğŸ“ æ–‡æœ¬ Prompt<br/>'A drop of rich black ink falls...'"]
        IMG_REF["ğŸ–¼ï¸ å‚è€ƒå›¾åƒ<br/>(å¯é€‰, i2v æ¨¡å¼)"]
        IMG_COND["ğŸ¬ æ¡ä»¶å›¾åƒ/è§†é¢‘<br/>(i2v ç¬¬ä¸€å¸§)"]
    end
    
    subgraph encoders["ğŸ”§ ç¼–ç å™¨å±‚"]
        direction TB
        MLLM["<b>MLLM</b><br/>(LLaVA)<br/>å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹"]
        BYT5["<b>Glyph ByT5</b><br/>å­—èŠ‚çº§æ–‡æœ¬ç¼–ç å™¨"]
        SIGLIP["<b>SigLip</b><br/>è§†è§‰è¯­è¨€æ¨¡å‹"]
        VAE_ENC["<b>VAE Encoder</b><br/>è§†é¢‘å‹ç¼©ç¼–ç "]
    end
    
    subgraph projectors["ğŸ“ æŠ•å½±å±‚"]
        TOKEN_REF["Token Refiner<br/>(1000, 3584) â†’ (1000, 3072)"]
        BYT5_PROJ["ByT5 Proj<br/>(256, 1472) â†’ (256, 3072)"]
        VIS_PROJ["Vision Proj<br/>(729, 1152) â†’ (729, 3072)"]
        PATCH_EMB["Patch Emb<br/>(TÃ—HÃ—W, 32) â†’ (TÃ—HÃ—W, 3072)"]
    end
    
    subgraph transformer["ğŸ§  Dual Stream Transformer"]
        direction TB
        ROPE["3D RoPE<br/>æ—¶ç©ºæ—‹è½¬ä½ç½®ç¼–ç "]
        ATTN["Self-Attention /<br/>Sparse-Attention"]
        MLP1["MLP (Text Stream)"]
        MLP2["MLP (Video Stream)"]
        BLOCKS["Ã— 53 Blocks"]
    end
    
    subgraph output["ğŸ“¤ è¾“å‡º"]
        LATENTS["å»å™ª Latents<br/>(B, 16, T, H, W)"]
    end
    
    TEXT --> MLLM --> TOKEN_REF
    TEXT --> BYT5 --> BYT5_PROJ
    IMG_REF -.-> SIGLIP --> VIS_PROJ
    IMG_COND --> VAE_ENC --> PATCH_EMB
    
    TOKEN_REF --> transformer
    BYT5_PROJ --> transformer
    VIS_PROJ -.-> transformer
    PATCH_EMB --> transformer
    
    ROPE --> ATTN
    ATTN --> MLP1
    ATTN --> MLP2
    MLP1 --> BLOCKS
    MLP2 --> BLOCKS
    
    transformer --> LATENTS
    
    style inputs fill:#e3f2fd
    style encoders fill:#fff3e0
    style projectors fill:#f3e5f5
    style transformer fill:#e8f5e9
    style output fill:#fce4ec
```

### å››è·¯è¾“å…¥è¯¦è§£

| è¾“å…¥æ¨¡æ€ | ç¼–ç å™¨ | æŠ•å½±å±‚ | è¾“å‡ºç»´åº¦ | é¢œè‰²æ ‡è¯† | ç”¨é€” |
|---------|--------|--------|----------|----------|------|
| **æ–‡æœ¬ (è¯­ä¹‰)** | MLLM (LLaVA) | Token Refiner | (1000, 3072) | ğŸŸ£ ç´«è‰² | é«˜å±‚è¯­ä¹‰ç†è§£ |
| **æ–‡æœ¬ (å­—ç¬¦)** | Glyph ByT5 | ByT5 Proj | (256, 3072) | ğŸŸ£ æµ…ç´« | ç²¾ç¡®å­—ç¬¦æ¸²æŸ“ |
| **å‚è€ƒå›¾åƒ** | SigLip | Vision Proj | (729, 3072) | ğŸ”µ è“è‰² | è§†è§‰é£æ ¼å‚è€ƒ (å¯é€‰) |
| **è§†é¢‘/å›¾åƒ Latent** | VAE Encoder | Patch Emb | (TÃ—HÃ—W, 3072) | ğŸŸ  æ©™è‰² | æ¡ä»¶å¸§ + å™ªå£°å¸§ |

### ç¼–ç å™¨è¯¦ç»†è§„æ ¼

#### 1. MLLM (å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹)

```mermaid
flowchart LR
    subgraph mllm["MLLM Pipeline"]
        A["æ–‡æœ¬ Prompt"] --> B["LLaVA Tokenizer"]
        B --> C["LLaVA Model<br/>(~14GB)"]
        C --> D["prompt_embeds<br/>(1, 1000, 3584)"]
    end
    
    subgraph refiner["Token Refiner"]
        D --> E["LayerNorm"]
        E --> F["Linear(3584â†’3072)"]
        F --> G["æ—¶é—´æ­¥è°ƒåˆ¶"]
        G --> H["(1, 1000, 3072)"]
    end
```

**ç‰¹ç‚¹**:
- ä½¿ç”¨ LLaVA ä½œä¸ºè¯­è¨€ç†è§£éª¨å¹²
- è¾“å‡º 1000 ä¸ª tokensï¼Œæ¯ä¸ª 3584 ç»´
- Token Refiner åŒ…å«æ—¶é—´æ­¥æ¡ä»¶æ³¨å…¥

#### 2. Glyph ByT5 (å­—èŠ‚çº§ç¼–ç å™¨)

```mermaid
flowchart LR
    A["æ–‡æœ¬ Prompt"] --> B["UTF-8 å­—èŠ‚åºåˆ—"]
    B --> C["ByT5 Encoder<br/>(~5GB)"]
    C --> D["byt5_text_states<br/>(1, 256, 1472)"]
    D --> E["Linear Proj"]
    E --> F["(1, 256, 3072)"]
```

**ä¸ºä»€ä¹ˆéœ€è¦ ByT5?**
```
é—®é¢˜åœºæ™¯:
  Prompt: "ç”Ÿæˆå¸¦æœ‰ 'HUNYUAN' æ–‡å­—çš„æµ·æŠ¥"
  
  MLLM ç†è§£: "æŸä¸ªå“ç‰Œ/åç§°çš„æµ·æŠ¥" (è¯­ä¹‰çº§åˆ«)
  ByT5 ç†è§£: H-U-N-Y-U-A-N æ¯ä¸ªå­—ç¬¦ (å­—èŠ‚çº§åˆ«)
  
ç»“æœ: é…åˆä½¿ç”¨å¯ä»¥å‡†ç¡®æ¸²æŸ“æ–‡å­—
```

#### 3. SigLip (è§†è§‰è¯­è¨€æ¨¡å‹)

```mermaid
flowchart LR
    A["å‚è€ƒå›¾åƒ<br/>224Ã—224"] --> B["SigLip ViT<br/>(~400MB)"]
    B --> C["vision_states<br/>(1, 729, 1152)"]
    C --> D["Linear Proj"]
    D --> E["(1, 729, 3072)"]
```

**Token æ•°é‡è§£æ**:
- 729 = 27 Ã— 27
- æ¥æº: 224 / patch_size(8) = 28ï¼Œå»æ‰ CLS æˆ–è¾¹ç•Œ = 27

#### 4. VAE Encoder (è§†é¢‘å‹ç¼©)

```mermaid
flowchart LR
    subgraph input["è¾“å…¥"]
        A["è§†é¢‘å¸§<br/>(B, 3, T, H, W)<br/>å¦‚ (1, 3, 121, 720, 1280)"]
    end
    
    subgraph vae["VAE å‹ç¼©"]
        B["æ—¶é—´å‹ç¼© 4x"]
        C["ç©ºé—´å‹ç¼© 16x"]
        D["é€šé“æ‰©å±• 3â†’32"]
    end
    
    subgraph output["è¾“å‡º"]
        E["Latent<br/>(1, 32, 31, 45, 80)"]
    end
    
    A --> B --> C --> D --> E
```

**å‹ç¼©å…¬å¼**:
```python
latent_frames = (video_frames - 1) // 4 + 1  # 121 â†’ 31
latent_height = video_height // 16           # 720 â†’ 45
latent_width = video_width // 16             # 1280 â†’ 80
latent_channels = 32                         # ä¸æ˜¯ 16!
```

### Dual Stream Block è¯¦è§£

è¿™æ˜¯ HunyuanVideo 1.5 çš„æ ¸å¿ƒåˆ›æ–°ä¹‹ä¸€ï¼š

```mermaid
flowchart TB
    subgraph input["è¾“å…¥ Tokens"]
        TXT["Text Tokens<br/>(ç´«+æµ…ç´«)<br/>1256 tokens"]
        IMG["Video Tokens<br/>(æ©™)<br/>~111,600 tokens"]
    end
    
    subgraph prep["é¢„å¤„ç†"]
        TXT --> TXT_QKV["txt_qkv_proj"]
        IMG --> IMG_QKV["img_qkv_proj"]
        TXT_QKV --> TXT_Q["txt_q, txt_k, txt_v"]
        IMG_QKV --> IMG_Q["img_q, img_k, img_v"]
    end
    
    subgraph rope["3D RoPE"]
        ROPE_T["æ—¶é—´ç»´åº¦ RoPE"]
        ROPE_H["é«˜åº¦ç»´åº¦ RoPE"]
        ROPE_W["å®½åº¦ç»´åº¦ RoPE"]
        IMG_Q --> ROPE_T --> ROPE_H --> ROPE_W
    end
    
    subgraph attention["Joint Attention"]
        direction TB
        CAT_Q["Concat Q<br/>[img_q, txt_q]"]
        CAT_K["Concat K<br/>[img_k, txt_k]"]
        CAT_V["Concat V<br/>[img_v, txt_v]"]
        
        ATTN["Self-Attention<br/>æˆ– Sparse-Attention"]
        
        CAT_Q --> ATTN
        CAT_K --> ATTN
        CAT_V --> ATTN
        
        ATTN --> SPLIT["Split Output"]
        SPLIT --> IMG_ATTN["img_attn"]
        SPLIT --> TXT_ATTN["txt_attn"]
    end
    
    subgraph dual_mlp["åŒæµ MLP (ç‹¬ç«‹æƒé‡)"]
        IMG_ATTN --> IMG_ADD1["âŠ• Residual"]
        IMG_ADD1 --> IMG_MLP["img_mlp"]
        IMG_MLP --> IMG_ADD2["âŠ• Residual"]
        
        TXT_ATTN --> TXT_ADD1["âŠ• Residual"]
        TXT_ADD1 --> TXT_MLP["txt_mlp"]
        TXT_MLP --> TXT_ADD2["âŠ• Residual"]
    end
    
    subgraph output["è¾“å‡º"]
        IMG_ADD2 --> IMG_OUT["Video Tokens<br/>(æ›´æ–°å)"]
        TXT_ADD2 --> TXT_OUT["Text Tokens<br/>(æ›´æ–°å)"]
    end
    
    ROPE_W --> CAT_Q
    TXT_Q --> CAT_Q
    
    style attention fill:#e8f5e9
    style dual_mlp fill:#fff3e0
```

### ä¸ºä»€ä¹ˆæ˜¯ "Dual Stream"?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ä¼ ç»Ÿ Cross-Attention (å¦‚ Stable Diffusion):                             â”‚
â”‚                                                                          â”‚
â”‚   Text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ ä¸å˜           â”‚
â”‚                        â†“ (åªä½œä¸º K,V)                                    â”‚
â”‚   Image â”€â”€â”€â”€ Q â”€â”€â”€â†’ Attention â”€â”€â†’ æ›´æ–°åçš„ Image                        â”‚
â”‚                                                                          â”‚
â”‚   é—®é¢˜: Text tokens ä¸ä¼šè¢«æ›´æ–°ï¼Œä¿¡æ¯æµæ˜¯å•å‘çš„                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HunyuanVideo Dual Stream (Joint Attention + Dual MLP):                  â”‚
â”‚                                                                          â”‚
â”‚   Text â”€â”€â”¬â”€â”€ Q,K,V â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â†’ txt_attn â”€â”€â†’ txt_mlp â”€â”€â†’ æ›´æ–° â”‚
â”‚          â”‚             â”‚    Joint     â”‚                                  â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Attention   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚   Video â”€â”¬â”€â”€ Q,K,V â”€â”€â†’ â”‚              â”‚ â”€â”€â†’ img_attn â”€â”€â†’ img_mlp â”€â”€â†’ æ›´æ–° â”‚
â”‚          â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                          â”‚
â”‚   ä¼˜åŠ¿:                                                                  â”‚
â”‚   1. åŒå‘äº¤äº’: Text å’Œ Video äº’ç›¸ attend                                â”‚
â”‚   2. ç‹¬ç«‹ MLP: å„è‡ªçš„ç‰¹å¾å˜æ¢ (ä¸å…±äº«æƒé‡)                               â”‚
â”‚   3. æ›´å¼ºè¡¨è¾¾åŠ›: Text tokens ä¹Ÿä¼šæ ¹æ® Video è°ƒæ•´                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3D RoPE (æ—‹è½¬ä½ç½®ç¼–ç )

```mermaid
flowchart LR
    subgraph dims["ä¸‰ä¸ªç»´åº¦"]
        T["æ—¶é—´ T<br/>dim: 16"]
        H["é«˜åº¦ H<br/>dim: 56"]
        W["å®½åº¦ W<br/>dim: 56"]
    end
    
    subgraph combine["ç»„åˆ"]
        T --> ROPE["3D RoPE<br/>total: 128"]
        H --> ROPE
        W --> ROPE
    end
    
    subgraph apply["åº”ç”¨"]
        ROPE --> Q["Query æ—‹è½¬"]
        ROPE --> K["Key æ—‹è½¬"]
    end
```

**rope_dim_list = [16, 56, 56]**:
- æ—¶é—´ç»´åº¦: 16 ç»´ (è§†é¢‘å¸§é—´çš„ä½ç½®å…³ç³»)
- ç©ºé—´ç»´åº¦: 56 + 56 = 112 ç»´ (2D ç©ºé—´ä½ç½®)
- æ€»è®¡: 128 ç»´ = head_dim

### Token æ•°é‡è®¡ç®—

```python
# 720p, 121 å¸§çš„ä¾‹å­
video_tokens = T_latent Ã— H_latent Ã— W_latent
             = 31 Ã— 45 Ã— 80
             = 111,600 tokens

# æ–‡æœ¬ tokens
mllm_tokens = 1000   # LLaVA è¾“å‡º
byt5_tokens = 256    # ByT5 è¾“å‡º
text_tokens = 1256   # æ‹¼æ¥å

# æ€» tokens (ä¸€æ¬¡ attention)
total_tokens = 111,600 + 1,256 = 112,856 tokens!
```

### ç¨€ç–æ³¨æ„åŠ› (Sparse Attention)

ç”±äº token æ•°é‡å·¨å¤§ï¼ŒHunyuanVideo ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›:

```mermaid
flowchart TB
    subgraph full["Full Attention (ä¸å¯è¡Œ)"]
        A["112,856 Ã— 112,856<br/>= 12.7 Billion å…ƒç´ <br/>â‰ˆ 100GB æ˜¾å­˜"]
    end
    
    subgraph sparse["Sparse Attention"]
        B["åˆ†å—å¤„ç†<br/>tile_size = [6, 8, 8]"]
        C["SSTA<br/>(Sparse Spatial-Temporal Attention)"]
        D["Top-K é‡‡æ ·<br/>ssta_topk = 4096"]
    end
    
    full --> |"ä¼˜åŒ–"| sparse
```

### å®Œæ•´ Transformer ç»“æ„

```
HunyuanVideo_1_5_DiffusionTransformer:
â”œâ”€â”€ embedders:
â”‚   â”œâ”€â”€ txt_in: SingleTokenRefiner (LLaVA â†’ 3072)
â”‚   â”œâ”€â”€ byt5_in: Linear (1472 â†’ 3072)
â”‚   â”œâ”€â”€ img_in: PatchEmbedder (32 â†’ 3072)
â”‚   â””â”€â”€ time_in: TimestepEmbedder (ç”¨äº AdaLN)
â”‚
â”œâ”€â”€ double_blocks: Ã— 53
â”‚   â”œâ”€â”€ img_mod: ModulateDiT (æ—¶é—´æ­¥è°ƒåˆ¶ for img)
â”‚   â”œâ”€â”€ txt_mod: ModulateDiT (æ—¶é—´æ­¥è°ƒåˆ¶ for txt)
â”‚   â”œâ”€â”€ img_norm1/2: RMSNorm
â”‚   â”œâ”€â”€ txt_norm1/2: RMSNorm
â”‚   â”œâ”€â”€ img_attn_qkv: Linear (3072 â†’ 3072Ã—3)
â”‚   â”œâ”€â”€ txt_attn_qkv: Linear (3072 â†’ 3072Ã—3)
â”‚   â”œâ”€â”€ img_attn_proj: Linear (3072 â†’ 3072)
â”‚   â”œâ”€â”€ txt_attn_proj: Linear (3072 â†’ 3072)
â”‚   â”œâ”€â”€ img_mlp: MLP (3072 â†’ 12288 â†’ 3072)
â”‚   â””â”€â”€ txt_mlp: MLP (3072 â†’ 12288 â†’ 3072)
â”‚
â”œâ”€â”€ final_layer: Linear (3072 â†’ 32Ã—patch_size^3)
â”‚
â””â”€â”€ params: ~13B (DiT éƒ¨åˆ†)
```

### æ¡ä»¶æ³¨å…¥æœºåˆ¶ (AdaLN)

```mermaid
flowchart TB
    subgraph time["æ—¶é—´æ­¥ç¼–ç "]
        T["timestep t"] --> TE["TimestepEmbedder"]
        TE --> VEC["vec (B, 3072)"]
    end
    
    subgraph mod["Modulation"]
        VEC --> IMGMOD["img_mod"]
        VEC --> TXTMOD["txt_mod"]
        
        IMGMOD --> |".chunk(6)"| IMG_PARAMS["shift1, scale1, gate1<br/>shift2, scale2, gate2"]
        TXTMOD --> |".chunk(6)"| TXT_PARAMS["shift1, scale1, gate1<br/>shift2, scale2, gate2"]
    end
    
    subgraph apply["åº”ç”¨"]
        X["è¾“å…¥ x"] --> NORM["LayerNorm(x)"]
        NORM --> MODULATE["x Ã— (1 + scale) + shift"]
        MODULATE --> LAYER["Attention/MLP"]
        LAYER --> GATE["output Ã— gate"]
        GATE --> RES["x + gated_output"]
    end
```

**AdaLN å…¬å¼**:
```python
# è°ƒåˆ¶ (before attention/mlp)
x_modulated = LayerNorm(x) * (1 + scale) + shift

# é—¨æ§ (after attention/mlp)
output = x + gate * layer_output
```

---

## æ¦‚è¿°å¯¹æ¯”

### æ–‡ä»¶å®šä½

| ç»´åº¦ | `dit_gpu.py` | `stage2_transformer_explained.py` |
|------|-------------|-----------------------------------|
| **ç›®çš„** | æ€§èƒ½æµ‹è¯•/åŸºå‡†æµ‹è¯• | çœŸå®è§†é¢‘ç”Ÿæˆæ¨ç† |
| **ä»£ç è¡Œæ•°** | ~426 è¡Œ | ~2779 è¡Œ |
| **å¤æ‚åº¦** | ç®€å• | å¤æ‚ï¼ˆå«è¯¦ç»†æ³¨é‡Šï¼‰ |
| **æ˜¯å¦ç”Ÿæˆè§†é¢‘** | âŒ åªæµ‹è¯•é€Ÿåº¦/æ˜¾å­˜ | âœ… ç”ŸæˆçœŸå®è§†é¢‘ |
| **è¾“å…¥æ•°æ®** | éšæœºå¼ é‡ | çœŸå® Text Embeddings |
| **Scheduler** | ä¸ä½¿ç”¨ | FlowMatchDiscreteScheduler |
| **å»å™ªå¾ªç¯** | âŒ å•æ¬¡å‰å‘ | âœ… å¤šæ­¥è¿­ä»£å»å™ª |

### ä»£ç é‡å¯¹æ¯”

```
dit_gpu.py:
â”œâ”€â”€ æ€§èƒ½æµ‹è¯•å‡½æ•°: ~150 è¡Œ
â”œâ”€â”€ æ¨¡å‹åŠ è½½: ~100 è¡Œ
â”œâ”€â”€ å·¥å…·å‡½æ•°: ~80 è¡Œ
â””â”€â”€ å‘½ä»¤è¡Œå‚æ•°: ~50 è¡Œ

stage2_transformer_explained.py:
â”œâ”€â”€ è¯¦ç»†æ–‡æ¡£æ³¨é‡Š: ~1000 è¡Œ
â”œâ”€â”€ æ ¸å¿ƒæ¨ç†é€»è¾‘: ~400 è¡Œ
â”œâ”€â”€ è¾…åŠ©å‡½æ•°: ~300 è¡Œ
â”œâ”€â”€ æ¦‚å¿µè§£é‡Šé™„å½•: ~200 è¡Œ
â””â”€â”€ å…¶ä»–: ~100 è¡Œ
```

---

## æ¶æ„æµç¨‹å›¾

### dit_gpu.py æ‰§è¡Œæµç¨‹

```mermaid
flowchart TB
    subgraph init["åˆå§‹åŒ–é˜¶æ®µ"]
        A[å‘½ä»¤è¡Œå‚æ•°è§£æ] --> B[åˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–]
        B --> C[CUDA è®¾å¤‡è®¾ç½®]
    end
    
    subgraph model["æ¨¡å‹åŠ è½½"]
        D[ç¡®å®šæ¨¡å‹è·¯å¾„] --> E[from_pretrained åŠ è½½]
        E --> F[ç§»åŠ¨åˆ° GPU]
        F --> G[è®¾ç½® eval æ¨¡å¼]
    end
    
    subgraph input["è¾“å…¥å‡†å¤‡"]
        H[åˆ›å»ºéšæœº latents] --> I[åˆ›å»ºéšæœº text_states]
        I --> J[åˆ›å»ºéšæœº mask]
        J --> K[æ„é€  hidden_states]
        K --> L[å‡†å¤‡ ByT5 embeddings]
    end
    
    subgraph test["æ€§èƒ½æµ‹è¯•"]
        M[record_time å¼€å§‹è®¡æ—¶] --> N[Transformer å‰å‘ä¼ æ’­]
        N --> O[torch.cuda.synchronize]
        O --> P[è®°å½•å³°å€¼æ˜¾å­˜]
        P --> Q{æ˜¯å¦ç»§ç»­?}
        Q -->|æ˜¯| M
        Q -->|å¦| R[ç»Ÿè®¡ç»“æœ]
    end
    
    init --> model --> input --> test
    
    style init fill:#e3f2fd
    style model fill:#fff3e0
    style input fill:#e8f5e9
    style test fill:#fce4ec
```

### stage2_transformer_explained.py æ‰§è¡Œæµç¨‹

```mermaid
flowchart TB
    subgraph init["åˆå§‹åŒ–é˜¶æ®µ"]
        A[æ¨¡å—çº§å¹¶è¡ŒçŠ¶æ€åˆå§‹åŒ–] --> B[å‘½ä»¤è¡Œå‚æ•°è§£æ]
        B --> C[æ¨ç†çŠ¶æ€åˆå§‹åŒ–]
    end
    
    subgraph load["åŠ è½½ Stage 1 è¾“å‡º"]
        D[åŠ è½½ config.json] --> E[åŠ è½½ embeddings.safetensors]
        E --> F[æå– LLaVA embeddings]
        F --> G[æå– ByT5 embeddings]
    end
    
    subgraph model["æ¨¡å‹åŠ è½½"]
        H[åŠ è½½ Transformer] --> I[åŠ è½½ Scheduler]
        I --> J[è®¾ç½® flow_shift]
    end
    
    subgraph prepare["è¾“å…¥å‡†å¤‡"]
        K[è®¡ç®—åˆ†è¾¨ç‡] --> L[åŒæ­¥éšæœºç§å­]
        L --> M[è®¾ç½®æ—¶é—´æ­¥]
        M --> N[å‡†å¤‡ text embeddings + CFG]
        N --> O[ç”Ÿæˆéšæœº latents]
        O --> P[å‡†å¤‡ cond_latents + mask]
        P --> Q[å‡†å¤‡ vision_states]
    end
    
    subgraph denoise["å»å™ªå¾ªç¯"]
        R[for t in timesteps] --> S[æ‹¼æ¥ latents + cond_latents]
        S --> T[CFG: å¤åˆ¶è¾“å…¥]
        T --> U[Scheduler ç¼©æ”¾]
        U --> V[å¤„ç† Meanflow timestep_r]
        V --> W[Transformer å‰å‘ä¼ æ’­]
        W --> X[CFG å…¬å¼åº”ç”¨]
        X --> Y[Scheduler.step æ›´æ–°]
        Y --> Z{æœ€åä¸€æ­¥?}
        Z -->|å¦| R
        Z -->|æ˜¯| AA[å®Œæˆå»å™ª]
    end
    
    subgraph save["ä¿å­˜è¾“å‡º"]
        BB[ä¿å­˜ latents.safetensors] --> CC[æ›´æ–° config.json]
    end
    
    init --> load --> model --> prepare --> denoise --> save
    
    style init fill:#e3f2fd
    style load fill:#fff9c4
    style model fill:#fff3e0
    style prepare fill:#e8f5e9
    style denoise fill:#fce4ec
    style save fill:#e1bee7
```

### ä¸¤è€…çš„æ ¸å¿ƒå·®å¼‚æµç¨‹

```mermaid
flowchart LR
    subgraph dit_gpu["dit_gpu.py (æ€§èƒ½æµ‹è¯•)"]
        A1[éšæœºè¾“å…¥] --> A2[1æ¬¡å‰å‘ä¼ æ’­]
        A2 --> A3[æµ‹é‡æ—¶é—´/æ˜¾å­˜]
    end
    
    subgraph stage2["stage2_transformer.py (æ¨ç†)"]
        B1[çœŸå® Embeddings] --> B2[Næ¬¡è¿­ä»£å»å™ª]
        B2 --> B3[ä¿å­˜ Latents]
    end
    
    style dit_gpu fill:#ffebee
    style stage2 fill:#e8f5e9
```

---

## æ ¸å¿ƒç»„ä»¶å¯¹æ¯”

### 1. æ¨¡å‹åŠ è½½æ–¹å¼

```python
# dit_gpu.py - å¯é€‰ä½¿ç”¨ SageAttention
transformer = HunyuanVideo_1_5_DiffusionTransformer.from_pretrained(
    model_dir,
    torch_dtype=torch.bfloat16,
    low_cpu_mem_usage=True,
    attn_mode=attn_mode,  # "flash" æˆ– "sageattn"
).to(DEVICE)

# stage2_transformer_explained.py - å›ºå®šé…ç½®
transformer = HunyuanVideo_1_5_DiffusionTransformer.from_pretrained(
    transformer_path,
    torch_dtype=transformer_dtype,
    low_cpu_mem_usage=True,
)
```

### 2. åˆ†å¸ƒå¼åˆå§‹åŒ–

```python
# ä¸¤è€…éƒ½ä½¿ç”¨ç›¸åŒçš„åˆå§‹åŒ–æ¨¡å¼
parallel_dims = initialize_parallel_state(sp=int(os.environ.get('WORLD_SIZE', '1')))
torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', '0')))
```

### 3. Scheduler ä½¿ç”¨

| ç‰¹æ€§ | `dit_gpu.py` | `stage2_transformer_explained.py` |
|------|-------------|-----------------------------------|
| Scheduler ç±»å‹ | æ—  | FlowMatchDiscreteScheduler |
| æ—¶é—´æ­¥è®¾ç½® | å›ºå®š t=999 | åŠ¨æ€ timesteps åºåˆ— |
| flow_shift | æ—  | ä» PIPELINE_CONFIGS è·å– |
| solver | æ—  | euler |

---

## è¾“å…¥å‡†å¤‡å¯¹æ¯”

### dit_gpu.py çš„è¾“å…¥æ„é€ 

```mermaid
graph TD
    subgraph inputs["è¾“å…¥å¼ é‡æ„é€ "]
        A["latents<br/>(B, 32, T_latent, H, W)<br/>éšæœºå™ªå£°"]
        B["cond_latents<br/>(B, 32, T_latent, H, W)<br/>å…¨é›¶"]
        C["mask<br/>(B, 1, T_latent, H, W)<br/>å…¨é›¶"]
        
        A --> D["torch.cat([latents, cond_latents, mask])"]
        B --> D
        C --> D
        D --> E["hidden_states<br/>(B, 65, T_latent, H, W)"]
    end
    
    subgraph text["æ–‡æœ¬åµŒå…¥"]
        F["text_states<br/>(B, 1000, 3584)<br/>éšæœº"]
        G["byt5_text_states<br/>(B, 256, 1472)<br/>å…¨é›¶"]
    end
    
    E --> H["Transformer"]
    F --> H
    G --> H
```

### stage2_transformer_explained.py çš„è¾“å…¥æ„é€ 

```mermaid
graph TD
    subgraph embeddings["çœŸå® Embeddings (æ¥è‡ª Stage 1)"]
        A1["prompt_embeds<br/>(1, 1000, 3584)<br/>LLaVA è¾“å‡º"]
        A2["negative_prompt_embeds<br/>(1, 1000, 3584)"]
        A3["prompt_embeds_2<br/>(1, 256, 1472)<br/>ByT5 è¾“å‡º"]
    end
    
    subgraph cfg["CFG å¤„ç†"]
        B1["torch.cat([negative, positive])"]
        A1 --> B1
        A2 --> B1
        B1 --> B2["(2, 1000, 3584)"]
    end
    
    subgraph latents["Latents å‡†å¤‡"]
        C1["prepare_latents()<br/>éšæœºå™ªå£°"]
        C2["prepare_cond_latents()<br/>æ¡ä»¶ + mask"]
        C1 --> C3["torch.cat([latents, cond])"]
        C2 --> C3
        C3 --> C4["(1, 33, T, H, W)"]
    end
    
    subgraph loop["å»å™ªå¾ªç¯"]
        D1["for t in timesteps"]
        D2["CFG: cat x 2"]
        D3["Transformer(...)"]
        D4["CFG å…¬å¼"]
        D5["scheduler.step()"]
        
        C4 --> D1
        B2 --> D3
        D1 --> D2 --> D3 --> D4 --> D5
        D5 --> D1
    end
```

### è¾“å…¥å‚æ•°å¯¹æ¯”è¡¨

| å‚æ•° | dit_gpu.py | stage2_transformer_explained.py |
|------|------------|----------------------------------|
| `hidden_states` | éšæœº (B, 65, T, H, W) | æ‹¼æ¥å (2B, 33, T, H, W) |
| `timestep` | å›ºå®š 999 | åŠ¨æ€ timesteps åºåˆ— |
| `text_states` | éšæœº | çœŸå® LLaVA embeddings |
| `text_states_2` | None | None (720p æ¨¡å¼) |
| `encoder_attention_mask` | å…¨ 1 | çœŸå® prompt_mask |
| `byt5_text_states` | å…¨é›¶ | çœŸå® ByT5 embeddings |
| `byt5_text_mask` | å…¨é›¶ | çœŸå® mask |
| `timestep_r` | ä¸ä¼  | Meanflow ä¸‹ä¸€æ­¥æ—¶é—´ |
| `vision_states` | ä¸ä¼  | å…¨é›¶ (t2v æ¨¡å¼) |
| `guidance` | ä¸ä¼  | None |
| `return_dict` | False | False |

---

## æ‰§è¡Œæµç¨‹å¯¹æ¯”

### å•æ¬¡è°ƒç”¨ vs è¿­ä»£å»å™ª

```mermaid
sequenceDiagram
    participant C as è°ƒç”¨è€…
    participant T as Transformer
    participant S as Scheduler
    
    Note over C,S: dit_gpu.py (æ€§èƒ½æµ‹è¯•)
    rect rgb(255, 235, 238)
        C->>T: forward(latents, t=999, ...)
        T-->>C: noise_pred
        Note right of C: å®Œæˆ! åªæµ‹é€Ÿåº¦
    end
    
    Note over C,S: stage2_transformer_explained.py (æ¨ç†)
    rect rgb(232, 245, 233)
        loop 50 æ­¥
            C->>T: forward(latents, t, ...)
            T-->>C: noise_pred
            C->>C: CFG å…¬å¼å¤„ç†
            C->>S: step(noise_pred, t, latents)
            S-->>C: updated_latents
        end
        Note right of C: ä¿å­˜ final_latents
    end
```

### CFG å¤„ç†å·®å¼‚

```python
# dit_gpu.py - å¯é€‰ CFGï¼Œç®€å•å¤åˆ¶
batch = 2 if enable_cfg else 1
# å¦‚æœå¯ç”¨ï¼Œbatch ç¿»å€ï¼Œä½†ä¸åš CFG å…¬å¼è®¡ç®—

# stage2_transformer_explained.py - å®Œæ•´ CFG å®ç°
if do_classifier_free_guidance:
    # 1. è¾“å…¥ç¿»å€
    latent_model_input = torch.cat([latents_concat] * 2)
    
    # 2. æ¨¡å‹è¾“å‡ºåˆ†ç¦»
    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
    
    # 3. åº”ç”¨ CFG å…¬å¼
    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)
```

---

## åŠŸèƒ½å·®å¼‚è¯¦è§£

### 1. Meanflow æ”¯æŒ

```mermaid
graph LR
    subgraph dit_gpu["dit_gpu.py"]
        A1[ä¸æ”¯æŒ Meanflow]
        A2[ä¸ä¼  timestep_r]
    end
    
    subgraph stage2["stage2_transformer.py"]
        B1[æ£€æµ‹ use_meanflow é…ç½®]
        B2{æ˜¯æœ€åä¸€æ­¥?}
        B3[timestep_r = 0]
        B4[timestep_r = timesteps[i+1]]
        
        B1 --> B2
        B2 -->|æ˜¯| B3
        B2 -->|å¦| B4
    end
```

### 2. å¤šä»»åŠ¡æ”¯æŒ (i2v vs t2v)

```python
# dit_gpu.py - åªæµ‹è¯• t2v æ¨¡å¼
cond_latents = torch.zeros(...)  # å…¨é›¶
mask = torch.zeros(...)           # å…¨é›¶

# stage2_transformer_explained.py - æ”¯æŒ i2v
def prepare_cond_latents(task_type, image_cond, latents, multitask_mask):
    if image_cond is not None and task_type == 'i2v':
        # i2v: ç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å›¾åƒ
        latents_concat = image_cond.repeat(1, 1, latents.shape[2], 1, 1)
        latents_concat[:, :, 1:, :, :] = 0.0  # åç»­å¸§æ¸…é›¶
    else:
        # t2v: å…¨é›¶
        latents_concat = torch.zeros_like(latents)
```

### 3. æ€§èƒ½æµ‹é‡ vs å®é™…æ¨ç†

```mermaid
graph TB
    subgraph dit_gpu["dit_gpu.py æµ‹é‡æ¨¡å¼"]
        A1[torch.cuda.synchronize] --> A2[è®°å½•å¼€å§‹æ—¶é—´]
        A2 --> A3[å‰å‘ä¼ æ’­]
        A3 --> A4[torch.cuda.synchronize]
        A4 --> A5[è®°å½•ç»“æŸæ—¶é—´]
        A5 --> A6[è®¡ç®—å³°å€¼æ˜¾å­˜]
        A6 --> A7[ç»Ÿè®¡å¹³å‡/æœ€å¤§/æœ€å°]
    end
    
    subgraph stage2["stage2_transformer.py æ¨ç†æ¨¡å¼"]
        B1[time.perf_counter] --> B2[å»å™ªå¾ªç¯]
        B2 --> B3[æ¯10æ­¥æ‰“å°GPUå†…å­˜]
        B3 --> B4[è®°å½•æ€»è€—æ—¶]
        B4 --> B5[ä¿å­˜ç»“æœ]
    end
```

### 4. SageAttention æ”¯æŒ

| ç‰¹æ€§ | dit_gpu.py | stage2_transformer_explained.py |
|------|------------|----------------------------------|
| SageAttention | âœ… å¯é€‰ `--use_sage_attn` | âŒ ä¸æ”¯æŒ |
| attn_mode å‚æ•° | `"flash"` æˆ– `"sageattn"` | é»˜è®¤ |
| åŠ¨æ€æ£€æµ‹ | âœ… æ£€æµ‹ SAGE_ATTN_AVAILABLE | âŒ æ—  |

---

## è®¾è®¡ç†å¿µåˆ†æ

### 1. dit_gpu.py è®¾è®¡æ€æƒ³

```
ç›®æ ‡: å¿«é€Ÿã€å¯é‡å¤åœ°æµ‹é‡ DiT æ¨¡å‹æ€§èƒ½
      â†“
è®¾è®¡å†³ç­–:
â”œâ”€â”€ è¾“å…¥: éšæœºå¼ é‡ï¼ˆæ— éœ€çœŸå®æ•°æ®ï¼‰
â”œâ”€â”€ å•æ¬¡å‰å‘: ä¸éœ€è¦å®Œæ•´å»å™ª
â”œâ”€â”€ ç²¾ç¡®è®¡æ—¶: CUDA synchronize ç¡®ä¿å‡†ç¡®
â”œâ”€â”€ å†…å­˜æµ‹é‡: reset_peak_memory_stats
â”œâ”€â”€ å¤šæ¬¡è¿è¡Œ: ç»Ÿè®¡ç¨³å®šæ€§
â””â”€â”€ æœ€å°ä¾èµ–: ä¸éœ€è¦ text encoder, VAE ç­‰
```

### 2. stage2_transformer_explained.py è®¾è®¡æ€æƒ³

```
ç›®æ ‡: æ­£ç¡®æ‰§è¡Œ Stage 2 æ¨ç†ï¼Œç”Ÿæˆé«˜è´¨é‡ latents
      â†“
è®¾è®¡å†³ç­–:
â”œâ”€â”€ ä¸‰é˜¶æ®µåˆ†ç¦»: èŠ‚çœå†…å­˜ï¼Œçµæ´»è°ƒåº¦
â”œâ”€â”€ çœŸå® embeddings: ä» Stage 1 åŠ è½½
â”œâ”€â”€ å®Œæ•´å»å™ªå¾ªç¯: scheduler + CFG
â”œâ”€â”€ å¤šä»»åŠ¡æ”¯æŒ: t2v / i2v
â”œâ”€â”€ Meanflow: æ”¹å–„æ—¶é—´ä¸€è‡´æ€§
â”œâ”€â”€ SP æ”¯æŒ: å¤š GPU é•¿è§†é¢‘ç”Ÿæˆ
â””â”€â”€ è¯¦ç»†æ–‡æ¡£: ä¾¿äºç†è§£å’Œç»´æŠ¤
```

### 3. ä»£ç å¤ç”¨åˆ†æ

```mermaid
graph TB
    subgraph shared["å…±äº«ç»„ä»¶"]
        A[HunyuanVideo_1_5_DiffusionTransformer]
        B[initialize_parallel_state]
        C[torch.cuda.set_device]
    end
    
    subgraph dit_only["dit_gpu.py ç‹¬æœ‰"]
        D[record_time/record_peak_memory]
        E[SageAttention æ£€æµ‹]
        F[ç»Ÿè®¡å‡½æ•° print_results]
    end
    
    subgraph stage2_only["stage2_transformer.py ç‹¬æœ‰"]
        G[FlowMatchDiscreteScheduler]
        H[prepare_latents/prepare_cond_latents]
        I[get_task_mask]
        J[safetensors åŠ è½½/ä¿å­˜]
        K[CFG å®Œæ•´å®ç°]
    end
    
    A --> dit_only
    A --> stage2_only
    B --> dit_only
    B --> stage2_only
```

---

## ä½¿ç”¨åœºæ™¯å»ºè®®

### ä½¿ç”¨ dit_gpu.py å½“ï¼š

1. âœ… éœ€è¦å¿«é€Ÿè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒç¡¬ä»¶ä¸Šçš„æ€§èƒ½
2. âœ… æµ‹è¯•æ–°çš„ attention ä¼˜åŒ–ï¼ˆå¦‚ SageAttentionï¼‰
3. âœ… æ¯”è¾ƒä¸åŒé…ç½®ï¼ˆå¸§æ•°ã€åˆ†è¾¨ç‡ï¼‰çš„æ€§èƒ½
4. âœ… ä¸å…³å¿ƒç”Ÿæˆè´¨é‡ï¼Œåªå…³å¿ƒé€Ÿåº¦/æ˜¾å­˜

### ä½¿ç”¨ stage2_transformer_explained.py å½“ï¼š

1. âœ… éœ€è¦ç”ŸæˆçœŸå®è§†é¢‘
2. âœ… éœ€è¦ç†è§£ HunyuanVideo çš„æ¨ç†æœºåˆ¶
3. âœ… éœ€è¦åœ¨å¤š GPU ä¸Šç”Ÿæˆé•¿è§†é¢‘
4. âœ… éœ€è¦è°ƒè¯•æˆ–ä¿®æ”¹æ¨ç†é€»è¾‘

---

## æ€§èƒ½å‚è€ƒæ•°æ®

### dit_gpu.py å…¸å‹è¾“å‡º

```
=== DiT æµ‹è¯•ç»“æœ (å¸§æ•°: 121) ===
è¿è¡Œæ¬¡æ•°: 3

å³°å€¼æ˜¾å­˜ (MB):
  å¹³å‡å€¼: 28456.78
  æœ€å°å€¼: 28432.12
  æœ€å¤§å€¼: 28489.34

æ‰§è¡Œæ—¶é—´ (ms):
  å¹³å‡å€¼: 1523.45
  æœ€å°å€¼: 1498.23
  æœ€å¤§å€¼: 1567.89
```

### stage2_transformer_explained.py å…¸å‹è¾“å‡º

```
å¼€å§‹ Transformer æ¨ç†...
  ä½¿ç”¨ Meanflow: True
  ä½¿ç”¨ CFG: True
  SP çŠ¶æ€: sp_enabled=True, sp_size=8

  æ­¥éª¤ 1/50
    GPU allocated: 28.45GB
  æ­¥éª¤ 11/50
    GPU allocated: 28.67GB
  ...
  æ­¥éª¤ 50/50
    GPU allocated: 28.52GB

âœ“ Transformer æ¨ç†å®Œæˆï¼Œè€—æ—¶: 264.32 ç§’
```

---

## æ€»ç»“

| æ–¹é¢ | dit_gpu.py | stage2_transformer_explained.py |
|------|------------|----------------------------------|
| **å®šä½** | æ€§èƒ½åŸºå‡†æµ‹è¯• | ç”Ÿäº§æ¨ç† |
| **å¤æ‚åº¦** | ç®€å• | å¤æ‚ |
| **è¾“å…¥** | éšæœº | çœŸå® |
| **è¾“å‡º** | æ€§èƒ½æŒ‡æ ‡ | è§†é¢‘ latents |
| **é€‚ç”¨åœºæ™¯** | æ€§èƒ½è°ƒä¼˜ | è§†é¢‘ç”Ÿæˆ |
| **å¯è¯»æ€§** | ä»£ç ç®€æ´ | è¯¦ç»†æ³¨é‡Š |
| **æ‰©å±•æ€§** | æ˜“äºä¿®æ”¹æµ‹è¯•å‚æ•° | æ˜“äºç†è§£å®Œæ•´æµç¨‹ |

ä¸¤ä¸ªæ–‡ä»¶äº’ä¸ºè¡¥å……ï¼š
- `dit_gpu.py` ç”¨äºå¿«é€ŸéªŒè¯ç¡¬ä»¶æ€§èƒ½
- `stage2_transformer_explained.py` ç”¨äºå®é™…ç”Ÿæˆè§†é¢‘å¹¶å­¦ä¹ æ¶æ„