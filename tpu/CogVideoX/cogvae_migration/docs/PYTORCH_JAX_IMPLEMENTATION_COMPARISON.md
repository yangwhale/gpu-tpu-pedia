# PyTorch vs JAX å®ç°ç»†èŠ‚å¯¹æ¯”

## æ€»ä½“æ¶æ„å¯¹æ¯”

### æ•°æ®æ ¼å¼
| ç»´åº¦ | PyTorch | JAX/Flax |
|------|---------|----------|
| è§†é¢‘ | (B, C, T, H, W) | (B, T, H, W, C) |
| 2D | (B, C, H, W) | (B, H, W, C) |
| 1D | (B, C, L) | (B, L, C) |

---

## 1. CausalConv3d å¯¹æ¯”

### PyTorch: `CogVideoXCausalConv3d`
```python
# diffusers/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:69-147
class CogVideoXCausalConv3d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, pad_mode="constant"):
        # ä½¿ç”¨ CogVideoXSafeConv3d (ç»§æ‰¿è‡ª nn.Conv3d)
        self.conv = CogVideoXSafeConv3d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=kernel_size,  # (T, H, W)
            stride=stride if isinstance(stride, tuple) else (stride, 1, 1),
            dilation=(dilation, 1, 1),
            padding=0 if self.pad_mode == "replicate" else self.const_padding_conv3d,
            padding_mode="zeros",
        )
```

**å…³é”®ç‚¹**ï¼š
- âœ… ä½¿ç”¨ 3D å·ç§¯
- âœ… Padding: spatial (0, width_pad, height_pad)
- âœ… Stride: (temporal_stride, 1, 1)
- âœ… è¿”å› conv_cache

### JAX: `FlaxCogVideoXCausalConv3d`
```python
# diffusers-tpu-chris/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox_flax.py:260-371
class FlaxCogVideoXCausalConv3d(nnx.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, pad_mode="constant", rngs=None):
        self.conv = FlaxConv3d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=kernel_size,
            stride=stride_tuple,  # (stride, 1, 1)
            padding=0 if self.pad_mode == "replicate" else const_padding_conv3d,
            rngs=rngs,
        )
```

**å¯¹æ¯”ç»“æœ**: âœ… **å®Œå…¨ä¸€è‡´**

---

## 2. Downsampler å¯¹æ¯”

### PyTorch: `CogVideoXDownsample3D`
```python
# diffusers/src/diffusers/models/downsampling.py:288-353
class CogVideoXDownsample3D(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=0, compress_time=False):
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)
        self.compress_time = compress_time
    
    def forward(self, x):
        if self.compress_time:
            # æ—¶é—´å‹ç¼©: F.avg_pool1d
            ...
        
        # æ‰‹åŠ¨ padding
        pad = (0, 1, 0, 1)
        x = F.pad(x, pad, mode="constant", value=0)
        
        # åº”ç”¨ Conv2d (not Conv3d!)
        x = self.conv(x)  # åœ¨ (B*frames, C, H, W) ä¸Šæ“ä½œ
```

**å…³é”®ç‚¹**ï¼š
- âš ï¸ ä½¿ç”¨ **Conv2d**ï¼ˆä¸æ˜¯ Conv3dï¼ï¼‰
- âš ï¸ æ‰‹åŠ¨ padding: (0, 1, 0, 1)
- âœ… é»˜è®¤ padding=0
- âœ… æ—¶é—´å‹ç¼©: F.avg_pool1d

### JAX: `FlaxCogVideoXDownBlock3D.downsamplers`
```python
# diffusers-tpu-chris/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox_flax.py:745-834
# ä½¿ç”¨ FlaxConv2d (âœ… æ­£ç¡®)
downsampler = FlaxConv2d(
    out_channels, out_channels,
    kernel_size=3,
    stride=2,
    padding=0,  # âœ… No padding in conv
    rngs=rngs
)

# åœ¨ forward ä¸­æ‰‹åŠ¨æ·»åŠ  padding
pad_width = [
    (0, 0),  # batch
    (0, 0),  # time
    (0, 1),  # height: pad bottom
    (0, 1),  # width: pad right
    (0, 0),  # channels
]
hidden_states = jnp.pad(hidden_states, pad_width, mode='constant', constant_values=0)
```

**å¯¹æ¯”ç»“æœ**: âœ… **å®Œå…¨ä¸€è‡´**

---

## 3. Upsampler å¯¹æ¯”

### PyTorch: `CogVideoXUpsample3D`
```python
# diffusers/src/diffusers/models/upsampling.py:359-420
class CogVideoXUpsample3D(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, compress_time=False):
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)
        self.compress_time = compress_time
    
    def forward(self, inputs):
        if self.compress_time:
            if inputs.shape[2] > 1 and inputs.shape[2] % 2 == 1:
                # å¥‡æ•°å¸§: åˆ†ç¦»ç¬¬ä¸€å¸§
                x_first, x_rest = inputs[:, :, 0], inputs[:, :, 1:]
                x_first = F.interpolate(x_first, scale_factor=2.0)  # 2D æ’å€¼
                x_rest = F.interpolate(x_rest, scale_factor=2.0)    # 3D æ’å€¼
                x_first = x_first[:, :, None, :, :]
                inputs = torch.cat([x_first, x_rest], dim=2)
            elif inputs.shape[2] > 1:
                # å¶æ•°å¸§: 3D æ’å€¼
                inputs = F.interpolate(inputs, scale_factor=2.0)
            else:
                # å•å¸§
                inputs = inputs.squeeze(2)
                inputs = F.interpolate(inputs, scale_factor=2.0)
                inputs = inputs[:, :, None, :, :]
        else:
            # ä»… 2D æ’å€¼
            b, c, t, h, w = inputs.shape
            inputs = inputs.permute(0, 2, 1, 3, 4).reshape(b * t, c, h, w)
            inputs = F.interpolate(inputs, scale_factor=2.0)
            inputs = inputs.reshape(b, t, c, *inputs.shape[2:]).permute(0, 2, 1, 3, 4)
        
        # åº”ç”¨ Conv2d
        b, c, t, h, w = inputs.shape
        inputs = inputs.permute(0, 2, 1, 3, 4).reshape(b * t, c, h, w)
        inputs = self.conv(inputs)
        inputs = inputs.reshape(b, t, *inputs.shape[1:]).permute(0, 2, 1, 3, 4)
```

**å…³é”®ç‚¹**ï¼š
- âš ï¸ ä½¿ç”¨ **Conv2d**ï¼ˆä¸æ˜¯ Conv3dï¼ï¼‰
- âš ï¸ padding=1ï¼ˆä¸æ˜¯0ï¼ï¼‰
- âœ… compress_time: 3D interpolate (æ—¶é—´+ç©ºé—´)
- âœ… é compress_time: 2D interpolate (ä»…ç©ºé—´)

### JAX: `FlaxCogVideoXUpBlock3D.upsamplers`
```python
# diffusers-tpu-chris/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox_flax.py:918-1024
upsampler = FlaxConv2d(
    out_channels, out_channels,
    kernel_size=3,
    stride=1,
    padding=upsample_padding,  # default is 1 âœ…
    rngs=rngs
)

# compress_time é€»è¾‘
if self.compress_time:
    if T > 1 and T % 2 == 1:
        # å¥‡æ•°å¸§
        first_frame = hidden_states[:, 0, :, :, :]
        rest_frames = hidden_states[:, 1:, :, :, :]
        
        first_frame = jax.image.resize(first_frame, (B, H * 2, W * 2, C), method='nearest')
        first_frame = first_frame[:, None, :, :, :]
        
        rest_frames = jax.image.resize(rest_frames, (B, 2 * (T-1), H * 2, W * 2, C), method='nearest')
        
        hidden_states = jnp.concatenate([first_frame, rest_frames], axis=1)
    elif T > 1:
        # å¶æ•°å¸§
        hidden_states = jax.image.resize(hidden_states, (B, T * 2, H * 2, W * 2, C), method='nearest')
    else:
        # å•å¸§
        hidden_states = hidden_states.reshape(B, H, W, C)
        hidden_states = jax.image.resize(hidden_states, (B, H * 2, W * 2, C), method='nearest')
        hidden_states = hidden_states[:, None, :, :, :]
else:
    # ä»… 2D
    hidden_states = hidden_states.reshape(B * T, H, W, C)
    hidden_states = jax.image.resize(hidden_states, (B * T, H * 2, W * 2, C), method='nearest')
    hidden_states = hidden_states.reshape(B, T, H * 2, W * 2, C)
```

**å¯¹æ¯”ç»“æœ**: âœ… **å®Œå…¨ä¸€è‡´**

---

## 4. GroupNorm å¯¹æ¯”

### PyTorch: `nn.GroupNorm`
```python
nn.GroupNorm(num_channels=channels, num_groups=groups, eps=1e-6, affine=True)
```

### JAX: `FlaxGroupNorm`
```python
# diffusers-tpu-chris/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox_flax.py:374-449
class FlaxGroupNorm(nnx.Module):
    def __init__(self, num_groups, num_channels, epsilon=1e-6, rngs=None):
        self.num_groups = num_groups
        self.num_channels = num_channels
        self.epsilon = epsilon
        self.scale = nnx.Param(jnp.ones((num_channels,)))
        self.bias = nnx.Param(jnp.zeros((num_channels,)))
```

**æ½œåœ¨é—®é¢˜**:
- âš ï¸ epsilon å€¼ç›¸åŒå—ï¼ŸPyTorch é»˜è®¤ 1e-5ï¼ŒCogVideoX ä½¿ç”¨ 1e-6
- âš ï¸ å½’ä¸€åŒ–è½´æ˜¯å¦å®Œå…¨ä¸€è‡´ï¼Ÿ

---

## 5. SpatialNorm3D å¯¹æ¯”

### PyTorch: `CogVideoXSpatialNorm3D`
```python
# diffusers/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:149-197
class CogVideoXSpatialNorm3D(nn.Module):
    def __init__(self, f_channels, zq_channels, groups=32):
        self.norm_layer = nn.GroupNorm(num_channels=f_channels, num_groups=groups, eps=1e-6, affine=True)
        self.conv_y = CogVideoXCausalConv3d(zq_channels, f_channels, kernel_size=1, stride=1)
        self.conv_b = CogVideoXCausalConv3d(zq_channels, f_channels, kernel_size=1, stride=1)
    
    def forward(self, f, zq, conv_cache=None):
        # å¤„ç†å¥‡æ•°å¸§
        if f.shape[2] > 1 and f.shape[2] % 2 == 1:
            f_first, f_rest = f[:, :, :1], f[:, :, 1:]
            f_first_size, f_rest_size = f_first.shape[-3:], f_rest.shape[-3:]
            z_first, z_rest = zq[:, :, :1], zq[:, :, 1:]
            z_first = F.interpolate(z_first, size=f_first_size)
            z_rest = F.interpolate(z_rest, size=f_rest_size)
            zq = torch.cat([z_first, z_rest], dim=2)
        else:
            zq = F.interpolate(zq, size=f.shape[-3:])
        
        conv_y, new_conv_cache["conv_y"] = self.conv_y(zq, conv_cache=conv_cache.get("conv_y"))
        conv_b, new_conv_cache["conv_b"] = self.conv_b(zq, conv_cache=conv_cache.get("conv_b"))
        
        norm_f = self.norm_layer(f)
        new_f = norm_f * conv_y + conv_b
```

### JAX: `FlaxCogVideoXSpatialNorm3D`
```python
# diffusers-tpu-chris/src/diffusers/models/autoencoders/autoencoder_kl_cogvideox_flax.py:452-528
# å®ç°é€»è¾‘å®Œå…¨ç›¸åŒ
```

**å¯¹æ¯”ç»“æœ**: âœ… **é€»è¾‘ä¸€è‡´**

---

## 6. æ’å€¼æ–¹æ³•å¯¹æ¯”

### PyTorch: `F.interpolate`
```python
F.interpolate(x, scale_factor=2.0)  # é»˜è®¤ mode='nearest'
F.interpolate(x, size=target_size)
```

### JAX: `jax.image.resize`
```python
jax.image.resize(x, shape, method='nearest')
```

**æ½œåœ¨é—®é¢˜**:
- âš ï¸ 'nearest' æ’å€¼çš„è¾¹ç•Œå¤„ç†å¯èƒ½ä¸åŒ
- âš ï¸ PyTorch çš„ F.interpolate é»˜è®¤ align_corners=False

---

## 7. æ¿€æ´»å‡½æ•°å¯¹æ¯”

### PyTorch
```python
nn.SiLU()  # æˆ– F.silu()
```

### JAX
```python
jax.nn.silu()
```

**å¯¹æ¯”ç»“æœ**: âœ… **æ•°å­¦å®šä¹‰ç›¸åŒ** (silu(x) = x * sigmoid(x))

---

## æ€»ç»“ï¼šå·²ç¡®è®¤çš„å·®å¼‚ç‚¹

### âœ… å·²æ­£ç¡®å®ç°
1. Downsampler ä½¿ç”¨ Conv2d + æ‰‹åŠ¨ padding
2. Upsampler ä½¿ç”¨ Conv2d + padding=1
3. CausalConv3d ä½¿ç”¨ Conv3d
4. compress_time é€»è¾‘å®Œå…¨ä¸€è‡´
5. å½¢çŠ¶è½¬æ¢å…¨éƒ¨æ­£ç¡®

### âš ï¸ éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥çš„ç»†èŠ‚
1. **GroupNorm epsilon**: PyTorch é»˜è®¤ 1e-5ï¼ŒCogVideoX ä½¿ç”¨ 1e-6
2. **æ’å€¼æ–¹æ³•**: jax.image.resize vs F.interpolate çš„ç»†å¾®å·®å¼‚
3. **æµ®ç‚¹ç²¾åº¦**: è®¡ç®—é¡ºåºå¯èƒ½å¯¼è‡´çš„ç´¯ç§¯è¯¯å·®
4. **Padding æ¨¡å¼**: 'constant' vs 'zeros' çš„ä¸€è‡´æ€§

### ğŸ” æ•°å€¼å·®å¼‚æ¥æºåˆ†æ
å½“å‰è¯¯å·®æ°´å¹³ï¼š
- ç¼–ç  MAE: ~0.46-0.57
- è§£ç  MAE: ~0.31
- æœ€å¤§è¯¯å·®: ~1.8-2.9

è¿™äº›è¯¯å·®å¯èƒ½æ¥è‡ªï¼š
1. æ·±åº¦ç½‘ç»œçš„ç´¯ç§¯è¯¯å·®
2. GroupNorm çš„æ•°å€¼ç¨³å®šæ€§
3. æ’å€¼æ–¹æ³•çš„å®ç°å·®å¼‚
4. æµ®ç‚¹è¿ç®—é¡ºåº

**å»ºè®®çš„ä¼˜åŒ–æ–¹å‘**ï¼š
1. ç¡®ä¿æ‰€æœ‰ epsilon å€¼å®Œå…¨ä¸€è‡´
2. éªŒè¯ GroupNorm çš„è®¡ç®—è½´
3. æµ‹è¯•ä¸åŒçš„æ’å€¼æ–¹æ³•
4. æ·»åŠ æ›´è¯¦ç»†çš„é€å±‚æ•°å€¼å¯¹æ¯”