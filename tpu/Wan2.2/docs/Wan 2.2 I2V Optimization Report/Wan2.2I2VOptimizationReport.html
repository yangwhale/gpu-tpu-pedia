<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=DFQxm4rd7fRHgM9OTejWVYbTZVi_Y5F9JqoQGMBQEYTcaiBzRCYExEETILPJWh4BOZL0_Hd-TvMZaB_sttNazF-P_BTTX-2BtVDw1ZUf3HgcZWF3hAHMNYZRL0MY3y1z);.lst-kix_sfguzhqt6p7-1>li:before{content:"\0025cb   "}ol.lst-kix_vswvsv86egvp-7.start{counter-reset:lst-ctn-kix_vswvsv86egvp-7 0}.lst-kix_sfguzhqt6p7-3>li:before{content:"\0025cf   "}ol.lst-kix_vswvsv86egvp-0.start{counter-reset:lst-ctn-kix_vswvsv86egvp-0 0}.lst-kix_sfguzhqt6p7-0>li:before{content:"\0025cf   "}.lst-kix_o0aummv5mzzk-7>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-7}ol.lst-kix_o0aummv5mzzk-6{list-style-type:none}.lst-kix_vswvsv86egvp-6>li{counter-increment:lst-ctn-kix_vswvsv86egvp-6}.lst-kix_o0aummv5mzzk-1>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-1}ol.lst-kix_o0aummv5mzzk-5{list-style-type:none}.lst-kix_sfguzhqt6p7-2>li:before{content:"\0025a0   "}ol.lst-kix_o0aummv5mzzk-8{list-style-type:none}ol.lst-kix_o0aummv5mzzk-7{list-style-type:none}.lst-kix_vswvsv86egvp-1>li{counter-increment:lst-ctn-kix_vswvsv86egvp-1}ol.lst-kix_o0aummv5mzzk-2{list-style-type:none}.lst-kix_o0aummv5mzzk-0>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-0}ol.lst-kix_o0aummv5mzzk-1{list-style-type:none}ol.lst-kix_o0aummv5mzzk-4{list-style-type:none}ol.lst-kix_o0aummv5mzzk-3{list-style-type:none}.lst-kix_vswvsv86egvp-7>li{counter-increment:lst-ctn-kix_vswvsv86egvp-7}.lst-kix_o0aummv5mzzk-6>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-6}ol.lst-kix_vswvsv86egvp-4.start{counter-reset:lst-ctn-kix_vswvsv86egvp-4 0}ol.lst-kix_o0aummv5mzzk-0{list-style-type:none}.lst-kix_vswvsv86egvp-0>li{counter-increment:lst-ctn-kix_vswvsv86egvp-0}ol.lst-kix_o0aummv5mzzk-6.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-6 0}ol.lst-kix_o0aummv5mzzk-8.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-8 0}.lst-kix_o0aummv5mzzk-8>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-8}ol.lst-kix_vswvsv86egvp-6.start{counter-reset:lst-ctn-kix_vswvsv86egvp-6 0}.lst-kix_o0aummv5mzzk-2>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-2}.lst-kix_sfguzhqt6p7-8>li:before{content:"\0025a0   "}.lst-kix_sfguzhqt6p7-7>li:before{content:"\0025cb   "}.lst-kix_vswvsv86egvp-0>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-0,decimal) ". "}ol.lst-kix_o0aummv5mzzk-5.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-5 0}.lst-kix_sfguzhqt6p7-4>li:before{content:"\0025cb   "}.lst-kix_sfguzhqt6p7-5>li:before{content:"\0025a0   "}ol.lst-kix_vswvsv86egvp-3.start{counter-reset:lst-ctn-kix_vswvsv86egvp-3 0}.lst-kix_sfguzhqt6p7-6>li:before{content:"\0025cf   "}.lst-kix_o0aummv5mzzk-5>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-5}ol.lst-kix_o0aummv5mzzk-2.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-2 0}.lst-kix_vswvsv86egvp-5>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-5,lower-roman) ". "}.lst-kix_o0aummv5mzzk-0>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-0,decimal) ". "}.lst-kix_vswvsv86egvp-3>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-3,decimal) ". "}.lst-kix_vswvsv86egvp-3>li{counter-increment:lst-ctn-kix_vswvsv86egvp-3}.lst-kix_vswvsv86egvp-7>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-7,lower-latin) ". "}.lst-kix_o0aummv5mzzk-1>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-1,lower-latin) ". "}.lst-kix_vswvsv86egvp-4>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-4,lower-latin) ". "}.lst-kix_vswvsv86egvp-8>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-8,lower-roman) ". "}ol.lst-kix_vswvsv86egvp-2.start{counter-reset:lst-ctn-kix_vswvsv86egvp-2 0}.lst-kix_vswvsv86egvp-1>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-1,lower-latin) ". "}ol.lst-kix_vswvsv86egvp-5.start{counter-reset:lst-ctn-kix_vswvsv86egvp-5 0}.lst-kix_o0aummv5mzzk-3>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-3,decimal) ". "}.lst-kix_o0aummv5mzzk-4>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-4,lower-latin) ". "}.lst-kix_o0aummv5mzzk-4>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-4}ol.lst-kix_o0aummv5mzzk-0.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-0 0}.lst-kix_o0aummv5mzzk-2>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-2,lower-roman) ". "}.lst-kix_vswvsv86egvp-2>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-2,lower-roman) ". "}ol.lst-kix_o0aummv5mzzk-4.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-4 0}ul.lst-kix_sfguzhqt6p7-6{list-style-type:none}ul.lst-kix_sfguzhqt6p7-7{list-style-type:none}.lst-kix_vswvsv86egvp-4>li{counter-increment:lst-ctn-kix_vswvsv86egvp-4}.lst-kix_o0aummv5mzzk-3>li{counter-increment:lst-ctn-kix_o0aummv5mzzk-3}.lst-kix_o0aummv5mzzk-7>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-7,lower-latin) ". "}.lst-kix_o0aummv5mzzk-8>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-8,lower-roman) ". "}ul.lst-kix_sfguzhqt6p7-8{list-style-type:none}.lst-kix_o0aummv5mzzk-5>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-5,lower-roman) ". "}ol.lst-kix_o0aummv5mzzk-1.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-1 0}ul.lst-kix_sfguzhqt6p7-0{list-style-type:none}ul.lst-kix_sfguzhqt6p7-1{list-style-type:none}ul.lst-kix_sfguzhqt6p7-2{list-style-type:none}ul.lst-kix_sfguzhqt6p7-3{list-style-type:none}.lst-kix_o0aummv5mzzk-6>li:before{content:"" counter(lst-ctn-kix_o0aummv5mzzk-6,decimal) ". "}ul.lst-kix_sfguzhqt6p7-4{list-style-type:none}.lst-kix_vswvsv86egvp-6>li:before{content:"" counter(lst-ctn-kix_vswvsv86egvp-6,decimal) ". "}ul.lst-kix_sfguzhqt6p7-5{list-style-type:none}ol.lst-kix_o0aummv5mzzk-3.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-3 0}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix_vswvsv86egvp-1.start{counter-reset:lst-ctn-kix_vswvsv86egvp-1 0}ol.lst-kix_vswvsv86egvp-8{list-style-type:none}ol.lst-kix_vswvsv86egvp-7{list-style-type:none}ol.lst-kix_vswvsv86egvp-6{list-style-type:none}ol.lst-kix_vswvsv86egvp-1{list-style-type:none}ol.lst-kix_o0aummv5mzzk-7.start{counter-reset:lst-ctn-kix_o0aummv5mzzk-7 0}ol.lst-kix_vswvsv86egvp-0{list-style-type:none}.lst-kix_vswvsv86egvp-5>li{counter-increment:lst-ctn-kix_vswvsv86egvp-5}.lst-kix_vswvsv86egvp-8>li{counter-increment:lst-ctn-kix_vswvsv86egvp-8}.lst-kix_vswvsv86egvp-2>li{counter-increment:lst-ctn-kix_vswvsv86egvp-2}ol.lst-kix_vswvsv86egvp-8.start{counter-reset:lst-ctn-kix_vswvsv86egvp-8 0}ol.lst-kix_vswvsv86egvp-5{list-style-type:none}ol.lst-kix_vswvsv86egvp-4{list-style-type:none}ol.lst-kix_vswvsv86egvp-3{list-style-type:none}ol.lst-kix_vswvsv86egvp-2{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c8{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:156pt;border-top-color:#000000;border-bottom-style:solid}.c36{padding-top:14pt;padding-bottom:10pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Google Sans Text";font-style:normal}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11pt;font-family:"Google Sans Text";font-style:normal}.c19{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c29{padding-top:0pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}.c25{padding-top:14pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c11{color:#ff0000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Google Sans Text";font-style:normal}.c4{color:#4a86e8;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Google Sans";font-style:normal}.c7{padding-top:24pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c23{padding-top:0pt;padding-bottom:10pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c5{padding-top:0pt;padding-bottom:10pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#0000ee;text-decoration:underline}.c39{color:#4576c5;font-weight:400;font-size:11pt;font-family:"Open Sans"}.c33{color:#1976d2;font-weight:400;font-size:28pt;font-family:"Google Sans Text"}.c32{border-spacing:0;border-collapse:collapse;margin-right:auto}.c6{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c27{color:#1976d2;font-weight:400;font-size:18pt;font-family:"Google Sans"}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c10{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c22{color:#4175ca;font-weight:400;font-size:12pt;font-family:"Google Sans Text"}.c18{text-decoration:none;vertical-align:baseline;font-style:normal}.c21{font-weight:700;font-size:11pt;font-family:"Google Sans Text"}.c2{font-size:9pt;font-weight:400;font-family:"Roboto Mono"}.c31{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c15{margin-left:36pt;padding-left:0pt}.c20{margin-left:72pt;padding-left:0pt}.c37{font-weight:400;font-family:"Roboto Mono"}.c13{color:#c5221f}.c34{font-weight:700}.c14{color:#9334e6}.c30{height:18pt}.c3{color:#37474f}.c28{color:#b80672}.c16{height:0pt}.c38{vertical-align:super}.c12{color:#188038}.c24{height:11pt}.c26{color:#1967d2}.title{padding-top:0pt;color:#1976d2;font-size:28pt;padding-bottom:6pt;font-family:"Google Sans Text";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}.subtitle{padding-top:0pt;color:#2196f3;font-size:12pt;padding-bottom:10pt;font-family:"Google Sans Text";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Google Sans Text"}p{margin:0;color:#000000;font-size:11pt;font-family:"Google Sans Text"}h1{padding-top:24pt;color:#1976d2;font-size:18pt;padding-bottom:6pt;font-family:"Google Sans";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#4a86e8;font-size:14pt;padding-bottom:6pt;font-family:"Google Sans";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#4175ca;font-size:12pt;padding-bottom:10pt;font-family:"Google Sans Text";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#4576c5;font-size:11pt;padding-bottom:4pt;font-family:"Open Sans";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#457ba7;font-size:11pt;padding-bottom:4pt;font-family:"Open Sans";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#457ba7;font-size:11pt;padding-bottom:4pt;font-family:"Open Sans";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c31 doc-content"><p class="c29 title" id="h.jubxywhhdh7x"><span class="c18 c33">Wan 2.2 I2V Optimization Report</span></p><p class="c23"><span class="c10"><a href="https://www.google.com/url?q=http://goto.google.com/wan2p2-i2v-optimization-report&amp;sa=D&amp;source=editors&amp;ust=1765684258212221&amp;usg=AOvVaw3cQMTQmBMhuqH4njdhs29t">go/wan2p2-i2v-optimization-report</a></span></p><p class="c5"><span>Author: </span><span class="c17"><a href="mailto:yuyanpeng@google.com">Yuyan Peng</a></span><span><br>Last Major Revision Date: </span><span>Nov 7, 2025</span><span class="c1"><br>Status: Done</span></p><h1 class="c7" id="h.ptkmze6y426s"><span class="c27 c18">TL;DR</span></h1><p class="c5"><span>This report details the optimization of the Wan2.2-I2V-A14B image-to-video pipeline on v6e-8 and v6e-16 TPUs, aiming to reduce end-to-end video generation time. Key optimizations included reusing sharding strategies and a custom attention kernel from Wan2.1, with further modifications to eliminate padding effects in the kernel. A major focus was placed on VAE optimization through JIT compilation of encoder/decoder by making them pure functions, and implementing spatial partitioning for convolution activations. These efforts resulted in a significant reduction in 720p 81 frames video generation time, achieving </span><span class="c34">94.5 seconds on v6e-16</span><span>&nbsp;and </span><span class="c34">184.7 seconds on v6e-8 </span><span>compared to 159 seconds on 8xH100</span><span class="c1">.</span></p><h1 class="c7" id="h.5q5prukyc4c4"><span class="c27 c18">Context</span></h1><h2 class="c19" id="h.xvz3vwivwp26"><span class="c4">Objective</span></h2><p class="c5"><span class="c1">Optimize end to end (e2e) time to generate a video by Wan2.2-I2V-A14B image to video (I2V) pipeline on v6e-8 or v6e-16 as a POC to the customer.</span></p><h2 class="c19" id="h.7ru1ni4a14jr"><span class="c4">Background</span></h2><p class="c5"><span class="c1">Wan2.2 introduces Mixture-of-Experts (MoE), which contains two DiT models with the same model architecture as Wan2.1. Wan2.2 will decide which DiT model should be used depending on the scheduler sampling steps. Besides DiT, Wan2.2 has the text encoder part and VAE just like Wan2.1. The overall pipelines are similar between Wan2.2 and Wan2.1.</span></p><p class="c5"><span>We&rsquo;ve done the Wan2.1 optimization in </span><span class="c17"><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1cJw93j8gQ8r6pouA-gS4ynpbjNlkqggJ4Zs76G3Daqs/edit?resourcekey%3D0-rnX-srj_Hqsg_KsHqqYrqg%26tab%3Dt.0%23heading%3Dh.d7id8slf0vtu&amp;sa=D&amp;source=editors&amp;ust=1765684258213890&amp;usg=AOvVaw0xYdaNRV-dFgzs02uQBlJh">Wan2.1 Optimization Report</a></span><span class="c1">&nbsp;and get 125s a video by Wan2.1 text to video (T2V) pipeline on v6e-16. The DiT in the Wan2.1 has been optimized with the sharding and custom attention pallas kernel. The sharding strategy and attention kernel could be reused since the Wan2.2 DiT architecture is the same as the Wan2.1.</span></p><p class="c5"><span class="c1">The difference from Wan2.1 T2V to Wan2.2 I2V is that Wan2.2 I2V has two DiT weights, additional VAE encoding, and diffusion sample steps from 50 to 40. The double size of weights means needing double of 14B parameters in the HBM, which restricts the working memory which is highly consumed by the VAE decoding. Additional VAE encoding could be an extra effort and take time. Fortunately, the fewer sample steps could reduce the e2e time.</span></p><p class="c5"><span>The baseline is generating a video within 159s on 8 H100 chips referred from the github </span><span class="c10"><a href="https://www.google.com/url?q=https://github.com/Wan-Video/Wan2.2&amp;sa=D&amp;source=editors&amp;ust=1765684258214686&amp;usg=AOvVaw2NGygegXk18WN9zfeiLkWH">repo</a></span><span class="c1">.</span></p><h1 class="c7" id="h.hvz8sz56lrtq"><span class="c18 c27">Method</span></h1><h2 class="c19" id="h.lrjcvbmlc5iq"><span class="c4">Overview</span></h2><p class="c5"><span>We choose </span><span class="c10"><a href="https://www.google.com/url?q=https://github.com/yuyanpeng-google/diffusers/tree/wan2.2-main&amp;sa=D&amp;source=editors&amp;ust=1765684258214880&amp;usg=AOvVaw2EljpALtBagYImQBijkefU">diffusers</a></span><span>&nbsp;as the framework since we are familiar with it given the previous wan2.1 optimization work. The </span><span class="c10"><a href="https://www.google.com/url?q=https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers&amp;sa=D&amp;source=editors&amp;ust=1765684258215021&amp;usg=AOvVaw3roJLscG-gvsOFWXQMAq7-">model</a></span><span class="c1">&nbsp;and pipeline is already integrated into the diffusers.</span></p><p class="c5"><span>The DiT part mostly uses the optimization experience from the Wan2.1, including sequence parallelism on all layers and cross attention except context parallelism on self attention, and custom attention kernel. We further modify the kernel to eliminate the padding effect. Although the padding is relatively short to the long sequence and gives little effect, it still produces some error by the </span><span class="c10"><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1gXJnWQU9khfghDfO8MF4WMLQvZIi5elxOHCP28Ls0B0/edit?resourcekey%3D0-f4cXiX4nsgapyWFgmTAwsA%26tab%3Dt.3ky4w71l3lhy%23heading%3Dh.mgny6fdyi6il&amp;sa=D&amp;source=editors&amp;ust=1765684258215527&amp;usg=AOvVaw3znoCyEXLWQowUGmAAv-1c">analysis</a></span><span class="c1">. By further modification of the kernel, we strip the padded kv sequence inside the kernel and prevent effects by the nonsense values while preserving the performance without segment id.</span></p><p class="c5"><span>The VAE encoder decoder part, we directly optimize VAE encoder and decoder from diffusers through torchax. There are two parts of optimization in VAE: 1. Jit the encoder, decoder by modifying the cache mechanism to pure functions. And 2. </span><span class="c10"><a href="https://www.google.com/url?q=https://g3doc.corp.google.com/platforms/xla/service/jellyfish/g3doc/spatial_partitioning.md?cl%3Dhead%23convolution&amp;sa=D&amp;source=editors&amp;ust=1765684258216011&amp;usg=AOvVaw0JCk0NNZVVKP61v0EqAuke">Spatial partitioning</a></span><span>&nbsp;the convolution activations. We optimize the entire code from pytorch which is different from the Wan2.1 using proxy from jax implementation in maxdiffusion.</span></p><h2 class="c19" id="h.s85o9xvchmwb"><span class="c4">Diffusion Transformer (DiT)</span></h2><p class="c5"><span>Apply sequence parallelism on all layers and cross attention except context parallelism on self attention and modify custom attention kernel by reverse qk order and better overlapping VPU and MXU computation. See</span><span class="c17"><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1-SQneQk-Ciy3c7o0ecaGnixVMwKHaMRBAIsFRZ4nnRs/edit?resourcekey%3D0-JSF2erehuijMCyapmPdbyQ%26tab%3Dt.0%23heading%3Dh.g30huzokkzwx&amp;sa=D&amp;source=editors&amp;ust=1765684258216516&amp;usg=AOvVaw0udHeuBPaPrQHITIeR3f8f">[External] Wan2.1-14B Text to Video Model Optimization on TPU v6e-16</a></span><span>&nbsp;DiT chapter for the detail of sharding strategy and custom kernel optimization.</span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 337.33px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 337.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c1">Also we further modify the attention kernel to eliminate the kv padding effect due to block size mismatch while preserving the performance. The kernel constrains the kv block to be multiple of kv compute size, and kv compute size needs to be multiple of 256 to get better performance. It&rsquo;s impossible to find a block size which divides the sequence length 75600 and be the multiple of 256. Therefore we need padding on KV, and with segment id to mask out the padding in the original implementation. The segment id is slow, and for our case it&rsquo;s just for padding but not complicated segmentation.</span></p><p class="c5"><span class="c1">Given that we only need to mask out the padding, and the padding should be less or equal than kv block size, we can branch out the last block and slice the kv to prevent the padding effect. </span></p><p class="c0 c24"><span class="c1"></span></p><p class="c0"><span>&#60419;</span></p><p class="c0"><span class="c2 c26">&nbsp; &nbsp; def</span><span class="c2">&nbsp;</span><span class="c2 c3">last_compute_body(kv_compute_index):</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c18 c2 c28"># # with jax.named_scope(&quot;qk&quot;):</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">m_prev,</span><span class="c2">&nbsp;</span><span class="c2 c3">l_prev</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">m_scratch_ref[...],</span><span class="c2">&nbsp;</span><span class="c2 c3">l_scratch_ref[...]</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c26">assert</span><span class="c2">&nbsp;</span><span class="c2 c3">m_prev.shape</span><span class="c2">&nbsp;</span><span class="c2 c3">==</span><span class="c2">&nbsp;</span><span class="c2 c3">(NUM_SUBLANES,</span><span class="c2">&nbsp;</span><span class="c2 c3">bq)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c26">assert</span><span class="c2">&nbsp;</span><span class="c2 c3">l_prev.shape</span><span class="c2">&nbsp;</span><span class="c2 c3">==</span><span class="c2">&nbsp;</span><span class="c2 c3">(NUM_SUBLANES,</span><span class="c2">&nbsp;</span><span class="c2 c3">bq)</span></p><p class="c0 c24"><span class="c6 c2"></span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c18 c2 c28"># We don&#39;t care about q padding since it doesn&#39;t matter and truncated afterward</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c18 c2 c28"># We care about kv padding</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">q</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">q_ref[...]</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">slice_k_len</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">kv_seq_len</span><span class="c2">&nbsp;</span><span class="c2 c3">%</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">slice_k</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">pl.ds(kv_compute_index</span><span class="c2">&nbsp;</span><span class="c2 c3">*</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute,</span><span class="c2">&nbsp;</span><span class="c2 c3">slice_k_len)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">k</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">k_ref[slice_k,</span><span class="c2">&nbsp;</span><span class="c2 c3">:]</span></p><p class="c0"><span class="c2">&nbsp; &nbsp;</span><span class="c2 c3">...</span></p><p class="c0 c24"><span class="c6 c2"></span></p><p class="c0"><span class="c2">&nbsp; &nbsp; </span><span class="c2 c3">@pl.when(j</span><span class="c2">&nbsp;</span><span class="c2 c3">!=</span><span class="c2">&nbsp;</span><span class="c2 c3">grid_width</span><span class="c2">&nbsp;</span><span class="c2 c3">-</span><span class="c2">&nbsp;</span><span class="c2 c13">1</span><span class="c2 c3">)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; </span><span class="c2 c26">def</span><span class="c2">&nbsp;</span><span class="c2 c3">body():</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">lax.fori_loop(</span><span class="c2 c13">0</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">(bkv</span><span class="c2">&nbsp;</span><span class="c2 c3">//</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute),</span><span class="c2">&nbsp;</span><span class="c2 c3">compute_body,</span><span class="c2">&nbsp;</span><span class="c2 c14">None</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">unroll=True)</span></p><p class="c0 c24"><span class="c6 c2"></span></p><p class="c0"><span class="c2">&nbsp; &nbsp; </span><span class="c2 c3">@pl.when(j</span><span class="c2">&nbsp;</span><span class="c2 c3">==</span><span class="c2">&nbsp;</span><span class="c2 c3">grid_width</span><span class="c2">&nbsp;</span><span class="c2 c3">-</span><span class="c2">&nbsp;</span><span class="c2 c13">1</span><span class="c2 c3">)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; </span><span class="c2 c26">def</span><span class="c2">&nbsp;</span><span class="c2 c3">last_body():</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c26">if</span><span class="c2">&nbsp;</span><span class="c2 c3">kv_seq_len</span><span class="c2">&nbsp;</span><span class="c2 c3">%</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv</span><span class="c2">&nbsp;</span><span class="c2 c3">==</span><span class="c2">&nbsp;</span><span class="c2 c13">0</span><span class="c2 c3">:</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">iter_num</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv</span><span class="c2">&nbsp;</span><span class="c2 c3">//</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">lax.fori_loop(</span><span class="c2 c13">0</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">iter_num,</span><span class="c2">&nbsp;</span><span class="c2 c3">compute_body,</span><span class="c2">&nbsp;</span><span class="c2 c14">None</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">unroll=True)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c26">else</span><span class="c2 c3">:</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c18 c2 c28"># the last iter may contain padding. Separate the case</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">remain_kv_seq_len</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">kv_seq_len</span><span class="c2">&nbsp;</span><span class="c2 c3">%</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">iter_num</span><span class="c2">&nbsp;</span><span class="c2 c3">=</span><span class="c2">&nbsp;</span><span class="c2 c3">(remain_kv_seq_len</span><span class="c2">&nbsp;</span><span class="c2 c3">+</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute</span><span class="c2">&nbsp;</span><span class="c2 c3">-</span><span class="c2">&nbsp;</span><span class="c2 c13">1</span><span class="c2 c3">)</span><span class="c2">&nbsp;</span><span class="c2 c3">//</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c26">if</span><span class="c2">&nbsp;</span><span class="c2 c3">remain_kv_seq_len</span><span class="c2">&nbsp;</span><span class="c2 c3">%</span><span class="c2">&nbsp;</span><span class="c2 c3">bkv_compute</span><span class="c2">&nbsp;</span><span class="c2 c3">==</span><span class="c2">&nbsp;</span><span class="c2 c13">0</span><span class="c2 c3">:</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">lax.fori_loop(</span><span class="c2 c13">0</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">iter_num,</span><span class="c2">&nbsp;</span><span class="c2 c3">compute_body,</span><span class="c2">&nbsp;</span><span class="c2 c14">None</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">unroll=True)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c26">else</span><span class="c2 c3">:</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">lax.fori_loop(</span><span class="c2 c13">0</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">iter_num</span><span class="c2">&nbsp;</span><span class="c2 c3">-</span><span class="c2">&nbsp;</span><span class="c2 c13">1</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">compute_body,</span><span class="c2">&nbsp;</span><span class="c2 c14">None</span><span class="c2 c3">,</span><span class="c2">&nbsp;</span><span class="c2 c3">unroll=True)</span></p><p class="c0"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c2 c3">last_compute_body(iter_num</span><span class="c2">&nbsp;</span><span class="c2 c3">-</span><span class="c2">&nbsp;</span><span class="c2 c13">1</span><span class="c2 c3">)</span></p><p class="c5"><span>&#60418;</span><span class="c10"><a href="https://www.google.com/url?q=https://github.com/yuyanpeng-google/diffusers/commit/a1ce152e2957d43fba53bd803cfe2a105895b425&amp;sa=D&amp;source=editors&amp;ust=1765684258222350&amp;usg=AOvVaw1Rmw55c2gFt5rzZKzMdxQG">https://github.com/yuyanpeng-google/diffusers/commit/a1ce152e2957d43fba53bd803cfe2a105895b425</a></span></p><p class="c5"><span class="c1">The overall compile time will be longer, but the running time will be slightly better since we don&rsquo;t need to explicitly pad zero at the end.</span></p><p class="c5"><span>Test the kernel by adding </span><span class="c12 c37">interpret=True</span><span>&nbsp;in the pallas_call, which will pad NaN for debugging, and don&rsquo;t see any NaN appear in the results. Compared to the w/ and w/o segment_id in jax lib splash_attention, with specific input, padding will cause about e-8 mean error, and the custom kernel would be e-9 no matter if padding happens. The e-9 mean error could be the precision error by the different calculating order. Script in</span><span class="c17"><a href="https://www.google.com/url?q=https://colab.research.google.com/drive/17XtIiqMp1wc8rAe4oW4Qw6eA8QOGsw5j?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765684258223018&amp;usg=AOvVaw35ZYgBxxtaEZKi1mlZ8a8F">Compare segment_id impact.ipynb</a></span><span class="c1">, running at the root of the diffuser.</span></p><h2 class="c19" id="h.8dlf9m2yn7e1"><span class="c4">VAE</span></h2><p class="c5"><span class="c1">The VAE optimization is the major improvement from the Wan2.1. In the previous Wan2.1 optimization, we were focusing on DiT optimization and proxy the maxdiffusion jax implementation. The mixed jax implementation could be different from the customized pytorch model, and add the barrier to the custom models optimization. Also, at the moment we haven&rsquo;t jit or optimize the sharding strategy in VAE. It could become a bottleneck since we need to do an additional VAE encoder step. Furthermore, the HBM memory pressure is high and could be OOM if we have two 14B models. Therefore we decided to optimize the VAE from diffusers.</span></p><p class="c5"><span class="c1">We optimize from the diffusers VAE code directly an do two optimization:</span></p><ol class="lst-kix_vswvsv86egvp-0 start" start="1"><li class="c5 c15 li-bullet-0"><span class="c1">Jit the encoder, decoder by modifying the cache mechanism to pure functions</span></li><li class="c5 c15 li-bullet-0"><span class="c1">Spatial partitioning the convolution activations. </span></li></ol><h3 class="c36" id="h.8p0e7tqfu1jv"><span class="c22 c18">Jit Encoder and Decoder</span></h3><p class="c5"><span class="c1">The encoding and decoding are using cache mechanisms along the time dimension. They will iterate 21 inters for 81 frames videos. The cache mechanisms implementation are not pure function originally, and prevent us directly jit them. The cache mechanisms use lists to directly modify the input arguments. To make them pure, modify the functions to return the modified value in every function return value, and update them in the caller.</span></p><p class="c5"><span class="c1">The encode, decode function will iterate through 21 iters with compiled 3 graphs depending on different cache states.</span></p><h4 class="c25" id="h.pl4tj73tdh1w"><span class="c39 c18">Alternative Considerations</span></h4><p class="c5"><span class="c1">We can jit the encode and decode functions directly and get possibly shorter latency. However, jit the functions directly result in unrolling the loop along the time dimension, which causes some disadvantages: 1. high memory pressure and 2. Complicated and large compiled graph.</span></p><p class="c5"><span>If we unroll all the iterations, it could optimize to calculate 81 frames simultaneously without the cache mechanism and cause very high memory usage. If we use </span><span class="c10"><a href="https://www.google.com/url?q=https://b.corp.google.com/issues/453574996%23comment6&amp;sa=D&amp;source=editors&amp;ust=1765684258225090&amp;usg=AOvVaw2b8oTdRdVSVwt5HRMLDEpf">optimization_barrier</a></span><span>&nbsp;to prevent calculation at the same time, the compiled graphs are complicated and take time to load executable before execution.</span></p><h3 class="c36" id="h.2be3ta9m4c3r"><span class="c18 c22">Spatial Partitioning</span></h3><p class="c5"><span class="c10"><a href="https://www.google.com/url?q=https://g3doc.corp.google.com/platforms/xla/service/jellyfish/g3doc/spatial_partitioning.md?cl%3Dhead%23convolution&amp;sa=D&amp;source=editors&amp;ust=1765684258225388&amp;usg=AOvVaw2RXk5HF2uhAa1dFtJe0KWr">Spatial partitioning</a></span><span class="c1">&nbsp;shard the convolution activations along height dimension by adding sharding_constraint before the convolution layers. The XLA will handle the halo issues which need to transfer the tensors at the edge to the neighboring devices because of the convolution calculation. &nbsp;Also by sharding the activations, we could save the HBM usage by the time sequence cache.</span></p><p class="c0 c24"><span class="c1"></span></p><p class="c0"><span>&#60419;</span><span class="c2 c12">mark_sharding</span><span class="c2">&nbsp;</span><span class="c2 c12">=</span><span class="c2">&nbsp;</span><span class="c2 c12 c18">interop.torch_view(jax.lax.with_sharding_constraint)</span></p><p class="c0"><span class="c18 c2 c12">...</span></p><p class="c0"><span class="c18 c2 c12"># Sharding along height. Height should be divided by the device counts.</span></p><p class="c0"><span class="c18 c2 c12">x = mark_sharding(x, P(None, None, None, None, (&quot;spatial&quot;,)))</span></p><h4 class="c25" id="h.tpnhu3nu1q74"><span class="c18 c39">&#60418;Alternative Considerations</span></h4><p class="c5"><span class="c1">Tensor parallelism (TP) is another easier way. It just needs to shard the weights along contracting dimensions and the XLA will handle the TP computation and communication. However, the contracting dimension is too small to fully utilize the MXU such as dimension = 96. If we even shard the dimension along 8 devices, it becomes 12 and neither be much faster nor lower working HBM usage since the padding to (8, 128) due to the memory layout. It can reduce some latency and peak HBM usage, but not much.</span></p><h1 class="c7" id="h.yyrmdej11w01"><span class="c27 c18">Results</span></h1><p class="c5"><span class="c1">There are two cases, the first one with cat is the official I2V pipeline sample, with 832x1104 image size, and the second one is another person is singing from the official repo with 1280x720 image size. Two video generation times are slightly different. We focus on the first one with the cat, but also some with the second singing for more heavy HBM usage.</span></p><p class="c5"><span class="c17"><a href="https://www.google.com/url?q=https://drive.google.com/file/d/1vkmpq0BSJNOFRXA_B-JAzUJGsjDevIo2/view&amp;sa=D&amp;source=editors&amp;ust=1765684258227069&amp;usg=AOvVaw17hUaZuVOnfcl5mCYXymj5">20251105_094433.mp4</a></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 828.00px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 828.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c7 c30" id="h.ep2ht4ujxxrz"><span class="c27 c18"></span></h1><p class="c5"><span class="c17"><a href="https://www.google.com/url?q=https://drive.google.com/file/d/1xRR5J3gmfTo2bAhD-IfXQ_0xKVBVUcok/view&amp;sa=D&amp;source=editors&amp;ust=1765684258227198&amp;usg=AOvVaw3iqAGmn5TpzHq01E2eUXcw">20251105_094050.mp4</a></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span>The recipe is in </span><span class="c10"><a href="https://www.google.com/url?q=https://github.com/yuyanpeng-google/diffusers/tree/wan2.2-main/exp&amp;sa=D&amp;source=editors&amp;ust=1765684258227385&amp;usg=AOvVaw1SuWteu59VHkMcwQ6eB4z9">https://github.com/yuyanpeng-google/diffusers/tree/wan2.2-main/exp</a></span><span class="c1">. The default argument will generate the 720p 81 frames video of the cat. The video resolution will respect the image aspect ratio and choose the nearest pixel count video size. For the person singing, use the command:</span></p><p class="c0 c24"><span class="c1"></span></p><p class="c0"><span>&#60419;</span><span class="c2 c12">python</span><span class="c2">&nbsp;</span><span class="c2 c12">wan2p2_benchmark.py</span><span class="c2">&nbsp;</span><span class="c2 c12">--prompt</span><span class="c2">&nbsp;</span><span class="c2 c12">&quot;a</span><span class="c2">&nbsp;</span><span class="c2 c12">person</span><span class="c2">&nbsp;</span><span class="c2 c12">is</span><span class="c2">&nbsp;</span><span class="c2 c12">singing&quot;</span><span class="c2">&nbsp;</span><span class="c2 c12">--image</span><span class="c2">&nbsp;</span><span class="c2 c12">&quot;pose.png&quot;</span></p><p class="c5"><span class="c1">&#60418;</span></p><p class="c5"><span class="c1">The below times are mostly from the cat example, but few numbers are from singing.</span></p><p class="c5"><span class="c1">Time taken generating a 720p 81 frames video (second):</span></p><table class="c32"><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9 c24"><span class="c6 c21"></span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c6 c21">v6e-8</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c6 c21">v6e-16</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">Custom attention kernel + sharding DiT + jit decode function</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">306.7</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">180.6</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">Jit encode function</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">206.5</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">161.2</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">Add dp in DiT</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">200.2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span>103.4</span><span class="c35">1</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span>Padding for sp</span><span class="c35">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">197.0</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">103.4</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">Handle attention padding inside kernel</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">193.6</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">102.8</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">Jit VAE encoder, decoder</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">190.1</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">102.3</span></p></td></tr><tr class="c16"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c1">VAE spatial partition</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c11">184.7</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c11">94.5</span></p></td></tr></table><p class="c5 c24"><span class="c1"></span></p><p class="c5"><span class="c38">1</span><span>Add dp=2 unlock the cp on v6e-16 since the head_num=40 cannot divide by 16<br></span><span class="c38">2</span><span>Padding fixes the sequence length in the cat example 75348 % 8 != 0</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 385.33px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 385.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c5"><span class="c10"><a href="https://www.google.com/url?q=https://xprof.corp.google.com/trace_viewer/yuyanpeng-6866355722672242898&amp;sa=D&amp;source=editors&amp;ust=1765684258230800&amp;usg=AOvVaw0tLovANK3hPNaiJQCqZDMw">Xprof</a></span><span class="c1">&nbsp;to latest v6e-8 with singing example 3 diffusion sampling steps.</span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 364.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 364.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c7" id="h.7aamlr9mj64y"><span class="c27 c18">Reference</span></h1><ol class="lst-kix_o0aummv5mzzk-0 start" start="1"><li class="c5 c15 li-bullet-0"><span class="c17"><a href="https://www.google.com/url?q=http://b/453574996&amp;sa=D&amp;source=editors&amp;ust=1765684258231024&amp;usg=AOvVaw3eGFV7R8uiLtk47nchG2rQ">Optimize wan2.2 on v6e for &quot;Wan-AI/Wan2.2-I2V-A14B-Diffusers&quot;.</a></span></li><li class="c5 c15 li-bullet-0"><span class="c17"><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1cJw93j8gQ8r6pouA-gS4ynpbjNlkqggJ4Zs76G3Daqs/edit?resourcekey%3D0-rnX-srj_Hqsg_KsHqqYrqg%26tab%3Dt.0%23heading%3Dh.d7id8slf0vtu&amp;sa=D&amp;source=editors&amp;ust=1765684258231134&amp;usg=AOvVaw0QVffwbkQ7dhbqhft8NAqF">Wan2.1 Optimization Report</a></span></li><li class="c5 c15 li-bullet-0"><span class="c10"><a href="https://www.google.com/url?q=https://github.com/Wan-Video/Wan2.2&amp;sa=D&amp;source=editors&amp;ust=1765684258231235&amp;usg=AOvVaw1fv1hEs05vT4tMaBILf3dQ">https://github.com/Wan-Video/Wan2.2</a></span></li><li class="c5 c15 li-bullet-0"><span class="c10"><a href="https://www.google.com/url?q=https://github.com/yuyanpeng-google/diffusers/tree/wan2.2-main&amp;sa=D&amp;source=editors&amp;ust=1765684258231368&amp;usg=AOvVaw040dXFA3lmKtHrlh5j0lKu">https://github.com/yuyanpeng-google/diffusers/tree/wan2.2-main</a></span></li><li class="c5 c15 li-bullet-0"><span class="c10"><a href="https://www.google.com/url?q=https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers&amp;sa=D&amp;source=editors&amp;ust=1765684258231502&amp;usg=AOvVaw2zCA452PA3ATO2kD7qyMFP">https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers</a></span></li><li class="c5 c15 li-bullet-0"><span class="c17"><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1gXJnWQU9khfghDfO8MF4WMLQvZIi5elxOHCP28Ls0B0/edit?resourcekey%3D0-f4cXiX4nsgapyWFgmTAwsA%26tab%3Dt.3ky4w71l3lhy%23heading%3Dh.mgny6fdyi6il&amp;sa=D&amp;source=editors&amp;ust=1765684258231615&amp;usg=AOvVaw2UvD4_Gvtuo_7pAc1bi1Qn">WAN 2.1 Inference</a></span></li><li class="c5 c15 li-bullet-0"><span class="c10"><a href="https://www.google.com/url?q=https://g3doc.corp.google.com/platforms/xla/service/jellyfish/g3doc/spatial_partitioning.md?cl%3Dhead%23convolution&amp;sa=D&amp;source=editors&amp;ust=1765684258231816&amp;usg=AOvVaw3I8zRZNgzb18H4laxS0wEO">https://g3doc.corp.google.com/platforms/xla/service/jellyfish/g3doc/spatial_partitioning.md?cl=head#convolution</a></span></li><li class="c5 c15 li-bullet-0"><span class="c17"><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1-SQneQk-Ciy3c7o0ecaGnixVMwKHaMRBAIsFRZ4nnRs/edit?resourcekey%3D0-JSF2erehuijMCyapmPdbyQ%26tab%3Dt.0%23heading%3Dh.g30huzokkzwx&amp;sa=D&amp;source=editors&amp;ust=1765684258231927&amp;usg=AOvVaw0qIl68uKrNfblqKirPvLdq">[External] Wan2.1-14B Text to Video Model Optimization on TPU v6e-16</a></span></li><li class="c5 c15 li-bullet-0"><span class="c17"><a href="https://www.google.com/url?q=https://colab.research.google.com/drive/17XtIiqMp1wc8rAe4oW4Qw6eA8QOGsw5j?usp%3Dsharing&amp;sa=D&amp;source=editors&amp;ust=1765684258232011&amp;usg=AOvVaw3PGSAGhHbDdIVGHn2Sy5L-">Compare segment_id impact.ipynb</a></span></li><li class="c5 c15 li-bullet-0"><span class="c10"><a href="https://www.google.com/url?q=https://xprof.corp.google.com/trace_viewer/yuyanpeng-6866355722672242898?hosts%3Dt1v-n-000650b9-w-0%26host_index%3D0%26trace_filter_config%3D%257B%257D%26view_start%3D7653.835%26view_end%3D21175.853&amp;sa=D&amp;source=editors&amp;ust=1765684258232281&amp;usg=AOvVaw08F8ssThlrwbTNwEnQ4fHx">https://xprof.corp.google.com/trace_viewer/yuyanpeng-6866355722672242898?hosts=t1v-n-000650b9-w-0&amp;host_index=0&amp;trace_filter_config={}&amp;view_start=7653.835&amp;view_end=21175.853</a></span></li></ol><ol class="lst-kix_o0aummv5mzzk-1 start" start="1"><li class="c5 c20 li-bullet-0"><span class="c1">Xprof to latest v6e-8 singing example</span></li></ol><p class="c5 c24"><span class="c1"></span></p></body></html>