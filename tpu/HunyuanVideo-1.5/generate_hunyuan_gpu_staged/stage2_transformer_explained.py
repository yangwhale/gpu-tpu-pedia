#!/usr/bin/env python3
"""
================================================================================
HunyuanVideo-1.5 ä¸‰é˜¶æ®µç”Ÿæˆ - é˜¶æ®µ2ï¼šTransformer (DiT) (GPU ç‰ˆæœ¬)
================================================================================

è¿™ä¸ªæ–‡ä»¶æ˜¯ HunyuanVideo-1.5 è§†é¢‘ç”Ÿæˆæµæ°´çº¿çš„ç¬¬äºŒé˜¶æ®µï¼šTransformer æ¨ç†ã€‚

================================================================================
ğŸ“š å®Œæ•´è°ƒç”¨æµç¨‹æ¦‚è§ˆ
================================================================================

HunyuanVideo-1.5 ä½¿ç”¨"ä¸‰é˜¶æ®µ"æ¶æ„æ¥ç”Ÿæˆè§†é¢‘ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Text Encoding (æ–‡æœ¬ç¼–ç )                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ è¾“å…¥: æ–‡æœ¬ prompt (å¦‚ "a cat walking in the garden")                          â”‚
â”‚ è¾“å‡º: text embeddings (æ–‡æœ¬åµŒå…¥å‘é‡) - å…± 8 ä¸ª tensor                         â”‚
â”‚                                                                             â”‚
â”‚ ä½¿ç”¨æ¨¡å‹ (é¡ºåºæ‰§è¡Œï¼Œå› ä¸ºæ˜¾å­˜é™åˆ¶):                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ æ­¥éª¤ 1: LLaVA (å¤§è¯­è¨€æ¨¡å‹)                                            â”‚  â”‚
â”‚   â”‚   - è¾“å…¥: prompt æ–‡æœ¬                                                 â”‚  â”‚
â”‚   â”‚   - è¾“å‡º: prompt_embeds (è¯­ä¹‰çº§åˆ«çš„ç†è§£)                              â”‚  â”‚
â”‚   â”‚   - å†…å­˜: ~14GB                                                       â”‚  â”‚
â”‚   â”‚   - å®Œæˆå: å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾æ˜¾å­˜                                         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ æ­¥éª¤ 2: ByT5 (å­—èŠ‚çº§æ–‡æœ¬ç¼–ç å™¨)                                        â”‚  â”‚
â”‚   â”‚   - è¾“å…¥: prompt æ–‡æœ¬ (ç›¸åŒçš„è¾“å…¥ï¼Œç‹¬ç«‹å¤„ç†)                           â”‚  â”‚
â”‚   â”‚   - è¾“å‡º: prompt_embeds_2 (å­—ç¬¦çº§åˆ«çš„ç‰¹å¾)                            â”‚  â”‚
â”‚   â”‚   - å†…å­˜: ~5GB                                                        â”‚  â”‚
â”‚   â”‚   - å®Œæˆå: å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾æ˜¾å­˜                                         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆæ˜¯é¡ºåºè€Œä¸æ˜¯å¹¶è¡Œï¼Ÿã€‘                                                  â”‚
â”‚   - LLaVA (~14GB) + ByT5 (~5GB) = ~19GB åŒæ—¶åŠ è½½                            â”‚
â”‚   - é¡ºåºæ‰§è¡Œå¯ä»¥åœ¨åŒä¸€å¼ å¡ä¸Šå®Œæˆï¼Œé™ä½ç¡¬ä»¶è¦æ±‚                                 â”‚
â”‚   - ä¸¤è€…å¤„ç†çš„æ˜¯ç›¸åŒçš„è¾“å…¥æ–‡æœ¬ï¼Œä½†æå–ä¸åŒå±‚æ¬¡çš„ç‰¹å¾                           â”‚
â”‚   - ä»é€»è¾‘ä¸Šå®ƒä»¬æ˜¯ç‹¬ç«‹çš„ï¼Œå¦‚æœæœ‰è¶³å¤Ÿæ˜¾å­˜ï¼Œç†è®ºä¸Šå¯ä»¥å¹¶è¡Œ                        â”‚
â”‚                                                                             â”‚
â”‚ æ€»å†…å­˜å³°å€¼: ~14GB (LLaVA æœ€å¤§)                                               â”‚
â”‚                                                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ ã€Stage 1 è¾“å‡ºçš„ 8 ä¸ª Tensor è¯¦è§£ã€‘                                          â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                             â”‚
â”‚ è¿™ 8 ä¸ª tensor åˆ†ä¸ºä¸¤ç»„ï¼šæ­£å‘ (positive) å’Œè´Ÿå‘ (negative)                    â”‚
â”‚ æ¯ç»„æœ‰ 4 ä¸ª tensorï¼šLLM embeddings + maskï¼ŒByT5 embeddings + mask            â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ç»„ 1: LLaVA (LLM) è¾“å‡º - è¯­ä¹‰çº§åˆ«çš„æ–‡æœ¬ç†è§£                              â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 1. prompt_embeds (1Ã—1000Ã—3584) - 3D                                     â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: (batch, seq_len, hidden_dim)                                â”‚ â”‚
â”‚ â”‚    â”œâ”€ 1: batch size                                                     â”‚ â”‚
â”‚ â”‚    â”œâ”€ 1000: æœ€å¤§ token åºåˆ—é•¿åº¦ (å›ºå®šé•¿åº¦ï¼ŒçŸ­çš„ä¼š padding)               â”‚ â”‚
â”‚ â”‚    â”œâ”€ 3584: LLaVA çš„éšè—å±‚ç»´åº¦                                          â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: æ­£å‘æç¤ºè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå‘Šè¯‰æ¨¡å‹"è¦ç”Ÿæˆä»€ä¹ˆ"                    â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 2. negative_prompt_embeds (1Ã—1000Ã—3584) - 3D                            â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: åŒä¸Š                                                        â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå‘Šè¯‰æ¨¡å‹"ä¸è¦ç”Ÿæˆä»€ä¹ˆ"                  â”‚ â”‚
â”‚ â”‚           ç”¨äº CFG (Classifier-Free Guidance) è®¡ç®—                      â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 3. prompt_embeds_mask (1Ã—1000) - 2D                                     â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: (batch, seq_len)                                            â”‚ â”‚
â”‚ â”‚    â”œâ”€ å€¼: 1 è¡¨ç¤ºçœŸå® tokenï¼Œ0 è¡¨ç¤º padding                               â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: æ³¨æ„åŠ› maskï¼Œè®©æ¨¡å‹å¿½ç•¥ padding éƒ¨åˆ†                         â”‚ â”‚
â”‚ â”‚           ä¾‹å¦‚: "a cat" åªæœ‰ 2 ä¸ª tokenï¼Œå…¶ä½™ 998 ä¸ªä½ç½®æ˜¯ padding       â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 4. negative_prompt_embeds_mask (1Ã—1000) - 2D                            â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„æ³¨æ„åŠ› mask                                      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ç»„ 2: ByT5 è¾“å‡º - å­—ç¬¦çº§åˆ«çš„æ–‡æœ¬ç‰¹å¾                                     â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 5. prompt_embeds_2 (1Ã—256Ã—1472) - 3D                                    â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: (batch, seq_len, hidden_dim)                                â”‚ â”‚
â”‚ â”‚    â”œâ”€ 256: æœ€å¤§å­—èŠ‚åºåˆ—é•¿åº¦ (ByT5 æŒ‰å­—èŠ‚/å­—ç¬¦å¤„ç†)                       â”‚ â”‚
â”‚ â”‚    â”œâ”€ 1472: ByT5 çš„éšè—å±‚ç»´åº¦                                           â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: å­—ç¬¦çº§åˆ«çš„æ–‡æœ¬è¡¨ç¤º                                          â”‚ â”‚
â”‚ â”‚           å¸®åŠ©æ¨¡å‹ç†è§£ç²¾ç¡®çš„æ‹¼å†™ã€æ ¼å¼ã€ç¬¦å·ç­‰                           â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 6. negative_prompt_embeds_2 (1Ã—256Ã—1472) - 3D                           â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„å­—ç¬¦çº§è¡¨ç¤º                                       â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 7. prompt_embeds_mask_2 (1Ã—256) - 2D                                    â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: ByT5 çš„æ³¨æ„åŠ› mask                                          â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 8. negative_prompt_embeds_mask_2 (1Ã—256) - 2D                           â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„ ByT5 æ³¨æ„åŠ› mask                                â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆæœ‰ 2D å’Œ 3Dï¼Ÿã€‘                                                      â”‚
â”‚                                                                             â”‚
â”‚   3D Tensor (embeddings):                                                   â”‚
â”‚   â”œâ”€ shape: (batch, seq_len, hidden_dim)                                    â”‚
â”‚   â””â”€ åŒ…å«å®é™…çš„è¯­ä¹‰ä¿¡æ¯ï¼Œæ¯ä¸ª token ç”¨ä¸€ä¸ª hidden_dim ç»´å‘é‡è¡¨ç¤º             â”‚
â”‚                                                                             â”‚
â”‚   2D Tensor (masks):                                                        â”‚
â”‚   â”œâ”€ shape: (batch, seq_len)                                                â”‚
â”‚   â””â”€ åªéœ€è¦æ ‡è®°æ¯ä¸ªä½ç½®æ˜¯å¦æœ‰æ•ˆï¼Œä¸éœ€è¦é¢å¤–çš„ç»´åº¦                             â”‚
â”‚       0/1 æ ‡è®°è¶³çŸ£                                                          â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸¤ç§ Text Embedding å¦‚ä½•ç»“åˆä½¿ç”¨ï¼Ÿ- æºç åˆ†æã€‘                              â”‚
â”‚                                                                             â”‚
â”‚ âš ï¸  é‡è¦ï¼šä¸æ˜¯ä¸¤æ¬¡äº¤å‰æ³¨æ„åŠ›ï¼Œè€Œæ˜¯æ‹¼æ¥ååšä¸€æ¬¡è”åˆæ³¨æ„åŠ›ï¼                      â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                    å¤„ç†æµç¨‹ï¼ˆåœ¨ forward() ä¸­ï¼‰                            â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 1: LLaVA embeddings æŠ•å½±                                          â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚ â”‚
â”‚ â”‚  # ä½¿ç”¨ SingleTokenRefiner å¤„ç† LLaVA embeddings                        â”‚ â”‚
â”‚ â”‚  txt = self.txt_in(txt, t, text_mask)                                   â”‚ â”‚
â”‚ â”‚  # txt shape: (B, 1000, 3072) - æŠ•å½±åˆ° hidden_size                      â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 2: ByT5 embeddings æŠ•å½±                                           â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚ â”‚
â”‚ â”‚  if self.glyph_byT5_v2:                                                 â”‚ â”‚
â”‚ â”‚      byt5_text_states = extra_kwargs["byt5_text_states"]                â”‚ â”‚
â”‚ â”‚      byt5_txt = self.byt5_in(byt5_text_states)                          â”‚ â”‚
â”‚ â”‚      # byt5_txt shape: (B, 256, 3072) - ä¹ŸæŠ•å½±åˆ° hidden_size            â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 3: â˜… å…³é”® â˜… æ‹¼æ¥ä¸¤ç§ text tokens                                   â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚ â”‚
â”‚ â”‚  # reorder_txt_token() å‡½æ•°å°†ä¸¤è€…æ‹¼æ¥æˆä¸€ä¸ªåºåˆ—                          â”‚ â”‚
â”‚ â”‚  txt, text_mask = self.reorder_txt_token(                               â”‚ â”‚
â”‚ â”‚      byt5_txt,      # ByT5 tokens                                       â”‚ â”‚
â”‚ â”‚      txt,           # LLaVA tokens                                      â”‚ â”‚
â”‚ â”‚      byt5_text_mask,                                                    â”‚ â”‚
â”‚ â”‚      text_mask                                                          â”‚ â”‚
â”‚ â”‚  )                                                                      â”‚ â”‚
â”‚ â”‚  # æ‹¼æ¥å txt shape: (B, 256+1000, 3072) = (B, 1256, 3072)              â”‚ â”‚
â”‚ â”‚  # æ‹¼æ¥é¡ºåº: [ByT5æœ‰æ•ˆtokens, LLaVAæœ‰æ•ˆtokens, ByT5 padding, LLaVA pad] â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 4: è”åˆæ³¨æ„åŠ›ï¼ˆä¸æ˜¯åˆ†å¼€çš„ä¸¤æ¬¡ï¼ï¼‰                                    â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚ â”‚
â”‚ â”‚  for block in self.double_blocks:                                       â”‚ â”‚
â”‚ â”‚      img, txt = block(img, txt, ...)                                    â”‚ â”‚
â”‚ â”‚      # txt åŒ…å«æ‹¼æ¥åçš„ LLaVA+ByT5ï¼Œä½œä¸ºä¸€ä¸ªæ•´ä½“å‚ä¸æ³¨æ„åŠ›               â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚           MMDoubleStreamBlock å†…éƒ¨ç»“æ„ï¼ˆæºç ç¬¬ 43-204 è¡Œï¼‰                â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚ â”‚  â”‚  img (è§†é¢‘)  â”‚     â”‚  txt (LLaVA + ByT5 æ‹¼æ¥å)      â”‚                â”‚ â”‚
â”‚ â”‚  â”‚  tokens     â”‚     â”‚  = 1256 ä¸ª tokens               â”‚                â”‚ â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚ â”‚         â”‚                             â”‚                                  â”‚ â”‚
â”‚ â”‚         â–¼                             â–¼                                  â”‚ â”‚
â”‚ â”‚   img_q, img_k, img_v          txt_q, txt_k, txt_v                       â”‚ â”‚
â”‚ â”‚         â”‚                             â”‚                                  â”‚ â”‚
â”‚ â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚ â”‚
â”‚ â”‚                       â–¼                                                  â”‚ â”‚
â”‚ â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚ â”‚
â”‚ â”‚         â”‚     parallel_attention()         â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  è”åˆè®¡ç®— img å’Œ txt çš„æ³¨æ„åŠ›     â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  img tokens å¯ä»¥ attend to:      â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚    - å…¶ä»– img tokens             â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚    - LLaVA text tokens           â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚    - ByT5 text tokens            â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  ï¼ˆæ‰€æœ‰ text tokens åœ¨åŒä¸€åºåˆ—ä¸­ï¼‰â”‚                              â”‚ â”‚
â”‚ â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚ â”‚
â”‚ â”‚                       â”‚                                                  â”‚ â”‚
â”‚ â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚ â”‚
â”‚ â”‚         â–¼                             â–¼                                  â”‚ â”‚
â”‚ â”‚   img_attn                      txt_attn                                 â”‚ â”‚
â”‚ â”‚         â”‚                             â”‚                                  â”‚ â”‚
â”‚ â”‚         â–¼                             â–¼                                  â”‚ â”‚
â”‚ â”‚   img + FFN                     txt + FFN                                â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ ã€å…³é”®æ¾„æ¸…ï¼šparallel_attention() ä¸æ˜¯"åˆ†å¼€åš"ï¼ã€‘                           â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                             â”‚
â”‚   âš ï¸ åå­—å®¹æ˜“è¯¯å¯¼ï¼parallel ä¸æ˜¯æŒ‡ img å’Œ txt åˆ†å¼€å¹¶è¡Œåš attention          â”‚
â”‚                                                                             â”‚
â”‚   ã€parallel_attention() çš„çœŸå®å«ä¹‰ã€‘ï¼ˆæºç  attention.py ç¬¬ 112-117 è¡Œï¼‰    â”‚
â”‚                                                                             â”‚
â”‚   ```python                                                                 â”‚
â”‚   def parallel_attention(q, k, v, img_q_len, img_kv_len, ...):              â”‚
â”‚       return sequence_parallel_attention(q, k, v, ...)                      â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   "Parallel" æŒ‡çš„æ˜¯:                                                        â”‚
â”‚   1. Sequence Parallelism (SP) - å¤š GPU åºåˆ—å¹¶è¡Œ                            â”‚
â”‚   2. ä¸æ˜¯æŒ‡ img/txt åˆ†å¼€å¹¶è¡Œï¼                                               â”‚
â”‚                                                                             â”‚
â”‚   ã€å®é™…æ‰§è¡Œè¿‡ç¨‹ã€‘ï¼ˆæºç  attention.py ç¬¬ 162-164 è¡Œï¼‰                        â”‚
â”‚                                                                             â”‚
â”‚   ```python                                                                 â”‚
â”‚   # è¾“å…¥æ˜¯åˆ†å¼€çš„                                                            â”‚
â”‚   query, encoder_query = q  # (img_q, txt_q)                                â”‚
â”‚   key, encoder_key = k      # (img_k, txt_k)                                â”‚
â”‚   value, encoder_value = v  # (img_v, txt_v)                                â”‚
â”‚                                                                             â”‚
â”‚   # â˜… å…³é”®ï¼šåœ¨è®¡ç®—å‰æ‹¼æ¥æˆä¸€ä¸ªåºåˆ—ï¼                                        â”‚
â”‚   query = torch.cat([query, encoder_query], dim=1)  # [img + txt]           â”‚
â”‚   key = torch.cat([key, encoder_key], dim=1)                                â”‚
â”‚   value = torch.cat([value, encoder_value], dim=1)                          â”‚
â”‚                                                                             â”‚
â”‚   # ç„¶ååšä¸€æ¬¡ attentionï¼ˆä¸æ˜¯åˆ†å¼€åšä¸¤æ¬¡ï¼ï¼‰                                 â”‚
â”‚   hidden_states = flash_attn_no_pad(...)  # ä¸€æ¬¡ joint attention           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ã€å›¾è§£ï¼šæ‹¼æ¥åçš„ Joint Attentionã€‘                                         â”‚
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  æ‹¼æ¥å‰ï¼ˆè¾“å…¥ï¼‰           æ‹¼æ¥åï¼ˆè®¡ç®—æ—¶ï¼‰                            â”‚  â”‚
â”‚   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚  â”‚
â”‚   â”‚  img_q: (B, 46800, H, D)                                              â”‚  â”‚
â”‚   â”‚  txt_q: (B, 1256, H, D)  â†’ query: (B, 48056, H, D)                    â”‚  â”‚
â”‚   â”‚                             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚  â”‚
â”‚   â”‚                             â”‚ æ‹¼æ¥æˆä¸€ä¸ªå¤§åºåˆ—    â”‚                    â”‚  â”‚
â”‚   â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    Attention çŸ©é˜µç»“æ„                                 â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚                        Key (48056)                                    â”‚  â”‚
â”‚   â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚  â”‚
â”‚   â”‚                    â”‚   img_k   â”‚  txt_k   â”‚                           â”‚  â”‚
â”‚   â”‚                    â”‚  (46800)  â”‚ (1256)   â”‚                           â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                           â”‚  â”‚
â”‚   â”‚   â”‚   img_q        â”‚           â”‚          â”‚                           â”‚  â”‚
â”‚   â”‚   â”‚  (46800)       â”‚  imgâ†”img  â”‚  imgâ†”txt â”‚ â† img å¯ä»¥ attend åˆ°æ‰€æœ‰   â”‚  â”‚
â”‚   â”‚ Q â”‚                â”‚           â”‚          â”‚                           â”‚  â”‚
â”‚   â”‚ u â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                           â”‚  â”‚
â”‚   â”‚ e â”‚   txt_q        â”‚           â”‚          â”‚                           â”‚  â”‚
â”‚   â”‚ r â”‚  (1256)        â”‚  txtâ†”img  â”‚  txtâ†”txt â”‚ â† txt ä¹Ÿå¯ä»¥ attend åˆ°æ‰€æœ‰ â”‚  â”‚
â”‚   â”‚ y â”‚                â”‚           â”‚          â”‚                           â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚   æ•´ä¸ªçŸ©é˜µåœ¨ä¸€æ¬¡ attention è®¡ç®—ä¸­å®Œæˆ                                 â”‚  â”‚
â”‚   â”‚   ä¸æ˜¯åˆ†å¼€è®¡ç®— img-img, img-txt, txt-img, txt-txt                    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   ã€ä¸ºä»€ä¹ˆåå­—å« parallel_attentionï¼Ÿã€‘                                     â”‚
â”‚                                                                             â”‚
â”‚   1. Sequence Parallelism (SP) æ”¯æŒ:                                        â”‚
â”‚      å½“å¯ç”¨å¤š GPU SP æ—¶ï¼Œä¼šåš all-to-all é€šä¿¡                               â”‚
â”‚      ```python                                                              â”‚
â”‚      if enable_sp:                                                          â”‚
â”‚          query = all_to_all_4D(query, sp_group, ...)                        â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   2. åŒå‘å¹¶è¡Œäº¤äº’:                                                          â”‚
â”‚      img â†” txt å¯ä»¥äº’ç›¸ attendï¼ˆä¸æ˜¯å•å‘çš„ cross-attentionï¼‰               â”‚
â”‚                                                                             â”‚
â”‚   3. å†å²å‘½å:                                                              â”‚
â”‚      å¯èƒ½æ¥è‡ª MM-DiT (Multimodal DiT) æ¶æ„çš„å‘½åä¹ æƒ¯                        â”‚
â”‚                                                                             â”‚
â”‚   ã€å¯¹æ¯”ï¼šçœŸæ­£çš„ Cross-Attention vs Joint Attentionã€‘                       â”‚
â”‚                                                                             â”‚
â”‚   Cross-Attentionï¼ˆå¦‚ Stable Diffusionï¼‰:                                   â”‚
â”‚   ```                                                                       â”‚
â”‚   Q = img                                                                   â”‚
â”‚   K, V = text                                                               â”‚
â”‚   output = softmax(Q @ K.T) @ V  â† å•å‘ï¼šimg attend to text                 â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   Joint Attentionï¼ˆHunyuanVideo ä½¿ç”¨çš„ï¼‰:                                   â”‚
â”‚   ```                                                                       â”‚
â”‚   Q = [img_q, txt_q]                                                        â”‚
â”‚   K = [img_k, txt_k]                                                        â”‚
â”‚   V = [img_v, txt_v]                                                        â”‚
â”‚   output = softmax(Q @ K.T) @ V  â† åŒå‘ï¼šimg â†” txt äº’ç›¸ attend             â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   HunyuanVideo é€‰æ‹© Joint Attention çš„åŸå› :                                â”‚
â”‚   - æ–‡æœ¬å¯ä»¥"çœ‹åˆ°"è§†é¢‘ï¼Œè°ƒæ•´è‡ªå·±çš„è¡¨ç¤º                                      â”‚
â”‚   - è§†é¢‘å¯ä»¥"çœ‹åˆ°"æ–‡æœ¬ï¼Œè·å–è¯­ä¹‰ä¿¡æ¯                                        â”‚
â”‚   - åŒå‘äº¤äº’æ¯”å•å‘æ›´å¼ºå¤§                                                    â”‚
â”‚                                                                             â”‚
â”‚   ã€åšå®Œ parallel_attention() åå¦‚ä½•åˆ†å¼€ img_attn å’Œ txt_attnï¼Ÿã€‘           â”‚
â”‚                                                                             â”‚
â”‚   ç­”æ¡ˆï¼šé€šè¿‡ä½ç½®åˆ‡ç‰‡ï¼å› ä¸ºçŸ¥é“æ‹¼æ¥æ—¶çš„åˆ†ç•Œç‚¹ã€‚                               â”‚
â”‚                                                                             â”‚
â”‚   æºç  hunyuanvideo_1_5_transformer.py ç¬¬ 188 è¡Œ:                           â”‚
â”‚   ```python                                                                 â”‚
â”‚   # parallel_attention è¿”å›æ‹¼æ¥çš„ç»“æœ                                       â”‚
â”‚   attn = parallel_attention(                                                â”‚
â”‚       (img_q, txt_q),     # è¾“å…¥æ˜¯å…ƒç»„                                      â”‚
â”‚       (img_k, txt_k),                                                       â”‚
â”‚       (img_v, txt_v),                                                       â”‚
â”‚       img_q_len=img_q.shape[1],  # â˜… å…³é”®ï¼šä¼ å…¥ img çš„é•¿åº¦                 â”‚
â”‚       img_kv_len=img_k.shape[1],                                            â”‚
â”‚       ...                                                                   â”‚
â”‚   )                                                                         â”‚
â”‚   # attn shape: (B, img_len + txt_len, H, D)                                â”‚
â”‚   #             (B, 46800 + 1256, H, D) = (B, 48056, H, D)                   â”‚
â”‚                                                                             â”‚
â”‚   # â˜… å…³é”®ï¼šé€šè¿‡åˆ‡ç‰‡åˆ†å¼€ï¼                                                  â”‚
â”‚   img_attn = attn[:, :img_q.shape[1]].contiguous()   # å‰ 46800 ä¸ª          â”‚
â”‚   txt_attn = attn[:, img_q.shape[1]:].contiguous()   # å 1256 ä¸ª           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   å›¾è§£:                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚  parallel_attention è¾“å‡º:                                             â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚   â”‚  â”‚     img_attn (46800 tokens)     â”‚   txt_attn (1256 tokens)    â”‚   â”‚  â”‚
â”‚   â”‚  â”‚    ç»è¿‡ attention åçš„è§†é¢‘è¡¨ç¤º   â”‚  ç»è¿‡ attention åçš„æ–‡æœ¬è¡¨ç¤º â”‚   â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚   â”‚                      â†‘                           â†‘                    â”‚  â”‚
â”‚   â”‚                      â”‚                           â”‚                    â”‚  â”‚
â”‚   â”‚              [:, :img_q.shape[1]]       [:, img_q.shape[1]:]         â”‚  â”‚
â”‚   â”‚                      â”‚                           â”‚                    â”‚  â”‚
â”‚   â”‚                      â–¼                           â–¼                    â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚
â”‚   â”‚  â”‚ img = img + img_attn    â”‚   â”‚ txt = txt + txt_attn    â”‚           â”‚  â”‚
â”‚   â”‚  â”‚      (æ®‹å·®è¿æ¥)          â”‚   â”‚      (æ®‹å·®è¿æ¥)          â”‚           â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚
â”‚   â”‚                      â”‚                           â”‚                    â”‚  â”‚
â”‚   â”‚                      â–¼                           â–¼                    â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚
â”‚   â”‚  â”‚ img = img + FFN(img)    â”‚   â”‚ txt = txt + FFN(txt)    â”‚           â”‚  â”‚
â”‚   â”‚  â”‚      (å‰é¦ˆç½‘ç»œ)          â”‚   â”‚      (å‰é¦ˆç½‘ç»œ)          â”‚           â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆåˆ†å¼€åè¿˜è¦å„è‡ªå¤„ç†ï¼Ÿ                                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚   è™½ç„¶ attention æ˜¯è”åˆè®¡ç®—çš„ï¼Œä½†åç»­çš„ï¼š                                   â”‚
â”‚   1. Attention è¾“å‡ºæŠ•å½± (img_attn_proj / txt_attn_proj)                    â”‚
â”‚   2. FFN (img_mlp / txt_mlp)                                               â”‚
â”‚   3. Modulation (img_mod / txt_mod)                                        â”‚
â”‚   4. æ®‹å·®è¿æ¥                                                               â”‚
â”‚                                                                             â”‚
â”‚   éƒ½æ˜¯åˆ†å¼€çš„ï¼è¿™æ˜¯ "Double Stream" çš„å«ä¹‰ï¼š                                 â”‚
â”‚   - ä¸¤ä¸ª"æµ"ï¼ˆimg å’Œ txtï¼‰åœ¨ attention æ—¶äº¤æ±‡                              â”‚
â”‚   - äº¤æ±‡ååˆåˆ†å¼€ï¼Œå„è‡ªåšåç»­å¤„ç†                                            â”‚
â”‚   - æ¯ä¸ªæµæœ‰è‡ªå·±çš„æƒé‡ï¼ˆä¸å…±äº«ï¼‰                                            â”‚
â”‚                                                                             â”‚
â”‚   æºç  hunyuanvideo_1_5_transformer.py ç¬¬ 190-202 è¡Œ:                       â”‚
â”‚   ```python                                                                 â”‚
â”‚   # åˆ†åˆ«æŠ•å½±å’Œæ®‹å·®è¿æ¥                                                      â”‚
â”‚   img = img + apply_gate(self.img_attn_proj(img_attn), gate=img_mod1_gate)  â”‚
â”‚   img = img + apply_gate(self.img_mlp(...), gate=img_mod2_gate)             â”‚
â”‚                                                                             â”‚
â”‚   txt = txt + apply_gate(self.txt_attn_proj(txt_attn), gate=txt_mod1_gate)  â”‚
â”‚   txt = txt + apply_gate(self.txt_mlp(...), gate=txt_mod2_gate)             â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ã€Double Stream vs Single Streamã€‘                                        â”‚
â”‚                                                                             â”‚
â”‚   HunyuanVideo æœ‰ä¸¤ç§ block:                                                â”‚
â”‚                                                                             â”‚
â”‚   1. MMDoubleStreamBlock (å‰ 20 å±‚):                                        â”‚
â”‚      - img å’Œ txt å„æœ‰ç‹¬ç«‹çš„ FFN                                            â”‚
â”‚      - attention è”åˆï¼Œå…¶ä»–åˆ†å¼€                                             â”‚
â”‚      - æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›                                                       â”‚
â”‚                                                                             â”‚
â”‚   2. MMSingleStreamBlock (å 40 å±‚):                                        â”‚
â”‚      - img å’Œ txt åˆå¹¶æˆä¸€ä¸ªåºåˆ—                                            â”‚
â”‚      - å…±äº« FFN                                                             â”‚
â”‚      - æ›´é«˜æ•ˆ                                                               â”‚
â”‚                                                                             â”‚
â”‚   æºç ç¬¬ 821-825 è¡Œ:                                                        â”‚
â”‚   ```python                                                                 â”‚
â”‚   # Single stream: åˆå¹¶åä¸å†åˆ†å¼€                                           â”‚
â”‚   txt_seq_len = txt.shape[1]                                                â”‚
â”‚   x = torch.cat((img, txt), 1)  # åˆå¹¶                                      â”‚
â”‚   for block in self.single_blocks:                                          â”‚
â”‚       x = block(x, vec, txt_len=txt_seq_len, ...)                           â”‚
â”‚   img = x[:, :img_seq_len, ...]  # æœ€åæ‰åˆ†å¼€                               â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ã€.contiguous() æ˜¯å¹²ä»€ä¹ˆçš„ï¼Ÿã€‘                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚                                                                             â”‚
â”‚   PyTorch ä¸­ï¼Œtensor çš„æ•°æ®åœ¨å†…å­˜ä¸­å¯èƒ½æ˜¯"éè¿ç»­"çš„ã€‚                       â”‚
â”‚   .contiguous() ç¡®ä¿æ•°æ®åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­å­˜å‚¨çš„ã€‚                              â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆä¼šä¸è¿ç»­ï¼Ÿ                                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚
â”‚   ```python                                                                 â”‚
â”‚   # åŸå§‹ tensor æ˜¯è¿ç»­çš„                                                    â”‚
â”‚   attn = torch.randn(2, 48056, 24, 128)  # [B, seq, H, D]                   â”‚
â”‚   # å†…å­˜å¸ƒå±€: [a0, a1, a2, ..., a48055] è¿ç»­å­˜å‚¨                            â”‚
â”‚                                                                             â”‚
â”‚   # åˆ‡ç‰‡æ“ä½œåªæ”¹å˜"è§†å›¾"ï¼Œä¸å¤åˆ¶æ•°æ®                                        â”‚
â”‚   img_attn = attn[:, :46800]                                                â”‚
â”‚   # img_attn "çœ‹"çš„æ˜¯åŸå§‹å†…å­˜çš„å‰ 46800 ä¸ªä½ç½®                              â”‚
â”‚   # ä½†å®ƒè‡ªå·±çš„ stride å’ŒåŸå§‹ tensor ä¸åŒ                                    â”‚
â”‚   # å®é™…æ•°æ®ä»åœ¨åŸä½ç½®ï¼Œåªæ˜¯"è·³ç€çœ‹"                                        â”‚
â”‚                                                                             â”‚
â”‚   # è¿™æ—¶ img_attn.is_contiguous() == False                                  â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   å›¾è§£å†…å­˜å¸ƒå±€:                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  åŸå§‹ tensor attn åœ¨å†…å­˜ä¸­çš„å¸ƒå±€ (è¿ç»­çš„):                            â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”              â”‚  â”‚
â”‚   â”‚  â”‚ 0 â”‚ 1 â”‚ 2 â”‚...â”‚46799â”‚46800â”‚...â”‚48055â”‚                â”‚              â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜                â”‚              â”‚  â”‚
â”‚   â”‚  â”‚â† â”€ â”€ â”€ img_attn â”€ â”€ â”€â†’â”‚â†txt_attnâ†’â”‚                   â”‚              â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚  åˆ‡ç‰‡åï¼Œimg_attn æ˜¯ attn çš„"è§†å›¾"ï¼š                                  â”‚  â”‚
â”‚   â”‚  - ä¸å¤åˆ¶æ•°æ®                                                         â”‚  â”‚
â”‚   â”‚  - åªæ˜¯è®°å½•"ä»å“ªå¼€å§‹ï¼Œæ­¥é•¿å¤šå°‘"                                       â”‚  â”‚
â”‚   â”‚  - is_contiguous() == Falseï¼ˆå› ä¸ºåé¢è¿˜æœ‰ txt_attn çš„æ•°æ®ï¼‰           â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆéœ€è¦ .contiguous()ï¼Ÿ                                                â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚   1. æŸäº›æ“ä½œéœ€è¦è¿ç»­å†…å­˜:                                                  â”‚
â”‚      - view(), reshape() ç­‰å½¢çŠ¶å˜æ¢                                        â”‚
â”‚      - ä¸€äº› CUDA kernel                                                    â”‚
â”‚      - Flash Attention ç­‰é«˜æ•ˆå®ç°                                          â”‚
â”‚                                                                             â”‚
â”‚   2. æ€§èƒ½ä¼˜åŒ–:                                                              â”‚
â”‚      - è¿ç»­å†…å­˜è®¿é—®æ›´å¿«ï¼ˆç¼“å­˜å‹å¥½ï¼‰                                        â”‚
â”‚      - é¿å…åç»­æ“ä½œæŠ¥é”™                                                    â”‚
â”‚                                                                             â”‚
â”‚   .contiguous() åšäº†ä»€ä¹ˆï¼Ÿ                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚   ```python                                                                 â”‚
â”‚   img_attn = attn[:, :46800].contiguous()                                   â”‚
â”‚   # 1. åˆ†é…æ–°çš„å†…å­˜ç©ºé—´                                                     â”‚
â”‚   # 2. å¤åˆ¶æ•°æ®åˆ°æ–°ç©ºé—´ï¼Œä½¿å…¶è¿ç»­                                           â”‚
â”‚   # 3. è¿”å›æ–°çš„ tensor                                                      â”‚
â”‚                                                                             â”‚
â”‚   # ç°åœ¨ img_attn.is_contiguous() == True                                   â”‚
â”‚   # å¯ä»¥å®‰å…¨åœ° view, reshape ç­‰                                             â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ä»€ä¹ˆæ—¶å€™å¯ä»¥ä¸ç”¨ï¼Ÿ                                                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚   å¦‚æœåç»­æ“ä½œä¸éœ€è¦è¿ç»­å†…å­˜ï¼ˆå¦‚ç®€å•çš„åŠ æ³•ã€ä¹˜æ³•ï¼‰ï¼Œå¯ä»¥çœç•¥ã€‚              â”‚
â”‚   ä½†ä¸ºäº†å®‰å…¨ï¼Œé€šå¸¸åœ¨åˆ‡ç‰‡ååŠ ä¸Š .contiguous() æ˜¯å¥½ä¹ æƒ¯ã€‚                     â”‚
â”‚                                                                             â”‚
â”‚   æ€§èƒ½æƒè¡¡:                                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚   - ä¸ç”¨ .contiguous(): çœå†…å­˜ã€çœæ—¶é—´ï¼ˆä¸å¤åˆ¶ï¼‰                            â”‚
â”‚   - ç”¨ .contiguous(): å¤åˆ¶æ•°æ®ï¼Œä½†åç»­æ“ä½œæ›´å¿«ã€æ›´å®‰å…¨                      â”‚
â”‚                                                                             â”‚
â”‚   åœ¨ HunyuanVideo ä¸­ï¼Œå› ä¸ºåç»­æœ‰ attention æŠ•å½±å’Œ FFNï¼š                     â”‚
â”‚   ```python                                                                 â”‚
â”‚   img = img + self.img_attn_proj(img_attn)  # çº¿æ€§å±‚éœ€è¦ç‰¹å®šå½¢çŠ¶           â”‚
â”‚   ```                                                                       â”‚
â”‚   æ‰€ä»¥éœ€è¦ç¡®ä¿å†…å­˜è¿ç»­ã€‚                                                    â”‚
â”‚                                                                             â”‚
â”‚   ã€txt_mod1_gate vs txt_mod2_gate æ˜¯ä»€ä¹ˆåŒºåˆ«ï¼Ÿã€‘                           â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚                                                                             â”‚
â”‚   è¿™æ˜¯ DiT (Diffusion Transformer) çš„ AdaLNï¼ˆè‡ªé€‚åº”å±‚å½’ä¸€åŒ–ï¼‰æœºåˆ¶ã€‚         â”‚
â”‚                                                                             â”‚
â”‚   æºç ç¬¬ 127-143 è¡Œï¼Œä»æ—¶é—´æ­¥ embedding ç”Ÿæˆ 6 ä¸ªè°ƒåˆ¶å‚æ•°ï¼š                  â”‚
â”‚   ```python                                                                 â”‚
â”‚   # vec æ˜¯æ—¶é—´æ­¥ embedding (æ¥è‡ª self.time_in(t))                          â”‚
â”‚   (                                                                         â”‚
â”‚       txt_mod1_shift,    # ç¬¬ä¸€å­å±‚ (attention) çš„åç§»                     â”‚
â”‚       txt_mod1_scale,    # ç¬¬ä¸€å­å±‚ (attention) çš„ç¼©æ”¾                     â”‚
â”‚       txt_mod1_gate,     # ç¬¬ä¸€å­å±‚ (attention) çš„é—¨æ§                     â”‚
â”‚       txt_mod2_shift,    # ç¬¬äºŒå­å±‚ (FFN) çš„åç§»                           â”‚
â”‚       txt_mod2_scale,    # ç¬¬äºŒå­å±‚ (FFN) çš„ç¼©æ”¾                           â”‚
â”‚       txt_mod2_gate,     # ç¬¬äºŒå­å±‚ (FFN) çš„é—¨æ§                           â”‚
â”‚   ) = self.txt_mod(vec).chunk(6, dim=-1)                                    â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   mod1 vs mod2 çš„åŒºåˆ«:                                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚  Transformer Block çš„ä¸¤ä¸ªå­å±‚:                                        â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚   â”‚  â”‚ å­å±‚ 1: Attention                                               â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ ä½¿ç”¨ mod1 ç³»åˆ—å‚æ•°:                                             â”‚  â”‚  â”‚
â”‚   â”‚  â”‚   â€¢ txt_mod1_shift, txt_mod1_scale: è°ƒåˆ¶ LayerNorm              â”‚  â”‚  â”‚
â”‚   â”‚  â”‚   â€¢ txt_mod1_gate: æ§åˆ¶æ®‹å·®è¿æ¥çš„å¼ºåº¦                           â”‚  â”‚  â”‚
â”‚   â”‚  â”‚                                                                 â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ x = LayerNorm(x)                                                â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ x = x * (1 + scale) + shift   â† modulate                        â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ attn_out = Attention(x)                                         â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ x = x + gate * attn_out       â† apply_gate                      â”‚  â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚   â”‚                               â†“                                       â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚   â”‚  â”‚ å­å±‚ 2: FFN (Feed-Forward Network)                              â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ ä½¿ç”¨ mod2 ç³»åˆ—å‚æ•°:                                             â”‚  â”‚  â”‚
â”‚   â”‚  â”‚   â€¢ txt_mod2_shift, txt_mod2_scale: è°ƒåˆ¶ LayerNorm              â”‚  â”‚  â”‚
â”‚   â”‚  â”‚   â€¢ txt_mod2_gate: æ§åˆ¶æ®‹å·®è¿æ¥çš„å¼ºåº¦                           â”‚  â”‚  â”‚
â”‚   â”‚  â”‚                                                                 â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ x = LayerNorm(x)                                                â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ x = x * (1 + scale) + shift   â† modulate                        â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ ffn_out = FFN(x)                                                â”‚  â”‚  â”‚
â”‚   â”‚  â”‚ x = x + gate * ffn_out        â† apply_gate                      â”‚  â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   shift, scale, gate å„è‡ªçš„ä½œç”¨:                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚   ```python                                                                 â”‚
â”‚   # modulate å‡½æ•°: è‡ªé€‚åº”è°ƒæ•´ç‰¹å¾                                           â”‚
â”‚   def modulate(x, shift, scale):                                            â”‚
â”‚       return x * (1 + scale) + shift                                        â”‚
â”‚       #          â†‘ ç¼©æ”¾       â†‘ åç§»                                        â”‚
â”‚                                                                             â”‚
â”‚   # apply_gate å‡½æ•°: æ§åˆ¶æ®‹å·®è¿æ¥å¼ºåº¦                                       â”‚
â”‚   def apply_gate(x, gate):                                                  â”‚
â”‚       return gate * x                                                       â”‚
â”‚       #      â†‘ é—¨æ§å€¼ï¼ˆ0~1 ä¹‹é—´ï¼‰                                           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆéœ€è¦è¿™äº›è°ƒåˆ¶å‚æ•°ï¼Ÿ                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚   1. æ—¶é—´æ­¥æ¡ä»¶æ³¨å…¥:                                                        â”‚
â”‚      ä¸åŒçš„ tï¼ˆå™ªå£°ç¨‹åº¦ï¼‰éœ€è¦ä¸åŒçš„å¤„ç†æ–¹å¼                                 â”‚
â”‚      - t å¤§ï¼ˆå™ªå£°å¤šï¼‰: å¯èƒ½éœ€è¦æ›´æ¿€è¿›çš„å»å™ª                                 â”‚
â”‚      - t å°ï¼ˆå™ªå£°å°‘ï¼‰: éœ€è¦æ›´ç²¾ç»†çš„è°ƒæ•´                                     â”‚
â”‚                                                                             â”‚
â”‚   2. ä¸¤ä¸ªå­å±‚éœ€è¦ä¸åŒçš„è°ƒåˆ¶:                                                â”‚
â”‚      - Attention: è´Ÿè´£å…¨å±€ä¿¡æ¯äº¤æ¢                                         â”‚
â”‚      - FFN: è´Ÿè´£å±€éƒ¨ç‰¹å¾å˜æ¢                                               â”‚
â”‚      - å®ƒä»¬å¯¹æ—¶é—´æ­¥çš„å“åº”æ–¹å¼ä¸åŒ                                          â”‚
â”‚                                                                             â”‚
â”‚   3. Gate çš„ä½œç”¨:                                                           â”‚
â”‚      - å…è®¸æ¨¡å‹å­¦ä¹ "è·³è¿‡"æŸäº›å­å±‚                                          â”‚
â”‚      - åœ¨æŸäº›æ—¶é—´æ­¥ï¼Œå¯èƒ½ attention æ›´é‡è¦ï¼ŒFFN å¯ä»¥å¼±åŒ–                   â”‚
â”‚      - æä¾›æ›´çµæ´»çš„ä¿¡æ¯æµæ§åˆ¶                                              â”‚
â”‚                                                                             â”‚
â”‚   æºç ä½¿ç”¨ç¤ºä¾‹ï¼ˆç¬¬ 190-202 è¡Œï¼‰:                                            â”‚
â”‚   ```python                                                                 â”‚
â”‚   # å­å±‚ 1: Attention + mod1                                                â”‚
â”‚   txt = txt + apply_gate(                                                   â”‚
â”‚       self.txt_attn_proj(txt_attn),                                         â”‚
â”‚       gate=txt_mod1_gate   # â† æ§åˆ¶ attention è¾“å‡ºçš„å¼ºåº¦                   â”‚
â”‚   )                                                                         â”‚
â”‚                                                                             â”‚
â”‚   # å­å±‚ 2: FFN + mod2                                                      â”‚
â”‚   txt = txt + apply_gate(                                                   â”‚
â”‚       self.txt_mlp(                                                         â”‚
â”‚           modulate(self.txt_norm2(txt),                                     â”‚
â”‚                    shift=txt_mod2_shift, scale=txt_mod2_scale)              â”‚
â”‚       ),                                                                    â”‚
â”‚       gate=txt_mod2_gate   # â† æ§åˆ¶ FFN è¾“å‡ºçš„å¼ºåº¦                         â”‚
â”‚   )                                                                         â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   è¿™ç§è®¾è®¡æ¥è‡ª DiT è®ºæ–‡:                                                    â”‚
â”‚   "Scalable Diffusion Models with Transformers" (Peebles & Xie, 2023)       â”‚
â”‚   æ˜¯å°†æ—¶é—´æ­¥ä¿¡æ¯é«˜æ•ˆæ³¨å…¥ Transformer çš„æ ‡å‡†æ–¹æ³•ã€‚                           â”‚
â”‚                                                                             â”‚
â”‚   ã€self.txt_mod / self.img_mod æ˜¯ä»€ä¹ˆï¼Ÿã€‘                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚                                                                             â”‚
â”‚   `mod` = Modulateï¼Œè°ƒåˆ¶å±‚ã€‚æ˜¯ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œæ¨¡å—ã€‚                      â”‚
â”‚                                                                             â”‚
â”‚   æºç  modulate_layers.py ç¬¬ 23-43 è¡Œ:                                      â”‚
â”‚   ```python                                                                 â”‚
â”‚   class ModulateDiT(nn.Module):                                             â”‚
â”‚       # Modulation layer for DiT                                            â”‚
â”‚                                                                             â”‚
â”‚       def __init__(self, hidden_size, factor, act_layer, ...):              â”‚
â”‚           self.act = act_layer()          # æ¿€æ´»å‡½æ•° (SiLU)                 â”‚
â”‚           self.linear = nn.Linear(                                          â”‚
â”‚               hidden_size,                # è¾“å…¥ç»´åº¦                        â”‚
â”‚               factor * hidden_size,       # è¾“å‡ºç»´åº¦ (6 å€)                 â”‚
â”‚               bias=True                                                     â”‚
â”‚           )                                                                 â”‚
â”‚           # å…³é”®ï¼šé›¶åˆå§‹åŒ–ï¼                                                â”‚
â”‚           nn.init.zeros_(self.linear.weight)                                â”‚
â”‚           nn.init.zeros_(self.linear.bias)                                  â”‚
â”‚                                                                             â”‚
â”‚       def forward(self, x):                                                 â”‚
â”‚           return self.linear(self.act(x))                                   â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   å›¾è§£:                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â”‚  æ—¶é—´æ­¥ embedding (vec)                                               â”‚  â”‚
â”‚   â”‚  shape: (B, hidden_size)   ä¾‹å¦‚ (2, 3072)                             â”‚  â”‚
â”‚   â”‚             â”‚                                                         â”‚  â”‚
â”‚   â”‚             â–¼                                                         â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚  â”‚
â”‚   â”‚  â”‚       SiLU æ¿€æ´»         â”‚                                          â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚  â”‚
â”‚   â”‚              â”‚                                                         â”‚  â”‚
â”‚   â”‚              â–¼                                                         â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚  â”‚
â”‚   â”‚  â”‚   Linear (3072 â†’ 18432) â”‚  factor=6, æ‰€ä»¥ 6Ã—3072=18432             â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚  â”‚
â”‚   â”‚              â”‚                                                         â”‚  â”‚
â”‚   â”‚              â–¼                                                         â”‚  â”‚
â”‚   â”‚  output shape: (B, 6 Ã— hidden_size)                                   â”‚  â”‚
â”‚   â”‚  ä¾‹å¦‚ (2, 18432)                                                      â”‚  â”‚
â”‚   â”‚              â”‚                                                         â”‚  â”‚
â”‚   â”‚              â–¼                                                         â”‚  â”‚
â”‚   â”‚  .chunk(6, dim=-1)  â† æ²¿æœ€åä¸€ç»´åˆ†æˆ 6 ä»½                              â”‚  â”‚
â”‚   â”‚              â”‚                                                         â”‚  â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                                            â”‚  â”‚
â”‚   â”‚  â”‚s1 â”‚s2 â”‚g1 â”‚s3 â”‚s4 â”‚g2 â”‚  å„ (B, 3072)                              â”‚  â”‚
â”‚   â”‚  â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                                            â”‚  â”‚
â”‚   â”‚  shift1 scale1 gate1 shift2 scale2 gate2                              â”‚  â”‚
â”‚   â”‚  (mod1 ç³»åˆ—)        (mod2 ç³»åˆ—)                                        â”‚  â”‚
â”‚   â”‚                                                                       â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆé›¶åˆå§‹åŒ–ï¼Ÿ                                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚   ```python                                                                 â”‚
â”‚   nn.init.zeros_(self.linear.weight)                                        â”‚
â”‚   nn.init.zeros_(self.linear.bias)                                          â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„è®­ç»ƒæŠ€å·§ï¼š                                                  â”‚
â”‚                                                                             â”‚
â”‚   1. åˆå§‹æ—¶ shift=0, scale=0, gate=0:                                       â”‚
â”‚      modulate(x, shift=0, scale=0) = x * (1 + 0) + 0 = x                   â”‚
â”‚      apply_gate(out, gate=0) = 0 * out = 0                                 â”‚
â”‚                                                                             â”‚
â”‚   2. è¿™æ„å‘³ç€è®­ç»ƒå¼€å§‹æ—¶ï¼š                                                   â”‚
â”‚      - modulate ä¸æ”¹å˜è¾“å…¥ï¼ˆæ’ç­‰å˜æ¢ï¼‰                                     â”‚
â”‚      - gate å®Œå…¨å…³é—­æ®‹å·®è¿æ¥                                               â”‚
â”‚                                                                             â”‚
â”‚   3. å¥½å¤„ï¼š                                                                  â”‚
â”‚      - æ¨¡å‹å¯ä»¥ä»"æ— è°ƒåˆ¶"çŠ¶æ€é€æ¸å­¦ä¹                                       â”‚
â”‚      - é¿å…åˆå§‹åŒ–ä¸å½“å¯¼è‡´è®­ç»ƒä¸ç¨³å®š                                        â”‚
â”‚      - è®©æ¨¡å‹è‡ªå·±å†³å®šéœ€è¦å¤šå°‘è°ƒåˆ¶                                          â”‚
â”‚                                                                             â”‚
â”‚   æ€»ç»“ï¼š                                                                     â”‚
â”‚   â”€â”€â”€â”€â”€                                                                     â”‚
â”‚   `mod` = ModulateDiT = ä¸€ä¸ªç®€å•çš„ SiLU + Linear æ¨¡å—                       â”‚
â”‚   è¾“å…¥ï¼šæ—¶é—´æ­¥ embedding (3072 ç»´)                                          â”‚
â”‚   è¾“å‡ºï¼š6 ä¸ªè°ƒåˆ¶å‚æ•° (å„ 3072 ç»´)                                           â”‚
â”‚                                                                             â”‚
â”‚   æ¯ä¸ª Block æœ‰ä¸¤ä¸ª mod:                                                    â”‚
â”‚   - self.img_mod: ä¸º img (è§†é¢‘) ç”Ÿæˆè°ƒåˆ¶å‚æ•°                               â”‚
â”‚   - self.txt_mod: ä¸º txt (æ–‡æœ¬) ç”Ÿæˆè°ƒåˆ¶å‚æ•°                               â”‚
â”‚   å®ƒä»¬ä¸å…±äº«æƒé‡ï¼Œåˆ†åˆ«å­¦ä¹ ï¼                                                â”‚
â”‚                                                                             â”‚
â”‚                                                                             â”‚
â”‚ ã€å…³é”®æºç ç‰‡æ®µ - hunyuanvideo_1_5_transformer.pyã€‘                          â”‚
â”‚                                                                             â”‚
â”‚   ç¬¬ 751-762 è¡Œ - ByT5 å¤„ç†ä¸æ‹¼æ¥:                                          â”‚
â”‚   ```python                                                                 â”‚
â”‚   if self.glyph_byT5_v2:                                                    â”‚
â”‚       byt5_text_states = extra_kwargs["byt5_text_states"]                   â”‚
â”‚       byt5_text_mask = extra_kwargs["byt5_text_mask"]                       â”‚
â”‚       byt5_txt = self.byt5_in(byt5_text_states)  # æŠ•å½±åˆ° hidden_size       â”‚
â”‚       txt, text_mask = self.reorder_txt_token(                              â”‚
â”‚           byt5_txt, txt, byt5_text_mask, text_mask                          â”‚
â”‚       )  # â˜… å…³é”®ï¼šæ‹¼æ¥æˆä¸€ä¸ªåºåˆ—                                           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ç¬¬ 630-664 è¡Œ - reorder_txt_token() æ‹¼æ¥é€»è¾‘:                             â”‚
â”‚   ```python                                                                 â”‚
â”‚   # æ‹¼æ¥é¡ºåºï¼šæœ‰æ•ˆçš„ ByT5 + æœ‰æ•ˆçš„ LLaVA + padding                          â”‚
â”‚   reorder_txt_i = torch.cat([                                               â”‚
â”‚       byt5_txt_i[byt5_text_mask_i],   # ByT5 æœ‰æ•ˆ tokens                    â”‚
â”‚       txt_i[text_mask_i],             # LLaVA æœ‰æ•ˆ tokens                   â”‚
â”‚       pad_byt5,                       # ByT5 padding                        â”‚
â”‚       pad_text                        # LLaVA padding                       â”‚
â”‚   ], dim=0)                                                                 â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ç¬¬ 176-186 è¡Œ - è”åˆæ³¨æ„åŠ›è®¡ç®—:                                           â”‚
â”‚   ```python                                                                 â”‚
â”‚   attn = parallel_attention(                                                â”‚
â”‚       (img_q, txt_q),  # txt_q åŒ…å« LLaVA + ByT5                            â”‚
â”‚       (img_k, txt_k),                                                       â”‚
â”‚       (img_v, txt_v),                                                       â”‚
â”‚       text_mask=text_mask,  # mask ä¹Ÿæ˜¯æ‹¼æ¥åçš„                             â”‚
â”‚       ...                                                                   â”‚
â”‚   )                                                                         â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆç”¨æ‹¼æ¥è€Œä¸æ˜¯ä¸¤æ¬¡ Cross-Attentionï¼Ÿã€‘                                  â”‚
â”‚                                                                             â”‚
â”‚   1. æ•ˆç‡æ›´é«˜ï¼šä¸€æ¬¡æ³¨æ„åŠ›è®¡ç®— vs ä¸¤æ¬¡                                        â”‚
â”‚   2. æ›´è‡ªç„¶çš„äº¤äº’ï¼š                                                          â”‚
â”‚      - è§†é¢‘ tokens å¯ä»¥åŒæ—¶ attend to ä¸¤ç§æ–‡æœ¬                              â”‚
â”‚      - ä¸¤ç§æ–‡æœ¬ç‰¹å¾ä¹Ÿå¯ä»¥ç›¸äº’äº¤äº’                                           â”‚
â”‚   3. ç»Ÿä¸€çš„ mask å¤„ç†ï¼š                                                      â”‚
â”‚      - æœ‰æ•ˆ tokens æ”¾å‰é¢ï¼Œpadding æ”¾åé¢                                   â”‚
â”‚      - å¯ä»¥ç”¨åŒä¸€ä¸ª mask æ§åˆ¶æ³¨æ„åŠ›èŒƒå›´                                     â”‚
â”‚                                                                             â”‚
â”‚ ã€æ‹¼æ¥åçš„åºåˆ—ç»“æ„ã€‘                                                         â”‚
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  ByT5 æœ‰æ•ˆ   â”‚  LLaVA æœ‰æ•ˆ  â”‚  ByT5 pad  â”‚  LLaVA pad  â”‚       â”‚       â”‚
â”‚   â”‚  tokens      â”‚  tokens      â”‚            â”‚             â”‚       â”‚       â”‚
â”‚   â”‚  (~50-100)   â”‚  (~20-50)    â”‚  (~150)    â”‚  (~950)     â”‚       â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â†‘              â†‘              â†‘            â†‘                       â”‚
â”‚       å­—ç¬¦çº§         è¯­ä¹‰çº§        mask=0       mask=0                     â”‚
â”‚       ç»†èŠ‚           ç†è§£        (è¢«å¿½ç•¥)      (è¢«å¿½ç•¥)                     â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆæŠŠæ‰€æœ‰ padding éƒ½æ”¾åˆ°åé¢ï¼Ÿã€‘                                        â”‚
â”‚                                                                             â”‚
â”‚   è¿™ç§é‡æ’åºç­–ç•¥æœ‰å‡ ä¸ªé‡è¦åŸå› ï¼š                                             â”‚
â”‚                                                                             â”‚
â”‚   1. ä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—æ•ˆç‡                                                      â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚      åŸå§‹å¸ƒå±€ï¼ˆä¸é‡æ’ï¼‰:                                                     â”‚
â”‚        [ByT5æœ‰æ•ˆ, ByT5 pad, LLaVAæœ‰æ•ˆ, LLaVA pad]                          â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€256â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€1000â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚
â”‚                                                                             â”‚
â”‚      é—®é¢˜ï¼šæœ‰æ•ˆ tokens è¢« padding åˆ†éš”ï¼Œæ³¨æ„åŠ›è®¡ç®—æ—¶éœ€è¦é¢‘ç¹è·³è¿‡              â”‚
â”‚                                                                             â”‚
â”‚      é‡æ’åå¸ƒå±€:                                                             â”‚
â”‚        [ByT5æœ‰æ•ˆ, LLaVAæœ‰æ•ˆ, ByT5 pad, LLaVA pad]                          â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€æœ‰æ•ˆåŒºåŸŸâ”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€padding åŒºåŸŸâ”€â”€â”€â”€â”¤                        â”‚
â”‚                                                                             â”‚
â”‚      ä¼˜ç‚¹ï¼šæœ‰æ•ˆ tokens è¿ç»­ï¼Œå¯ä»¥æ›´é«˜æ•ˆåˆ©ç”¨ç¡¬ä»¶å¹¶è¡Œè®¡ç®—                       â”‚
â”‚                                                                             â”‚
â”‚   2. Block Mask / åˆ†å—æ³¨æ„åŠ›ä¼˜åŒ–                                             â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚      æºç æ³¨é‡Š (ç¬¬ 640-641 è¡Œ):                                              â”‚
â”‚      ```python                                                              â”‚
â”‚      # When using block mask with approximate computation,                  â”‚
â”‚      # set pad to zero to reduce error                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚      HunyuanVideo ä½¿ç”¨ "flex-block-attn" åˆ†å—æ³¨æ„åŠ›ï¼š                       â”‚
â”‚      - å°†åºåˆ—åˆ†æˆå›ºå®šå¤§å°çš„å— (å¦‚ tile_size=[6,8,8])                        â”‚
â”‚      - å—å†…è®¡ç®—æ³¨æ„åŠ›ï¼Œå—é—´ç”¨ç¨€ç–é‡‡æ ·                                        â”‚
â”‚                                                                             â”‚
â”‚      å¦‚æœæœ‰æ•ˆ tokens å’Œ padding äº¤é”™ï¼š                                       â”‚
â”‚        å— 1: [æœ‰æ•ˆ, æœ‰æ•ˆ, pad]    â† éœ€è¦å¤æ‚çš„ mask å¤„ç†                    â”‚
â”‚        å— 2: [æœ‰æ•ˆ, pad, pad]     â† å—å†…æ··åˆï¼Œå¢åŠ è®¡ç®—è¯¯å·®                   â”‚
â”‚                                                                             â”‚
â”‚      å¦‚æœ padding é›†ä¸­åˆ°åé¢ï¼š                                               â”‚
â”‚        å— 1: [æœ‰æ•ˆ, æœ‰æ•ˆ, æœ‰æ•ˆ]   â† å®Œæ•´çš„æœ‰æ•ˆå—                            â”‚
â”‚        å— N: [pad, pad, pad]      â† æ•´å—è¢«å¿½ç•¥                              â”‚
â”‚                                                                             â”‚
â”‚   3. SSTA (Sparse Spatial-Temporal Attention) ä¼˜åŒ–                          â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚      HunyuanVideo ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›æ¥å¤„ç†é•¿åºåˆ—ï¼š                               â”‚
â”‚      - ssta_topk: åªé€‰æ‹© top-k é‡è¦çš„ tokens                                â”‚
â”‚      - ssta_sampling_type: 'importance' é‡è¦æ€§é‡‡æ ·                          â”‚
â”‚                                                                             â”‚
â”‚      æœ‰æ•ˆ tokens è¿ç»­æ’åˆ—ä½¿å¾—ï¼š                                              â”‚
â”‚      - é‡‡æ ·ç´¢å¼•è®¡ç®—æ›´ç®€å•                                                    â”‚
â”‚      - ä¸ä¼šæ„å¤–é‡‡æ ·åˆ° padding tokens                                        â”‚
â”‚      - å‡å°‘æ— æ•ˆè®¡ç®—                                                          â”‚
â”‚                                                                             â”‚
â”‚   4. å†…å­˜è®¿é—®ä¼˜åŒ–                                                            â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚
â”‚      GPU å†…å­˜è®¿é—®æ˜¯è¿ç»­çš„æ›´é«˜æ•ˆï¼š                                            â”‚
â”‚      - æœ‰æ•ˆ tokens è¿ç»­ â†’ ç¼“å­˜å‘½ä¸­ç‡é«˜                                      â”‚
â”‚      - padding åœ¨æœ«å°¾ â†’ å¯èƒ½æ•´ä¸ªä¸åŠ è½½                                      â”‚
â”‚                                                                             â”‚
â”‚ ã€å…·ä½“ä»£ç æµç¨‹ã€‘                                                             â”‚
â”‚                                                                             â”‚
â”‚   1. CFG å‡†å¤‡ï¼ˆåœ¨æ¨ç†å¾ªç¯ä¹‹å‰ï¼‰:                                              â”‚
â”‚      ```python                                                              â”‚
â”‚      # åˆå¹¶æ­£å‘å’Œè´Ÿå‘ embeddings                                             â”‚
â”‚      prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])     â”‚
â”‚      # shape: (2, 1000, 3584)                                               â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   2. ByT5 embeddings æ‰“åŒ…:                                                   â”‚
â”‚      ```python                                                              â”‚
â”‚      extra_kwargs = {                                                       â”‚
â”‚          "byt5_text_states": byt5_text_states,  # (2, 256, 1472)            â”‚
â”‚          "byt5_text_mask": byt5_text_mask,      # (2, 256)                  â”‚
â”‚      }                                                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   3. Transformer è°ƒç”¨:                                                       â”‚
â”‚      ```python                                                              â”‚
â”‚      output = transformer(                                                  â”‚
â”‚          latent_model_input,      # è§†é¢‘ latents                            â”‚
â”‚          t_expand,                # æ—¶é—´æ­¥                                  â”‚
â”‚          prompt_embeds,           # LLaVA embeddings (ä¸»é€šé“)               â”‚
â”‚          prompt_embeds_2,         # è§ä¸‹æ–¹è¯¦è§£ â†“                            â”‚
â”‚          prompt_mask,             # LLaVA æ³¨æ„åŠ› mask                       â”‚
â”‚          ...                                                                â”‚
â”‚          extra_kwargs=extra_kwargs,  # ByT5 embeddings åœ¨è¿™é‡Œï¼             â”‚
â”‚      )                                                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚ ã€å…³äº prompt_embeds_2 å‚æ•°çš„å›°æƒ‘è§£ç­”ã€‘                                       â”‚
â”‚                                                                             â”‚
â”‚   è¿™ä¸ªå‘½åç¡®å®å®¹æ˜“æ··æ·†ï¼è®©æˆ‘æ¾„æ¸…ï¼š                                            â”‚
â”‚                                                                             â”‚
â”‚   prompt_embeds_2 (Transformer çš„ç¬¬4ä¸ªå‚æ•°):                                 â”‚
â”‚   â”œâ”€ è¿™æ˜¯ Transformer æ¥å£é¢„ç•™çš„è¾…åŠ©æ–‡æœ¬å‚æ•°ä½ç½®                             â”‚
â”‚   â”œâ”€ è®¾è®¡ç”¨äº CLIP æˆ–å…¶ä»–è¾…åŠ© text encoderï¼ˆé ByT5ï¼‰                        â”‚
â”‚   â”œâ”€ å¯¹äº 720p_t2v ç‰ˆæœ¬ï¼šè®¾ä¸º Noneï¼Œä¸ä½¿ç”¨                                   â”‚
â”‚   â””â”€ å¯¹äºå…¶ä»–ç‰ˆæœ¬ï¼ˆå¦‚ 1080pï¼‰ï¼šå¯èƒ½ä½¿ç”¨ CLIP embeddings                       â”‚
â”‚                                                                             â”‚
â”‚   extra_kwargs["byt5_text_states"] (ByT5 embeddings):                        â”‚
â”‚   â”œâ”€ è¿™æ‰æ˜¯ ByT5 çš„ embeddingsï¼                                            â”‚
â”‚   â”œâ”€ é€šè¿‡ extra_kwargs å­—å…¸ä¼ å…¥ï¼ˆä¸æ˜¯ä½ç½®å‚æ•°ï¼‰                               â”‚
â”‚   â”œâ”€ å‘½åä¸º byt5_text_states è€Œé prompt_embeds_2                            â”‚
â”‚   â””â”€ åœ¨ Transformer å†…éƒ¨ä¼šè¢«ç‰¹æ®Šå¤„ç†                                         â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡ï¼Ÿ                                                           â”‚
â”‚   â”œâ”€ HunyuanVideo æ”¯æŒå¤šç§é…ç½®å’Œç‰ˆæœ¬                                         â”‚
â”‚   â”œâ”€ prompt_embeds_2 æ˜¯ç»™ CLIP ç­‰é¢„ç•™çš„"æ ‡å‡†"ä½ç½®                            â”‚
â”‚   â”œâ”€ ByT5 æ˜¯åæ¥æ·»åŠ çš„ç‰¹æ€§ï¼Œç”¨ extra_kwargs æ›´çµæ´»                           â”‚
â”‚   â””â”€ è¿™æ ·ä¸åŒç‰ˆæœ¬å¯ä»¥çµæ´»ç»„åˆä½¿ç”¨å“ªäº› text encoder                            â”‚
â”‚                                                                             â”‚
â”‚   å®é™…ä½¿ç”¨çš„ Text Encoder ç»„åˆ:                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚ ç‰ˆæœ¬            â”‚ ä¸» Text Encoder      â”‚ è¾…åŠ© Text Encoder   â”‚            â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚   â”‚ 720p_t2v       â”‚ LLaVA               â”‚ ByT5 (via extra)    â”‚            â”‚
â”‚   â”‚ 720p_i2v       â”‚ LLaVA               â”‚ ByT5 (via extra)    â”‚            â”‚
â”‚   â”‚ æŸäº›å…¶ä»–ç‰ˆæœ¬    â”‚ LLaVA               â”‚ CLIP (via param)    â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                             â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸¤ç§ Embedding çš„ä½œç”¨åˆ†å·¥ã€‘                                                 â”‚
â”‚                                                                             â”‚
â”‚   LLaVA (ä¸»):                                                                â”‚
â”‚   â”œâ”€ æä¾›é«˜å±‚è¯­ä¹‰ç†è§£                                                        â”‚
â”‚   â”œâ”€ "ä¸€åªçŒ«åœ¨èŠ±å›­é‡Œèµ°" â†’ ç†è§£åœºæ™¯ã€åŠ¨ä½œã€ä¸»ä½“                                â”‚
â”‚   â””â”€ ä¸»å¯¼è§†é¢‘çš„æ•´ä½“å†…å®¹ç”Ÿæˆ                                                  â”‚
â”‚                                                                             â”‚
â”‚   ByT5 (è¾…åŠ©):                                                               â”‚
â”‚   â”œâ”€ æä¾›å­—ç¬¦çº§åˆ«çš„ç²¾ç¡®ç†è§£                                                  â”‚
â”‚   â”œâ”€ å¸®åŠ©å‡†ç¡®æ¸²æŸ“æ–‡å­—ã€ç¬¦å·ã€å“ç‰Œåç­‰                                        â”‚
â”‚   â””â”€ ä¿®æ­£ LLM å¯èƒ½é—æ¼çš„ç»†èŠ‚                                                 â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ç§ Embeddingï¼Ÿã€‘                                                â”‚
â”‚                                                                             â”‚
â”‚   å•çº¯ä½¿ç”¨ LLM çš„é—®é¢˜:                                                       â”‚
â”‚   - LLM ä»¥ token ä¸ºå•ä½ï¼Œå¯èƒ½ä¸¢å¤±å­—ç¬¦çº§ç»†èŠ‚                                   â”‚
â”‚   - ä¾‹å¦‚ "COCA-COLA" å¯èƒ½è¢«ç†è§£ä¸º"å¯ä¹å“ç‰Œ"ï¼Œä½†æ‹¼å†™å¯èƒ½æ¨¡ç³Š                   â”‚
â”‚                                                                             â”‚
â”‚   åŠ å…¥ ByT5 çš„å¥½å¤„:                                                          â”‚
â”‚   - æŒ‰å­—èŠ‚å¤„ç†ï¼Œä¿ç•™ç²¾ç¡®çš„å­—ç¬¦ä¿¡æ¯                                            â”‚
â”‚   - ç‰¹åˆ«é€‚åˆ: æ–‡å­—æ¸²æŸ“ã€ç‰¹å®šç¬¦å·ã€ä¸­æ–‡/æ—¥æ–‡ç­‰å¤æ‚å­—ç¬¦                          â”‚
â”‚                                                                             â”‚
â”‚   ä¸¤è€…ç»“åˆ = è¯­ä¹‰ç†è§£ + å­—ç¬¦ç²¾ç¡®æ€§                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Transformer / DiT (æ‰©æ•£å˜æ¢å™¨) â† å½“å‰æ–‡ä»¶                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ è¾“å…¥:                                                                        â”‚
â”‚   - Stage 1 çš„ text embeddings                                              â”‚
â”‚   - éšæœºå™ªå£° latents                                                         â”‚
â”‚                                                                             â”‚
â”‚ è¾“å‡º: å»å™ªåçš„ latents (è§†é¢‘çš„æ½œåœ¨ç©ºé—´è¡¨ç¤º)                                    â”‚
â”‚                                                                             â”‚
â”‚ æ ¸å¿ƒè¿‡ç¨‹: æ‰©æ•£å»å™ª (Diffusion Denoising)                                     â”‚
â”‚   é€šè¿‡å¤šæ­¥è¿­ä»£ï¼Œé€æ¸å°†éšæœºå™ªå£°è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„è§†é¢‘ latents                         â”‚
â”‚                                                                             â”‚
â”‚ å†…å­˜éœ€æ±‚: ~40GB+ (è¿™æ˜¯è®¡ç®—æœ€å¯†é›†çš„é˜¶æ®µ)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: VAE Decoder (å˜åˆ†è‡ªç¼–ç å™¨è§£ç )                                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ è¾“å…¥: Stage 2 çš„å»å™ª latents                                                 â”‚
â”‚ è¾“å‡º: å®é™…çš„è§†é¢‘å¸§ (RGB åƒç´ )                                                 â”‚
â”‚                                                                             â”‚
â”‚ ä½¿ç”¨æ¨¡å‹: VAE Decoder                                                        â”‚
â”‚   å°† latent ç©ºé—´çš„è¡¨ç¤ºè§£ç å›åƒç´ ç©ºé—´                                           â”‚
â”‚                                                                             â”‚
â”‚ å†…å­˜éœ€æ±‚: ~5-8GB                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
ğŸ¯ ä¸ºä»€ä¹ˆè¦åˆ†é˜¶æ®µï¼Ÿ
================================================================================

1. **å†…å­˜ä¼˜åŒ–**: 
   - å®Œæ•´ pipeline éœ€è¦åŒæ—¶åŠ è½½æ‰€æœ‰æ¨¡å‹ (>60GB)
   - åˆ†é˜¶æ®µå¯ä»¥åœ¨æ¯ä¸ªé˜¶æ®µç»“æŸåé‡Šæ”¾å†…å­˜
   - å¯¹äºæ˜¾å­˜æœ‰é™çš„ GPU å°¤å…¶é‡è¦

2. **çµæ´»æ€§**:
   - å¯ä»¥ä¸ºä¸åŒé˜¶æ®µä½¿ç”¨ä¸åŒçš„ç¡¬ä»¶ (å¦‚ TPU for Stage 1, GPU for Stage 2)
   - å¯ä»¥ç¼“å­˜ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
   - ä¾¿äºè°ƒè¯•å’Œå¼€å‘

3. **å¯æ‰©å±•æ€§**:
   - å¯ä»¥å¯¹åŒä¸€ä¸ª text embedding å°è¯•ä¸åŒçš„æ¨ç†å‚æ•°
   - å¯ä»¥æ‰¹é‡å¤„ç†å¤šä¸ª prompt

================================================================================
ğŸ”¬ æ ¸å¿ƒæ¦‚å¿µè§£é‡Š
================================================================================

1. **Latent Space (æ½œåœ¨ç©ºé—´)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   è§†é¢‘ä¸æ˜¯ç›´æ¥åœ¨åƒç´ ç©ºé—´ç”Ÿæˆçš„ï¼Œè€Œæ˜¯åœ¨ä¸€ä¸ªå‹ç¼©çš„"æ½œåœ¨ç©ºé—´"ä¸­ç”Ÿæˆã€‚
   
   åŸå§‹è§†é¢‘: (T, H, W, 3) â†’ VAE ç¼–ç  â†’ Latent: (T/4, H/16, W/16, C)
   
   è¿™å¤§å¤§å‡å°‘äº†è®¡ç®—é‡ï¼š
   - 720p è§†é¢‘ (1280x720) â†’ Latent (80x45)
   - æ—¶é—´ç»´åº¦ä¹Ÿå‹ç¼© 4 å€

2. **DiT (Diffusion Transformer)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   DiT æ˜¯ä¸€ç§ä½¿ç”¨ Transformer æ¶æ„çš„æ‰©æ•£æ¨¡å‹ï¼š
   
   ä¼ ç»Ÿ U-Net:  ä½¿ç”¨å·ç§¯å±‚ï¼Œå¯¹å›¾åƒç‰¹å¾è¿›è¡Œå¤„ç†
   DiT:         ä½¿ç”¨ Transformerï¼Œå°†å›¾åƒ/è§†é¢‘ patch åŒ–åç”¨æ³¨æ„åŠ›æœºåˆ¶å¤„ç†
   
   HunyuanVideo-1.5 ä½¿ç”¨çš„æ˜¯ä¸“é—¨ä¸ºè§†é¢‘è®¾è®¡çš„ DiTï¼š
   - æ”¯æŒ 3D æ³¨æ„åŠ› (æ—¶é—´ + ç©ºé—´)
   - æ”¯æŒå¤šç§ä»»åŠ¡ (t2v, i2v)

3. **Flow Matching (æµåŒ¹é…)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   è¿™æ˜¯ä¸€ç§æ›¿ä»£ä¼ ç»Ÿ DDPM çš„æ‰©æ•£è®­ç»ƒæ–¹æ³•ï¼š
   
   DDPM: é¢„æµ‹å™ªå£° Îµ
   Flow Matching: é¢„æµ‹ä»å™ªå£°åˆ°æ•°æ®çš„"æµ"å‘é‡
   
   ä¼˜ç‚¹ï¼š
   - è®­ç»ƒæ›´ç¨³å®š
   - æ¨ç†å¯ä»¥ç”¨æ›´å°‘çš„æ­¥æ•°
   - æ”¯æŒæ›´çµæ´»çš„è°ƒåº¦å™¨

4. **CFG (Classifier-Free Guidanceï¼Œæ— åˆ†ç±»å™¨å¼•å¯¼)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   CFG æ˜¯æé«˜ç”Ÿæˆè´¨é‡çš„å…³é”®æŠ€æœ¯ï¼š
   
   åŸç†ï¼š
   - åŒæ—¶è¿è¡Œä¸¤æ¬¡æ¨ç†ï¼šæœ‰æ¡ä»¶ï¼ˆwith textï¼‰å’Œæ— æ¡ä»¶ï¼ˆwithout textï¼‰
   - æœ€ç»ˆé¢„æµ‹ = æ— æ¡ä»¶é¢„æµ‹ + guidance_scale Ã— (æœ‰æ¡ä»¶é¢„æµ‹ - æ— æ¡ä»¶é¢„æµ‹)
   
   ä»£ç ä½“ç°ï¼š
   ```python
   noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)
   ```
   
   guidance_scale å‚æ•°ï¼š
   - å…¸å‹å€¼: 1.0 - 15.0
   - è¶Šé«˜ â†’ è¶Šç¬¦åˆ promptï¼Œä½†å¯èƒ½è¿‡æ‹Ÿåˆ
   - è¶Šä½ â†’ è¶Šè‡ªç„¶ï¼Œä½†å¯èƒ½åç¦» prompt

5. **Meanflow (å‡å€¼æµ)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   HunyuanVideo-1.5 çš„ç‹¬ç‰¹è®¾è®¡ï¼Œç”¨äºæ”¹å–„è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§ã€‚
   
   åœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ï¼š
   - ä¸ä»…è€ƒè™‘å½“å‰æ—¶é—´æ­¥ t
   - è¿˜è€ƒè™‘ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ t_r (timestep_r)
   - è¿™æœ‰åŠ©äºå¹³æ»‘è§†é¢‘ä¸­çš„å¸§é—´è¿‡æ¸¡

6. **Sequence Parallelism (SPï¼Œåºåˆ—å¹¶è¡Œ)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   å¤š GPU å¹¶è¡Œç­–ç•¥ï¼š
   
   - å°†è§†é¢‘çš„æ—¶é—´åºåˆ—åˆ†å‰²åˆ°å¤šä¸ª GPU
   - æ¯ä¸ª GPU å¤„ç†ä¸€éƒ¨åˆ†å¸§
   - é€šè¿‡é€šä¿¡åŒæ­¥æ³¨æ„åŠ›è®¡ç®—
   
   è¿™ä½¿å¾—å¯ä»¥ç”Ÿæˆæ›´é•¿çš„è§†é¢‘

================================================================================
ğŸ“¦ æœ¬æ–‡ä»¶çš„ç»“æ„
================================================================================

1. æ¨¡å—åˆå§‹åŒ–
   â”œâ”€â”€ å¹¶è¡ŒçŠ¶æ€åˆå§‹åŒ– (parallel_state)
   â””â”€â”€ CUDA è®¾å¤‡è®¾ç½®

2. è¾…åŠ©å‡½æ•°
   â”œâ”€â”€ get_latent_size()     - è®¡ç®— latent å°ºå¯¸
   â”œâ”€â”€ get_task_mask()       - è·å–ä»»åŠ¡ç±»å‹ mask
   â”œâ”€â”€ prepare_latents()     - å‡†å¤‡éšæœºå™ªå£°
   â”œâ”€â”€ prepare_cond_latents() - å‡†å¤‡æ¡ä»¶ latents
   â””â”€â”€ get_closest_resolution() - è®¡ç®—æœ€ä½³åˆ†è¾¨ç‡

3. main() ä¸»å‡½æ•°
   â”œâ”€â”€ å‚æ•°è§£æ
   â”œâ”€â”€ åŠ è½½ Stage 1 ç»“æœ
   â”œâ”€â”€ åŠ è½½ Transformer
   â”œâ”€â”€ åˆå§‹åŒ– Scheduler
   â”œâ”€â”€ å‡†å¤‡è¾“å…¥å¼ é‡
   â”œâ”€â”€ Denoising Loop (æ ¸å¿ƒï¼)
   â””â”€â”€ ä¿å­˜è¾“å‡º

================================================================================
å…³é”®ä¿®å¤è¯´æ˜ï¼šæœ¬æ–‡ä»¶ç›´æ¥åŠ è½½ transformerï¼Œä¸ä½¿ç”¨ create_pipeline
é¿å…åŠ è½½ä¸éœ€è¦çš„ç»„ä»¶ï¼ˆtext encoder 14GBï¼‰å¯¼è‡´ OOM

ç”¨äº GPU H100 8å¡ç¯å¢ƒ
================================================================================
"""

import os
import sys

# ============================================================================
# ğŸ”§ æ¨¡å—çº§åˆ«åˆå§‹åŒ– - å¹¶è¡ŒçŠ¶æ€
# ============================================================================
# 
# ã€ä¸ºä»€ä¹ˆå¿…é¡»åœ¨æ¨¡å—çº§åˆ«åˆå§‹åŒ–ï¼Ÿã€‘
# 
# HunyuanVideo ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†ï¼Œéœ€è¦åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰è®¾ç½®å¥½å¹¶è¡ŒçŠ¶æ€ã€‚
# è¿™æ˜¯å› ä¸ºï¼š
# 1. æŸäº›æ¨¡å—ï¼ˆå¦‚ attentionï¼‰åœ¨å¯¼å…¥æ—¶ä¼šæ£€æŸ¥å¹¶è¡ŒçŠ¶æ€
# 2. CUDA è®¾å¤‡å¿…é¡»åœ¨ä»»ä½•å¼ é‡æ“ä½œä¹‹å‰è®¾ç½®
# 
# å®˜æ–¹ generate.py ç¬¬ 37-38 è¡Œå°±æ˜¯è¿™æ ·åšçš„ï¼š
#   parallel_dims = initialize_parallel_state(sp=int(os.environ.get('WORLD_SIZE', '1')))
#   torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', '0')))
#
# ã€ç¯å¢ƒå˜é‡è¯´æ˜ã€‘
# 
# WORLD_SIZE: æ€»è¿›ç¨‹æ•°ï¼ˆGPU æ•°é‡ï¼‰
# LOCAL_RANK: å½“å‰è¿›ç¨‹åœ¨æœ¬æœºçš„æ’åï¼ˆ0, 1, 2, ...ï¼‰
# RANK: å…¨å±€æ’å
# 
# å¯¹äºå• GPU: WORLD_SIZE=1, LOCAL_RANK=0, RANK=0
# å¯¹äº 8 GPU: WORLD_SIZE=8, LOCAL_RANK=0-7, RANK=0-7
# ============================================================================

# è®¾ç½® PyTorch CUDA å†…å­˜åˆ†é…ç­–ç•¥
# expandable_segments:True å…è®¸å†…å­˜æ®µåŠ¨æ€æ‰©å±•ï¼Œå‡å°‘ç¢ç‰‡åŒ–
if 'PYTORCH_CUDA_ALLOC_CONF' not in os.environ:
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# æ·»åŠ  HunyuanVideo-1.5-TPU åˆ° Python è·¯å¾„
# è¿™æ ·æˆ‘ä»¬æ‰èƒ½å¯¼å…¥ hyvideo æ¨¡å—
HUNYUAN_ROOT = os.path.expanduser("~/HunyuanVideo-1.5-TPU")
if HUNYUAN_ROOT not in sys.path:
    sys.path.insert(0, HUNYUAN_ROOT)

import torch
from hyvideo.commons.parallel_states import initialize_parallel_state

# ã€å…³é”®ã€‘æ¨¡å—çº§åˆ«åˆå§‹åŒ–å¹¶è¡ŒçŠ¶æ€
# sp å‚æ•°: Sequence Parallelism çš„å¹¶è¡Œåº¦ï¼ˆç­‰äº WORLD_SIZEï¼‰
parallel_dims = initialize_parallel_state(sp=int(os.environ.get('WORLD_SIZE', '1')))

# ã€å…³é”®ã€‘è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„ GPU
# LOCAL_RANK å†³å®šäº†å“ªä¸ª GPU
torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', '0')))

# ç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯¼å…¥å…¶ä»–æ¨¡å—äº†
import time
import random
import argparse
import atexit
from types import SimpleNamespace
import numpy as np
from PIL import Image
from torch import distributed as dist

# ============================================================================
# ğŸ“¦ å¯¼å…¥æ ¸å¿ƒç»„ä»¶
# ============================================================================
# 
# ã€ä¸ºä»€ä¹ˆç›´æ¥å¯¼å…¥ Transformer è€Œä¸ç”¨ create_pipelineï¼Ÿã€‘
# 
# create_pipeline ä¼šåŠ è½½å®Œæ•´çš„ pipelineï¼ŒåŒ…æ‹¬ï¼š
# - Text Encoder (LLaVA): ~14GB
# - Text Encoder 2 (ByT5): ~5GB  
# - Transformer: ~13GB
# - VAE: ~1GB
# 
# ä½†æˆ‘ä»¬åªéœ€è¦ Transformerï¼å…¶ä»–ç»„ä»¶åœ¨ Stage 1 å’Œ Stage 3 ä½¿ç”¨ã€‚
# ç›´æ¥åŠ è½½ Transformer å¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ã€‚
# ============================================================================

# HunyuanVideo-1.5 çš„ DiT (Diffusion Transformer)
from hyvideo.models.transformers.hunyuanvideo_1_5_transformer import HunyuanVideo_1_5_DiffusionTransformer

# Flow Matching è°ƒåº¦å™¨
from hyvideo.schedulers.scheduling_flow_match_discrete import FlowMatchDiscreteScheduler

# æ¨ç†çŠ¶æ€ï¼ˆç”¨äºæ§åˆ¶ç¼“å­˜ã€ç¼–è¯‘ç­‰ä¼˜åŒ–ï¼‰
from hyvideo.commons.infer_state import initialize_infer_state

# å·¥å…·å‡½æ•°
from hyvideo.commons import auto_offload_model, PIPELINE_CONFIGS
from hyvideo.commons.parallel_states import get_parallel_state
from hyvideo.utils.multitask_utils import merge_tensor_by_mask

# æˆ‘ä»¬è‡ªå®šä¹‰çš„å·¥å…·å‡½æ•°ï¼ˆç”¨äº Stage é—´æ•°æ®ä¼ é€’ï¼‰
from utils import (
    load_embeddings_from_safetensors,
    save_latents_to_safetensors,
    load_generation_config,
    save_generation_config,
    get_default_paths,
)

# ============================================================================
# ğŸ§¹ æ³¨å†Œæ¸…ç†å‡½æ•°
# ============================================================================
# 
# åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†éœ€è¦åœ¨ç¨‹åºç»“æŸæ—¶æ­£ç¡®å…³é—­è¿›ç¨‹ç»„
# atexit.register ç¡®ä¿å³ä½¿ç¨‹åºå´©æºƒä¹Ÿä¼šæ‰§è¡Œæ¸…ç†
# ============================================================================

def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è¿›ç¨‹ç»„ï¼Œé¿å…åƒµå°¸è¿›ç¨‹"""
    if dist.is_initialized():
        dist.destroy_process_group()

atexit.register(cleanup_distributed)


# ============================================================================
# ğŸ› ï¸ è¾…åŠ©å‡½æ•°ï¼šè·å–è¿›ç¨‹æ’å
# ============================================================================

def get_rank():
    """
    è·å–å½“å‰è¿›ç¨‹çš„å…¨å±€æ’å
    
    Returns:
        int: è¿›ç¨‹æ’åã€‚å• GPU æ—¶è¿”å› 0
    
    ç”¨é€”ï¼š
    - åªæœ‰ rank 0 æ‰“å°æ—¥å¿—
    - åªæœ‰ rank 0 ä¿å­˜æ–‡ä»¶
    - é¿å…é‡å¤æ“ä½œ
    """
    return int(os.environ.get('RANK', '0'))


def print_rank0(msg):
    """
    åªåœ¨ rank 0 è¿›ç¨‹æ‰“å°æ¶ˆæ¯
    
    å¤š GPU æ—¶ï¼Œæ¯ä¸ª GPU éƒ½æ˜¯ç‹¬ç«‹è¿›ç¨‹ã€‚å¦‚æœæ‰€æœ‰è¿›ç¨‹éƒ½æ‰“å°ï¼š
    - æ—¥å¿—ä¼šé‡å¤ N æ¬¡
    - è¾“å‡ºæ··ä¹±
    
    Args:
        msg: è¦æ‰“å°çš„æ¶ˆæ¯
    """
    if get_rank() == 0:
        print(msg)


# ============================================================================
# ğŸ”¬ è¾…åŠ©å‡½æ•°ï¼šLatent å°ºå¯¸è®¡ç®—
# ============================================================================
# 
# ã€ä»€ä¹ˆæ˜¯ Latentï¼Ÿã€‘
# 
# Latent (æ½œåœ¨å‘é‡) æ˜¯è§†é¢‘åœ¨å‹ç¼©ç©ºé—´ä¸­çš„è¡¨ç¤ºï¼š
# 
#   åŸå§‹è§†é¢‘: (batch, channels, frames, height, width)
#              (1,     3,        49,     720,    1280)
#   
#   VAE ç¼–ç åçš„ Latent: (batch, latent_channels, latent_frames, latent_height, latent_width)
#                        (1,     16,              13,            45,            80)
#
# å‹ç¼©æ¯”ä¾‹ï¼š
# - æ—¶é—´: 49 â†’ 13 (å‹ç¼© 4 å€ï¼Œä½†ç¬¬ä¸€å¸§ç‰¹æ®Šå¤„ç†)
# - ç©ºé—´: 720Ã—1280 â†’ 45Ã—80 (å„å‹ç¼© 16 å€)
# ============================================================================

def get_latent_size(video_length, height, width, vae_temporal_ratio=4, vae_spatial_ratio=16):
    """
    è®¡ç®— latent çš„å°ºå¯¸
    
    Args:
        video_length: è§†é¢‘å¸§æ•° (å¦‚ 49)
        height: è§†é¢‘é«˜åº¦åƒç´  (å¦‚ 720)
        width: è§†é¢‘å®½åº¦åƒç´  (å¦‚ 1280)
        vae_temporal_ratio: VAE æ—¶é—´å‹ç¼©æ¯” (é»˜è®¤ 4)
        vae_spatial_ratio: VAE ç©ºé—´å‹ç¼©æ¯” (é»˜è®¤ 16)
    
    Returns:
        tuple: (latent_frames, latent_height, latent_width)
    
    è®¡ç®—å…¬å¼:
        latent_frames = (video_length - 1) // 4 + 1
        - ä¸ºä»€ä¹ˆæ˜¯ (n-1)//4+1 è€Œä¸æ˜¯ n//4ï¼Ÿ
        - å› ä¸ºç¬¬ä¸€å¸§æ˜¯å…³é”®å¸§ï¼Œéœ€è¦ç‰¹æ®Šä¿ç•™
        
        ä¾‹å¦‚: 49 å¸§ â†’ (49-1)//4+1 = 13 ä¸ª latent å¸§
              ç¬¬ä¸€å¸§å¯¹åº”ç¬¬ä¸€ä¸ª latentï¼Œåé¢æ¯ 4 å¸§ä¸€ä¸ª latent
    """
    video_length = (video_length - 1) // vae_temporal_ratio + 1
    height = height // vae_spatial_ratio
    width = width // vae_spatial_ratio
    return video_length, height, width


# ============================================================================
# ğŸ­ è¾…åŠ©å‡½æ•°ï¼šä»»åŠ¡ç±»å‹ Mask
# ============================================================================
# 
# ã€ä»»åŠ¡ç±»å‹è¯´æ˜ã€‘
# 
# HunyuanVideo-1.5 æ”¯æŒå¤šç§ä»»åŠ¡ï¼š
# - t2v (Text-to-Video): çº¯æ–‡æœ¬ç”Ÿæˆè§†é¢‘
# - i2v (Image-to-Video): å›¾ç‰‡ + æ–‡æœ¬ç”Ÿæˆè§†é¢‘
# 
# Mask ç”¨äºå‘Šè¯‰æ¨¡å‹å“ªäº›å¸§æ˜¯"å·²çŸ¥çš„"ï¼ˆæ¡ä»¶å¸§ï¼‰ï¼š
# - t2v: æ‰€æœ‰å¸§éƒ½æ˜¯æœªçŸ¥çš„ï¼Œmask å…¨ä¸º 0
# - i2v: ç¬¬ä¸€å¸§æ˜¯å·²çŸ¥çš„ï¼ˆè¾“å…¥å›¾ç‰‡ï¼‰ï¼Œmask[0] = 1
# ============================================================================

def get_task_mask(task_type, latent_target_length):
    """
    è·å–ä»»åŠ¡ç±»å‹å¯¹åº”çš„ mask
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ("t2v" æˆ– "i2v")
        latent_target_length: latent çš„æ—¶é—´é•¿åº¦
    
    Returns:
        torch.Tensor: shape (latent_target_length,)
            - 0.0 è¡¨ç¤ºè¯¥å¸§éœ€è¦ç”Ÿæˆ
            - 1.0 è¡¨ç¤ºè¯¥å¸§æ˜¯æ¡ä»¶å¸§ï¼ˆå¦‚ i2v çš„ç¬¬ä¸€å¸§ï¼‰
    
    t2v (Text-to-Video):
        mask = [0, 0, 0, ..., 0]  # æ‰€æœ‰å¸§éƒ½éœ€è¦ç”Ÿæˆ
    
    i2v (Image-to-Video):
        mask = [1, 0, 0, ..., 0]  # ç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å›¾ç‰‡
    """
    if task_type == "t2v":
        # t2v: æ‰€æœ‰å¸§éƒ½éœ€è¦ç”Ÿæˆ
        return torch.zeros(latent_target_length)
    elif task_type == "i2v":
        # i2v: ç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å¸§
        mask = torch.zeros(latent_target_length)
        mask[0] = 1.0
        return mask
    else:
        raise ValueError(f"{task_type} is not supported!")


# ============================================================================
# ğŸ² è¾…åŠ©å‡½æ•°ï¼šå‡†å¤‡åˆå§‹ Latents
# ============================================================================
# 
# ã€æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³ã€‘
# 
# æ‰©æ•£æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ˜¯"å»å™ª"ï¼š
# 
#   çº¯å™ªå£° â†’ å»å™ªæ­¥éª¤ 1 â†’ å»å™ªæ­¥éª¤ 2 â†’ ... â†’ å»å™ªæ­¥éª¤ N â†’ æ¸…æ™°ç»“æœ
#   z_T         z_{T-1}       z_{T-2}     ...      z_0
#
# æ‰€ä»¥æˆ‘ä»¬é¦–å…ˆéœ€è¦ä¸€ä¸ªéšæœºå™ªå£°ä½œä¸ºèµ·ç‚¹ã€‚
# 
# ã€ä¸ºä»€ä¹ˆåœ¨ CPU ç”Ÿæˆå†ç§»åˆ° GPUï¼Ÿã€‘
# 
# è¿™æ˜¯ä¸ºäº†ç¡®ä¿éšæœºæ•°çš„å¯é‡ç°æ€§ï¼š
# - CUDA çš„éšæœºæ•°ç”Ÿæˆå™¨åœ¨ä¸åŒç¡¬ä»¶ä¸Šå¯èƒ½æœ‰å·®å¼‚
# - CPU ç”Ÿæˆæ›´ç¨³å®šã€å¯é‡ç°
# ============================================================================

def prepare_latents(batch_size, num_channels, latent_height, latent_width, video_length,
                   dtype, device, generator):
    """
    å‡†å¤‡åˆå§‹çš„éšæœº latentsï¼ˆçº¯å™ªå£°ï¼‰
    
    Args:
        batch_size: æ‰¹æ¬¡å¤§å°ï¼Œé€šå¸¸ä¸º 1
        num_channels: latent é€šé“æ•°ï¼ŒHunyuanVideo ä½¿ç”¨ 16
        latent_height: latent é«˜åº¦
        latent_width: latent å®½åº¦
        video_length: latent æ—¶é—´é•¿åº¦ï¼ˆå¸§æ•°ï¼‰
        dtype: æ•°æ®ç±»å‹ (torch.bfloat16 æˆ– torch.float32)
        device: ç›®æ ‡è®¾å¤‡ (cuda)
        generator: éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆç”¨äºç§å­æ§åˆ¶ï¼‰
    
    Returns:
        torch.Tensor: shape (batch_size, num_channels, video_length, latent_height, latent_width)
                      ä¾‹å¦‚ (1, 16, 13, 45, 80) for 720p 49å¸§è§†é¢‘
    
    æ³¨æ„ï¼š
        latents çš„å½¢çŠ¶æ˜¯ (B, C, T, H, W)ï¼Œæ³¨æ„ T åœ¨ H, W ä¹‹å‰ï¼
        è¿™æ˜¯è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ ‡å‡†æ ¼å¼ã€‚
    """
    shape = (batch_size, num_channels, video_length, latent_height, latent_width)
    
    # åœ¨ CPU ä¸Šç”Ÿæˆéšæœºæ•°ï¼Œç¡®ä¿å¯é‡ç°æ€§
    latents = torch.randn(shape, generator=generator, device=torch.device('cpu'), dtype=dtype)
    
    # ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
    latents = latents.to(device)
    
    return latents


# ============================================================================
# ğŸ¯ è¾…åŠ©å‡½æ•°ï¼šå‡†å¤‡æ¡ä»¶ Latents
# ============================================================================
#
# ã€ä»€ä¹ˆæ˜¯æ¡ä»¶ Latentsï¼Ÿã€‘
#
# åœ¨ HunyuanVideo ä¸­ï¼Œæ¡ä»¶ latents ç”¨äºï¼š
# 1. i2v ä»»åŠ¡ï¼šæä¾›ç¬¬ä¸€å¸§çš„å›¾åƒä¿¡æ¯
# 2. æä¾›é¢å¤–çš„ç»“æ„ä¿¡æ¯ç»™ Transformer
#
# æ¡ä»¶ latents ä¼šå’Œä¸» latents åœ¨é€šé“ç»´åº¦æ‹¼æ¥ï¼š
#   - ä¸» latents: (B, 16, T, H, W)
#   - æ¡ä»¶ latents: (B, 17, T, H, W)  # 16 é€šé“ + 1 é€šé“ mask
#   - æ‹¼æ¥å: (B, 33, T, H, W)
#
# ============================================================================
# ã€i2v æ¨¡å¼çš„ latents_concat æ„é€ è¯¦è§£ã€‘
# ============================================================================
#
# é—®é¢˜ï¼šä¸ºä»€ä¹ˆå…ˆ repeat å†æ¸…é›¶ï¼Œè€Œä¸æ˜¯ç›´æ¥æ„é€ ï¼Ÿ
#
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ è¾“å…¥ï¼šimage_cond - ç¬¬ä¸€å¸§å›¾åƒç»è¿‡ VAE ç¼–ç åçš„ latent                      â”‚
# â”‚       shape: (B, 16, 1, H, W)   â† æ³¨æ„æ—¶é—´ç»´åº¦æ˜¯ 1ï¼ˆå•å¸§ï¼‰                â”‚
# â”‚                                                                          â”‚
# â”‚ ç›®æ ‡ï¼šæ„é€ ä¸€ä¸ª shape ä¸º (B, 16, T, H, W) çš„æ¡ä»¶å¼ é‡                        â”‚
# â”‚       å…¶ä¸­åªæœ‰ç¬¬ä¸€å¸§ [:, :, 0, :, :] æœ‰å›¾åƒä¿¡æ¯                           â”‚
# â”‚       å…¶ä»–å¸§ [:, :, 1:, :, :] éƒ½æ˜¯ 0                                      â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ã€æ–¹æ³• 1ï¼šå…ˆ repeat å†æ¸…é›¶ï¼ˆä»£ç ä½¿ç”¨çš„æ–¹æ³•ï¼‰ã€‘
#
#   æ­¥éª¤ 1: image_cond.repeat(1, 1, latents.shape[2], 1, 1)
#   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
#   repeat å‚æ•°: (1, 1, T, 1, 1)
#     - ç¬¬ 1 ç»´ (B): ä¸é‡å¤
#     - ç¬¬ 2 ç»´ (C): ä¸é‡å¤
#     - ç¬¬ 3 ç»´ (T): é‡å¤ T æ¬¡ï¼ˆå¦‚ 13 æ¬¡ï¼‰
#     - ç¬¬ 4 ç»´ (H): ä¸é‡å¤
#     - ç¬¬ 5 ç»´ (W): ä¸é‡å¤
#
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ åŸå§‹: image_cond                                                     â”‚
#   â”‚       â”Œâ”€â”€â”€â”€â”€â”                                                        â”‚
#   â”‚       â”‚å¸§ 0 â”‚   shape: (B, 16, 1, H, W)                              â”‚
#   â”‚       â””â”€â”€â”€â”€â”€â”˜                                                        â”‚
#   â”‚                                                                      â”‚
#   â”‚ repeat å:                                                           â”‚
#   â”‚       â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”            â”‚
#   â”‚       â”‚å¸§ 0 â”‚å¸§ 0 â”‚å¸§ 0 â”‚å¸§ 0 â”‚å¸§ 0 â”‚å¸§ 0 â”‚å¸§ 0 â”‚ ... T â”‚            â”‚
#   â”‚       â”‚å¤åˆ¶ â”‚å¤åˆ¶ â”‚å¤åˆ¶ â”‚å¤åˆ¶ â”‚å¤åˆ¶ â”‚å¤åˆ¶ â”‚å¤åˆ¶ â”‚       â”‚            â”‚
#   â”‚       â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
#   â”‚       shape: (B, 16, T, H, W)                                        â”‚
#   â”‚       æ‰€æœ‰å¸§éƒ½æ˜¯ç¬¬ä¸€å¸§çš„å¤åˆ¶ï¼                                         â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
#   æ­¥éª¤ 2: latents_concat[:, :, 1:, :, :] = 0.0
#   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
#   æŠŠç¬¬ 1 å¸§åˆ°æœ€åä¸€å¸§ï¼ˆç´¢å¼• 1 åˆ° T-1ï¼‰éƒ½æ¸…é›¶
#
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ æ¸…é›¶å:                                                              â”‚
#   â”‚       â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”            â”‚
#   â”‚       â”‚å¸§ 0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0   â”‚            â”‚
#   â”‚       â”‚çœŸå® â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚            â”‚
#   â”‚       â”‚å›¾åƒ â”‚     â”‚     â”‚     â”‚     â”‚     â”‚     â”‚       â”‚            â”‚
#   â”‚       â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
#   â”‚       â†‘                                                              â”‚
#   â”‚       åªæœ‰è¿™ä¸€å¸§æœ‰æ¡ä»¶ä¿¡æ¯                                             â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ã€ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿè¯­ä¹‰å«ä¹‰ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
#   i2v (Image-to-Video) çš„ä»»åŠ¡æ˜¯ï¼š
#     ç»™å®šç¬¬ä¸€å¸§å›¾åƒï¼Œç”Ÿæˆåç»­çš„è§†é¢‘å¸§
#
#   æ¡ä»¶ latents å‘Šè¯‰æ¨¡å‹ï¼š
#     - ç¬¬ä¸€å¸§ï¼ˆç´¢å¼• 0ï¼‰æ˜¯"å·²çŸ¥çš„"ï¼Œæœ‰çœŸå®çš„å›¾åƒä¿¡æ¯
#     - å…¶ä»–å¸§ï¼ˆç´¢å¼• 1 åˆ° T-1ï¼‰æ˜¯"æœªçŸ¥çš„"ï¼Œéœ€è¦ç”Ÿæˆ
#
#   0.0 çš„å«ä¹‰ï¼š
#     - åœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œ0.0 è¡¨ç¤º"æ²¡æœ‰æ¡ä»¶ä¿¡æ¯"
#     - æ¨¡å‹çœ‹åˆ° 0.0 å°±çŸ¥é“è¿™ä¸€å¸§éœ€è¦è‡ªå·±ç”Ÿæˆ
#     - é…åˆ mask é€šé“ä¸€èµ·å·¥ä½œï¼ˆmask=1 è¡¨ç¤ºæ¡ä»¶å¸§ï¼Œmask=0 è¡¨ç¤ºç”Ÿæˆå¸§ï¼‰
#
# ã€æ–¹æ³• 2ï¼šæ›´ç›´è§‚çš„å†™æ³•ï¼ˆç­‰ä»·ä½†æ•ˆç‡ç•¥ä½ï¼‰ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
#   # å…ˆåˆ›å»ºå…¨é›¶å¼ é‡
#   latents_concat = torch.zeros(
#       latents.shape[0], 16, latents.shape[2],
#       latents.shape[3], latents.shape[4],
#       device=latents.device, dtype=latents.dtype
#   )
#   # åªå¡«å……ç¬¬ä¸€å¸§
#   latents_concat[:, :, 0:1, :, :] = image_cond
#
#   ä¸ºä»€ä¹ˆå®˜æ–¹ç”¨ repeat + æ¸…é›¶ï¼Ÿ
#   - repeat æ˜¯ PyTorch é«˜åº¦ä¼˜åŒ–çš„æ“ä½œ
#   - é¿å…æ‰‹åŠ¨ç®¡ç†è®¾å¤‡å’Œæ•°æ®ç±»å‹
#   - ä»£ç æ›´ç®€æ´ï¼ˆè™½ç„¶ä¸é‚£ä¹ˆç›´è§‚ï¼‰
#
# ã€å¯¹æ¯” t2v æ¨¡å¼ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
#   t2v (Text-to-Video)ï¼šæ²¡æœ‰è¾“å…¥å›¾åƒ
#
#   latents_concat = torch.zeros_like(latents)
#
#   â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0 â”‚ 0.0   â”‚
#   â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
#   æ‰€æœ‰å¸§éƒ½æ˜¯ 0ï¼Œæ¨¡å‹éœ€è¦ä»çº¯æ–‡æœ¬ç”Ÿæˆæ•´ä¸ªè§†é¢‘
#
# ============================================================================

def prepare_cond_latents(task_type, image_cond, latents, multitask_mask):
    """
    å‡†å¤‡æ¡ä»¶ latentsï¼ˆç”¨äº i2v æˆ–æä¾›é¢å¤–ä¿¡æ¯ï¼‰
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ("t2v" æˆ– "i2v")
        image_cond: å›¾åƒæ¡ä»¶ latent (i2v æ—¶ä¸ºå›¾åƒçš„ VAE ç¼–ç ï¼Œt2v æ—¶ä¸º None)
                    shape: (B, 16, 1, H, W) - å•å¸§å›¾åƒçš„ latent è¡¨ç¤º
        latents: ä¸» latentsï¼Œshape: (B, 16, T, H, W)
        multitask_mask: ä»»åŠ¡ maskï¼ŒæŒ‡ç¤ºå“ªäº›å¸§æ˜¯æ¡ä»¶å¸§
    
    Returns:
        torch.Tensor: æ¡ä»¶ latentsï¼Œshape (B, 17, T, H, W)
                      å‰ 16 é€šé“æ˜¯æ¡ä»¶ä¿¡æ¯
                      æœ€å 1 é€šé“æ˜¯ mask
    
    å¯¹äº t2v:
        - æ¡ä»¶ latents å…¨ä¸º 0ï¼ˆæ²¡æœ‰å›¾åƒæ¡ä»¶ï¼‰
        - mask é€šé“æ ¹æ® multitask_mask è®¾ç½®
    
    å¯¹äº i2v:
        - ç¬¬ä¸€å¸§æœ‰å›¾åƒæ¡ä»¶
        - å…¶ä»–å¸§ä¸º 0
        - mask æŒ‡ç¤ºç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å¸§
    """
    if image_cond is not None and task_type == 'i2v':
        # ====================================================================
        # i2v æ¨¡å¼ï¼šæ„é€ æ¡ä»¶ latents
        # ====================================================================
        #
        # æ­¥éª¤ 1: å°†å•å¸§å›¾åƒ latent æ‰©å±•åˆ°æ‰€æœ‰æ—¶é—´æ­¥
        # image_cond shape: (B, 16, 1, H, W)
        # æ‰©å±•å shape: (B, 16, T, H, W)  å…¶ä¸­æ¯ä¸€å¸§éƒ½æ˜¯ image_cond çš„å¤åˆ¶
        latents_concat = image_cond.repeat(1, 1, latents.shape[2], 1, 1)
        
        # æ­¥éª¤ 2: å°†é™¤ç¬¬ä¸€å¸§å¤–çš„æ‰€æœ‰å¸§æ¸…é›¶
        # ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºåªæœ‰ç¬¬ä¸€å¸§æ˜¯"å·²çŸ¥"çš„æ¡ä»¶å›¾åƒ
        # å…¶ä»–å¸§éœ€è¦æ¨¡å‹ç”Ÿæˆï¼Œæ‰€ä»¥ç”¨ 0.0 è¡¨ç¤º"æ— æ¡ä»¶ä¿¡æ¯"
        # [:, :, 1:, :, :] é€‰æ‹©æ‰€æœ‰ batchã€æ‰€æœ‰é€šé“ã€ç¬¬ 1 å¸§åˆ°æœ€åä¸€å¸§ã€æ‰€æœ‰ç©ºé—´ä½ç½®
        latents_concat[:, :, 1:, :, :] = 0.0
    else:
        # t2v: æ²¡æœ‰å›¾åƒæ¡ä»¶ï¼Œå…¨ä¸º 0
        latents_concat = torch.zeros_like(latents)
    
    # ========================================================================
    # æ„é€  mask é€šé“ - å‘Šè¯‰æ¨¡å‹å“ªäº›å¸§æ˜¯"å·²çŸ¥"çš„æ¡ä»¶å¸§
    # ========================================================================
    #
    # ã€ç›®æ ‡ã€‘
    # æ„é€ ä¸€ä¸ª shape ä¸º (B, 1, T, H, W) çš„ mask å¼ é‡
    # - æ¡ä»¶å¸§ä½ç½®ï¼ˆå¦‚ i2v çš„ç¬¬ä¸€å¸§ï¼‰ï¼šå€¼ä¸º 1.0
    # - ç”Ÿæˆå¸§ä½ç½®ï¼ˆéœ€è¦æ¨¡å‹ç”Ÿæˆï¼‰ï¼šå€¼ä¸º 0.0
    #
    # ã€ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ª maskï¼Ÿã€‘
    # è¿™ä¸ª mask ä¼šä½œä¸ºæ¡ä»¶ latents çš„ä¸€éƒ¨åˆ†ä¼ ç»™ Transformerï¼š
    # - æ¡ä»¶ latents æœ‰ 17 ä¸ªé€šé“ï¼š16 é€šé“å›¾åƒä¿¡æ¯ + 1 é€šé“ mask
    # - mask é€šé“å‘Šè¯‰æ¨¡å‹"è¿™ä¸€å¸§æ˜¯å·²çŸ¥çš„è¿˜æ˜¯è¦ç”Ÿæˆçš„"
    # - æ¨¡å‹ä¼šå¯¹ mask=1 çš„å¸§ä¿æŒæ›´æ¥è¿‘æ¡ä»¶ï¼Œå¯¹ mask=0 çš„å¸§è‡ªç”±ç”Ÿæˆ
    #
    # ========================================================================
    # ã€ä¸ºä»€ä¹ˆ mask æ˜¯ 5D (B,1,T,H,W) è€Œä¸æ˜¯ç®€å•çš„ 1D (T,)ï¼Ÿã€‘
    # ========================================================================
    #
    # ä½ å¯èƒ½ä¼šé—®ï¼šæ—¢ç„¶æ¡ä»¶å¸§çš„æœ€å°å•ä½æ˜¯"å¸§"ï¼Œä¸ºä»€ä¹ˆä¸ç”¨ä¸€ä¸ªç®€å•çš„
    # 1D tensor [1, 0, 0, ..., 0] å°±å¤Ÿäº†ï¼Ÿä¸ºä»€ä¹ˆè¦å¼„æˆ (B, 1, T, H, W)ï¼Ÿ
    #
    # åŸå› æœ‰ä¸‰ï¼š
    #
    # 1. ã€æ‹¼æ¥éœ€è¦ç»´åº¦åŒ¹é…ã€‘
    #    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #    mask_concat æœ€ç»ˆè¦å’Œ latents_concat åœ¨é€šé“ç»´åº¦æ‹¼æ¥ï¼š
    #
    #    latents_concat: (B, 16, T, H, W)  â† 16 é€šé“çš„æ¡ä»¶å›¾åƒ latent
    #    mask_concat:    (B, 1,  T, H, W)  â† 1 é€šé“çš„ mask
    #    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #    æ‹¼æ¥ç»“æœ:       (B, 17, T, H, W)
    #
    #    å¦‚æœ mask æ˜¯ 1D çš„ (T,)ï¼Œå°±æ²¡æ³•ç›´æ¥æ‹¼æ¥ï¼Œéœ€è¦å…ˆæ‰©å±•ç»´åº¦ã€‚
    #    å®˜æ–¹é€‰æ‹©åœ¨å¤–éƒ¨å°±æ„é€ å¥½ 5D å¼ é‡ï¼Œæ¥å£æ›´ç»Ÿä¸€ã€‚
    #
    # 2. ã€Transformer çš„è¾“å…¥æ ¼å¼ã€‘
    #    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #    Transformer æœŸæœ›çš„æ¡ä»¶ latents æ ¼å¼æ˜¯ (B, C, T, H, W)
    #    æ‰€æœ‰é€šé“ï¼ˆåŒ…æ‹¬ maskï¼‰éƒ½åº”è¯¥æ˜¯è¿™ä¸ªæ ¼å¼ã€‚
    #    è¿™æ · Transformer å†…éƒ¨å¯ä»¥ç»Ÿä¸€å¤„ç†ï¼Œä¸éœ€è¦ç‰¹æ®Šé€»è¾‘ã€‚
    #
    # 3. ã€ä¸ºæœªæ¥æ‰©å±•é¢„ç•™ã€‘
    #    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #    è™½ç„¶å½“å‰ mask åœ¨æ•´å¸§å†…éƒ½æ˜¯åŒä¸€ä¸ªå€¼ï¼ˆè¦ä¹ˆå…¨ 0ï¼Œè¦ä¹ˆå…¨ 1ï¼‰ï¼Œ
    #    ä½†è¿™ç§è®¾è®¡å…è®¸æœªæ¥æ”¯æŒæ›´ç²¾ç»†çš„æ§åˆ¶ï¼š
    #
    #    - ç©ºé—´çº§åˆ«çš„ maskï¼šæŸäº›åŒºåŸŸæ˜¯æ¡ä»¶ï¼ŒæŸäº›éœ€è¦ç”Ÿæˆï¼ˆç±»ä¼¼ inpaintingï¼‰
    #    - ä¸å…¶ä»–æ¡ä»¶ä¿¡å·ï¼ˆæ·±åº¦å›¾ã€è¾¹ç¼˜å›¾ç­‰ï¼‰ä¿æŒä¸€è‡´çš„æ¥å£
    #
    # ã€å®é™…ä¸Šæ¯å¸§å†…çš„å€¼æ˜¯ç›¸åŒçš„ã€‘
    #
    #    mask_concat[:, :, 0, :, :] = 1.0  â† ç¬¬ 0 å¸§æ‰€æœ‰ HÃ—W ä½ç½®éƒ½æ˜¯ 1
    #    mask_concat[:, :, 1, :, :] = 0.0  â† ç¬¬ 1 å¸§æ‰€æœ‰ HÃ—W ä½ç½®éƒ½æ˜¯ 0
    #    ...
    #
    #    è™½ç„¶æµªè´¹äº†ä¸€äº›å­˜å‚¨ç©ºé—´ï¼Œä½†æ¢æ¥äº†æ¥å£çš„ç»Ÿä¸€æ€§å’Œæ‰©å±•æ€§ã€‚
    #
    # ========================================================================
    
    # æ­¥éª¤ 1: åˆ›å»ºä¸¤ä¸ª"ç´ æ"å¼ é‡
    # mask_zeros: å…¨ 0ï¼Œè¡¨ç¤º"éœ€è¦ç”Ÿæˆ"
    # mask_ones: å…¨ 1ï¼Œè¡¨ç¤º"è¿™æ˜¯æ¡ä»¶å¸§"
    # shape éƒ½æ˜¯ (B, 1, T, H, W) - 1 ä¸ªé€šé“ï¼ŒT å¸§ï¼ŒHÃ—W ç©ºé—´
    mask_zeros = torch.zeros(latents.shape[0], 1, latents.shape[2], latents.shape[3], latents.shape[4])
    mask_ones = torch.ones(latents.shape[0], 1, latents.shape[2], latents.shape[3], latents.shape[4])
    
    # ========================================================================
    # æ­¥éª¤ 2: ä½¿ç”¨ merge_tensor_by_mask æ ¹æ® multitask_mask é€‰æ‹©æ€§åˆå¹¶
    # ========================================================================
    #
    # ã€merge_tensor_by_mask å‡½æ•°è§£æã€‘
    #
    # å‡½æ•°ç­¾å:
    #   merge_tensor_by_mask(tensor1, tensor2, mask, dim)
    #
    # åŠŸèƒ½:
    #   æ ¹æ® mask çš„å€¼ï¼Œä» tensor1 æˆ– tensor2 ä¸­é€‰æ‹©å¯¹åº”ä½ç½®çš„å€¼
    #   - mask[i] = 0 â†’ é€‰æ‹© tensor1 çš„ç¬¬ i å¸§
    #   - mask[i] = 1 â†’ é€‰æ‹© tensor2 çš„ç¬¬ i å¸§
    #
    # å‚æ•°:
    #   - tensor1: mask=0 æ—¶ä½¿ç”¨çš„å¼ é‡ (mask_zerosï¼Œå…¨ 0)
    #   - tensor2: mask=1 æ—¶ä½¿ç”¨çš„å¼ é‡ (mask_onesï¼Œå…¨ 1)
    #   - mask: æ§åˆ¶é€‰æ‹©çš„ mask (multitask_mask)
    #   - dim: åœ¨å“ªä¸ªç»´åº¦ä¸Šæ“ä½œ (dim=2 è¡¨ç¤ºæ—¶é—´ç»´åº¦ T)
    #
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ ã€å…·ä½“ä¾‹å­ã€‘                                                         â”‚
    # â”‚                                                                      â”‚
    # â”‚ å‡è®¾ T=13 (13 ä¸ª latent å¸§)                                          â”‚
    # â”‚                                                                      â”‚
    # â”‚ t2v æ¨¡å¼:                                                            â”‚
    # â”‚   multitask_mask = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]           â”‚
    # â”‚                    â†“                                                 â”‚
    # â”‚   ç»“æœ mask_concat:                                                   â”‚
    # â”‚   å¸§ç´¢å¼•:    0    1    2    3    4   ...   12                        â”‚
    # â”‚   å€¼:      [0.0, 0.0, 0.0, 0.0, 0.0, ..., 0.0]                       â”‚
    # â”‚            â†‘ å…¨éƒ¨æ˜¯ 0ï¼Œæ‰€æœ‰å¸§éƒ½éœ€è¦ç”Ÿæˆ                               â”‚
    # â”‚                                                                      â”‚
    # â”‚ i2v æ¨¡å¼:                                                            â”‚
    # â”‚   multitask_mask = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]           â”‚
    # â”‚                    â†“                                                 â”‚
    # â”‚   ç»“æœ mask_concat:                                                   â”‚
    # â”‚   å¸§ç´¢å¼•:    0    1    2    3    4   ...   12                        â”‚
    # â”‚   å€¼:      [1.0, 0.0, 0.0, 0.0, 0.0, ..., 0.0]                       â”‚
    # â”‚            â†‘ ç¬¬ä¸€å¸§æ˜¯ 1ï¼ˆæ¡ä»¶å¸§ï¼‰ï¼Œå…¶ä½™æ˜¯ 0ï¼ˆç”Ÿæˆå¸§ï¼‰                  â”‚
    # â”‚                                                                      â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #
    # ã€ä¸ºä»€ä¹ˆç”¨ merge_tensor_by_mask è€Œä¸æ˜¯ç®€å•çš„ç´¢å¼•æ“ä½œï¼Ÿã€‘
    #
    # 1. çµæ´»æ€§ï¼šæ”¯æŒä»»æ„å¤æ‚çš„ mask æ¨¡å¼
    #    - ä¸åªæ˜¯"ç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å¸§"
    #    - å¯ä»¥æ˜¯ä»»æ„å¸§çš„ç»„åˆï¼Œå¦‚ [1, 0, 0, 1, 0, ...]ï¼ˆé¦–å°¾éƒ½æ˜¯æ¡ä»¶å¸§ï¼‰
    #
    # 2. ä¸€è‡´æ€§ï¼šä¸ HunyuanVideo çš„å…¶ä»–å¤šä»»åŠ¡åŠŸèƒ½ä¿æŒä¸€è‡´
    #    - æ”¯æŒ FVS (First-Video-Segment) ç­‰æ›´å¤æ‚çš„ä»»åŠ¡
    #    - ç»Ÿä¸€çš„æ¥å£å¤„ç†å„ç§æ¡ä»¶å¸§æ¨¡å¼
    #
    # 3. æ‰¹å¤„ç†å‹å¥½ï¼šå¯ä»¥å¤„ç† batch ä¸­ä¸åŒæ ·æœ¬æœ‰ä¸åŒ mask çš„æƒ…å†µ
    #
    # ========================================================================
    
    # ========================================================================
    # ã€ä¸ºä»€ä¹ˆè¿™é‡Œç”¨ .cpu()ï¼Ÿã€‘
    # ========================================================================
    #
    # çŸ­ç­”æ¡ˆï¼šè¿™æ˜¯å®˜æ–¹ä»£ç çš„å†™æ³•ï¼Œå¯èƒ½æ˜¯å†å²é—ç•™æˆ–è¿‡åº¦è°¨æ…ã€‚
    #
    # è¯¦ç»†åˆ†æï¼š
    #
    # 1. ã€å®˜æ–¹ä»£ç å°±æ˜¯è¿™ä¹ˆå†™çš„ã€‘
    #    è¿™æ®µä»£ç æ˜¯ä» HunyuanVideo å®˜æ–¹ pipeline ç§»æ¤è¿‡æ¥çš„ã€‚
    #    å®˜æ–¹åœ¨å¤„ç† merge_tensor_by_mask æ—¶å°±ç”¨äº† .cpu()ã€‚
    #
    # 2. ã€merge_tensor_by_mask å†…éƒ¨å®ç°ã€‘
    #    æŸ¥çœ‹ hyvideo/utils/multitask_utils.pyï¼Œè¿™ä¸ªå‡½æ•°å†…éƒ¨å¯èƒ½ä½¿ç”¨ï¼š
    #    - Python å¾ªç¯éå† batch
    #    - åˆ—è¡¨æ“ä½œ
    #    - torch.stack() ç­‰æ“ä½œ
    #
    #    è¿™äº›æ“ä½œåœ¨ GPU tensor ä¸Šä¹Ÿèƒ½å·¥ä½œï¼Œä½†å®˜æ–¹é€‰æ‹©åœ¨ CPU ä¸Šåšã€‚
    #
    # 3. ã€å¯èƒ½çš„åŸå› ã€‘
    #    a) å†å²åŸå› ï¼šæ—©æœŸå¼€å‘æ—¶å¯èƒ½é‡åˆ°æŸäº› GPU å…¼å®¹æ€§é—®é¢˜
    #    b) å®‰å…¨èµ·è§ï¼šç¡®ä¿å°å¼ é‡æ“ä½œä¸å ç”¨ GPU èµ„æº
    #    c) è°ƒè¯•æ–¹ä¾¿ï¼šCPU ä¸Šæ›´å®¹æ˜“è°ƒè¯•
    #    d) åŸå§‹å®ç°å°±åœ¨ CPU ä¸Š
    #
    # 4. ã€å®é™…å½±å“ã€‘
    #    - mask_zeros/mask_ones å¾ˆå°ï¼š(1, 1, 13, 45, 80) â‰ˆ 0.2MB
    #    - CPU â†” GPU ä¼ è¾“å¼€é”€å¾ˆå°
    #    - å¯¹æ•´ä½“æ€§èƒ½å½±å“å¯å¿½ç•¥ï¼ˆç›¸æ¯” Transformer çš„è®¡ç®—é‡ï¼‰
    #
    # 5. ã€èƒ½å»æ‰ .cpu() å—ï¼Ÿã€‘
    #    ç†è®ºä¸Šå¯ä»¥å°è¯•ï¼š
    #    ```python
    #    mask_concat = merge_tensor_by_mask(
    #        mask_zeros,  # å·²ç»åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
    #        mask_ones,
    #        mask=multitask_mask.to(latents.device),
    #        dim=2
    #    )
    #    ```
    #    ä½†æ²¡å¿…è¦å†’é™©æ”¹åŠ¨ï¼Œå› ä¸ºï¼š
    #    - æ€§èƒ½æ”¶ç›Šå¾®ä¹å…¶å¾®
    #    - å¯èƒ½å¼•å…¥æœªçŸ¥ bug
    #    - ä¸å®˜æ–¹ä»£ç ä¿æŒä¸€è‡´æ›´å®‰å…¨
    #
    # ========================================================================
    
    mask_concat = merge_tensor_by_mask(
        mask_zeros.cpu(),           # tensor1: mask=0 æ—¶é€‰è¿™ä¸ªï¼ˆå…¨ 0ï¼‰â†’ ç§»åˆ° CPU
        mask_ones.cpu(),            # tensor2: mask=1 æ—¶é€‰è¿™ä¸ªï¼ˆå…¨ 1ï¼‰â†’ ç§»åˆ° CPU
        mask=multitask_mask.cpu(),  # æ§åˆ¶é€‰æ‹©çš„ mask â†’ ç§»åˆ° CPU
        dim=2                       # åœ¨æ—¶é—´ç»´åº¦ (T) ä¸Šæ“ä½œ
    ).to(device=latents.device)     # æœ€åæŠŠç»“æœç§»å› GPU
    
    # æ‹¼æ¥ï¼š[æ¡ä»¶ latents (16 é€šé“), mask (1 é€šé“)]
    return torch.concat([latents_concat, mask_concat], dim=1)


# ============================================================================
# ğŸ“ è¾…åŠ©å‡½æ•°ï¼šè·å–æœ€æ¥è¿‘çš„åˆ†è¾¨ç‡
# ============================================================================
# 
# ã€ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªå‡½æ•°ï¼Ÿã€‘
# 
# 1. è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨ç‰¹å®šåˆ†è¾¨ç‡ä¸Šè®­ç»ƒ
# 2. å¿…é¡»ä½¿ç”¨ä¸è®­ç»ƒä¸€è‡´çš„åˆ†è¾¨ç‡æ‰èƒ½è·å¾—å¥½æ•ˆæœ
# 3. åˆ†è¾¨ç‡å¿…é¡»æ˜¯æŸäº›æ•°å­—çš„å€æ•°ï¼ˆå¦‚ 16ï¼‰ä»¥åŒ¹é… VAE
# 
# ã€Bucket ç³»ç»Ÿã€‘
# 
# HunyuanVideo ä½¿ç”¨ "bucket" ç³»ç»Ÿç®¡ç†åˆ†è¾¨ç‡ï¼š
# - å®šä¹‰ä¸€ç»„æ ‡å‡†åˆ†è¾¨ç‡
# - æ ¹æ®ç”¨æˆ·è¯·æ±‚çš„å®½é«˜æ¯”é€‰æ‹©æœ€æ¥è¿‘çš„åˆ†è¾¨ç‡
# ============================================================================

def get_closest_resolution(aspect_ratio, target_resolution):
    """
    æ ¹æ®å®½é«˜æ¯”è·å–æœ€æ¥è¿‘çš„æ ‡å‡†åˆ†è¾¨ç‡
    
    Args:
        aspect_ratio: å®½é«˜æ¯”å­—ç¬¦ä¸² (å¦‚ "16:9", "9:16", "1:1")
        target_resolution: ç›®æ ‡åˆ†è¾¨ç‡çº§åˆ« ("360p", "480p", "720p", "1080p")
    
    Returns:
        tuple: (height, width) æœ€æ¥è¿‘çš„æ ‡å‡†åˆ†è¾¨ç‡
    
    å·¥ä½œåŸç†ï¼š
    1. æ ¹æ® target_resolution ç¡®å®šåŸºç¡€å°ºå¯¸
    2. ç”Ÿæˆè¯¥åˆ†è¾¨ç‡ä¸‹æ‰€æœ‰å¯èƒ½çš„ (H, W) ç»„åˆ
    3. æ‰¾åˆ°å®½é«˜æ¯”æœ€æ¥è¿‘ç”¨æˆ·è¯·æ±‚çš„ç»„åˆ
    
    ä¾‹å¦‚:
        aspect_ratio="16:9", target_resolution="720p"
        â†’ è¿”å› (720, 1280) æˆ–æ¥è¿‘çš„å€¼
    """
    from hyvideo.utils.data_utils import generate_crop_size_list, get_closest_ratio
    
    # å„åˆ†è¾¨ç‡çº§åˆ«çš„é…ç½®
    # bucket_hw_base_size: åŸºç¡€å°ºå¯¸ï¼ˆç”¨äºç”Ÿæˆå€™é€‰åˆ†è¾¨ç‡ï¼‰
    # bucket_hw_bucket_stride: åˆ†è¾¨ç‡æ­¥é•¿ï¼ˆå¿…é¡»æ˜¯æ­¤æ•°çš„å€æ•°ï¼‰
    target_size_config = {
        "360p": {"bucket_hw_base_size": 480, "bucket_hw_bucket_stride": 16},
        "480p": {"bucket_hw_base_size": 640, "bucket_hw_bucket_stride": 16},
        "720p": {"bucket_hw_base_size": 960, "bucket_hw_bucket_stride": 16},
        "1080p": {"bucket_hw_base_size": 1440, "bucket_hw_bucket_stride": 16},
    }
    
    bucket_hw_base_size = target_size_config[target_resolution]["bucket_hw_base_size"]
    bucket_hw_bucket_stride = target_size_config[target_resolution]["bucket_hw_bucket_stride"]
    
    # è§£æå®½é«˜æ¯”
    if ":" in aspect_ratio:
        w_ratio, h_ratio = map(int, aspect_ratio.split(":"))
    else:
        # é»˜è®¤ 16:9
        w_ratio, h_ratio = 16, 9
    
    # ç”Ÿæˆæ‰€æœ‰å€™é€‰åˆ†è¾¨ç‡
    crop_size_list = generate_crop_size_list(bucket_hw_base_size, bucket_hw_bucket_stride)
    
    # è®¡ç®—æ¯ä¸ªå€™é€‰åˆ†è¾¨ç‡çš„å®½é«˜æ¯”
    aspect_ratios = np.array([round(float(h) / float(w), 5) for h, w in crop_size_list])
    
    # æ‰¾åˆ°æœ€æ¥è¿‘çš„åˆ†è¾¨ç‡
    closest_size, _ = get_closest_ratio(h_ratio, w_ratio, aspect_ratios, crop_size_list)
    
    return closest_size[0], closest_size[1]  # height, width


# ============================================================================
# ğŸš€ ä¸»å‡½æ•°
# ============================================================================
# 
# è¿™æ˜¯ Stage 2 çš„æ ¸å¿ƒé€»è¾‘ï¼š
# 1. åŠ è½½ Stage 1 çš„è¾“å‡ºï¼ˆtext embeddingsï¼‰
# 2. åŠ è½½ Transformer æ¨¡å‹
# 3. è¿è¡Œæ‰©æ•£å»å™ªå¾ªç¯
# 4. ä¿å­˜è¾“å‡ºçš„ latents
# ============================================================================

def main():
    # ========================================================================
    # ğŸ“‹ å‚æ•°è§£æ
    # ========================================================================
    parser = argparse.ArgumentParser(description='HunyuanVideo-1.5 Stage 2: Transformer')
    
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    parser.add_argument('--input_dir', type=str, default='./stage_outputs',
                       help='Stage 1 è¾“å‡ºç›®å½•ï¼ŒåŒ…å« embeddings å’Œ config')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤åŒ input_dir')
    
    # è§†é¢‘ç”Ÿæˆå‚æ•°
    parser.add_argument('--aspect_ratio', type=str, default='16:9',
                       help='è§†é¢‘å®½é«˜æ¯”ï¼Œå¦‚ 16:9, 9:16, 1:1')
    parser.add_argument('--video_length', type=int, default=49,
                       help='è§†é¢‘å¸§æ•° (æ¨è 49, 97, 145 ç­‰ 4n+1 çš„å€¼)')
    parser.add_argument('--num_inference_steps', type=int, default=50,
                       help='æ¨ç†æ­¥æ•°ï¼Œè¶Šå¤šè´¨é‡è¶Šå¥½ä½†è¶Šæ…¢')
    parser.add_argument('--guidance_scale', type=float, default=6.0,
                       help='CFG å¼•å¯¼å¼ºåº¦ï¼Œè¶Šé«˜è¶Šç¬¦åˆ prompt')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ï¼Œç”¨äºå¤ç°ç»“æœ')
    
    args = parser.parse_args()
    
    # ========================================================================
    # âš¡ åˆå§‹åŒ–æ¨ç†çŠ¶æ€ (infer_state)
    # ========================================================================
    # 
    # infer_state æ§åˆ¶å„ç§æ¨ç†ä¼˜åŒ–ï¼š
    # 
    # - use_sageattn: æ˜¯å¦ä½¿ç”¨ SageAttentionï¼ˆä¸€ç§é«˜æ•ˆæ³¨æ„åŠ›å®ç°ï¼‰
    # - sage_blocks_range: å“ªäº› Transformer å—ä½¿ç”¨ SageAttention
    # - enable_torch_compile: æ˜¯å¦å¯ç”¨ torch.compile åŠ é€Ÿ
    # - enable_cache: æ˜¯å¦å¯ç”¨ DeepCacheï¼ˆè·³è¿‡éƒ¨åˆ†è®¡ç®—ï¼‰
    # - cache_type: ç¼“å­˜ç±»å‹
    # - no_cache_block_id: ä¸ç¼“å­˜çš„å— ID
    # - cache_start_step: ä»ç¬¬å‡ æ­¥å¼€å§‹ç¼“å­˜
    # - cache_end_step: ç¬¬å‡ æ­¥ç»“æŸç¼“å­˜
    # - cache_step_interval: ç¼“å­˜æ­¥é—´éš”
    # 
    # è¿™äº›ä¼˜åŒ–å¯ä»¥æ˜¾è‘—åŠ é€Ÿæ¨ç†ï¼Œä½†å¯èƒ½å½±å“è´¨é‡ã€‚
    # ========================================================================
    infer_args = SimpleNamespace(
        use_sageattn=False,              # ä¸ä½¿ç”¨ SageAttention
        sage_blocks_range="0-53",        # å¦‚æœä½¿ç”¨ï¼Œåº”ç”¨åˆ°æ‰€æœ‰ 53 ä¸ªå—
        enable_torch_compile=False,      # ä¸å¯ç”¨ç¼–è¯‘ï¼ˆè°ƒè¯•æ—¶å…³é—­ï¼‰
        enable_cache=False,              # ä¸å¯ç”¨ç¼“å­˜ï¼ˆä¿æŒæœ€é«˜è´¨é‡ï¼‰
        cache_type="deepcache",
        no_cache_block_id="53",
        cache_start_step=11,
        cache_end_step=45,
        total_steps=args.num_inference_steps,
        cache_step_interval=4,
    )
    initialize_infer_state(infer_args)
    
    # è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    output_dir = args.output_dir or args.input_dir
    input_paths = get_default_paths(args.input_dir)
    output_paths = get_default_paths(output_dir)
    
    print_rank0(f"\n{'='*60}")
    print_rank0("HunyuanVideo-1.5 Stage 2: Transformer (ç›´æ¥åŠ è½½ï¼Œæ—  text encoder)")
    print_rank0(f"{'='*60}")
    
    # ========================================================================
    # ğŸ“‚ åŠ è½½ Stage 1 çš„è¾“å‡º
    # ========================================================================
    # 
    # Stage 1 ç”Ÿæˆçš„æ–‡ä»¶ï¼š
    # - config.json: ç”Ÿæˆé…ç½®ï¼ˆpromptã€æ¨¡å‹è·¯å¾„ç­‰ï¼‰
    # - embeddings.safetensors: æ–‡æœ¬åµŒå…¥å‘é‡
    # 
    # æˆ‘ä»¬éœ€è¦è¿™äº›æ¥æŒ‡å¯¼ Transformer ç”Ÿæˆä»€ä¹ˆæ ·çš„è§†é¢‘ã€‚
    # ========================================================================
    
    print_rank0(f"\nåŠ è½½ Stage 1 é…ç½®: {input_paths['config']}")
    config = load_generation_config(input_paths['config'])
    
    print_rank0(f"åŠ è½½ Stage 1 embeddings: {input_paths['embeddings']}")
    embeddings_dict, _ = load_embeddings_from_safetensors(input_paths['embeddings'], device='cpu')
    
    # ç”¨å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    config['aspect_ratio'] = args.aspect_ratio
    config['video_length'] = args.video_length
    config['num_inference_steps'] = args.num_inference_steps
    config['guidance_scale'] = args.guidance_scale
    config['seed'] = args.seed
    
    # ä»é…ç½®ä¸­æå–æ¨¡å‹ä¿¡æ¯
    model_path = config['model_path']
    transformer_version = config['transformer_version']
    resolution = config.get('resolution', '720p')
    task_type = config.get('task_type', 't2v')
    
    print_rank0(f"\né…ç½®:")
    print_rank0(f"  model_path: {model_path}")
    print_rank0(f"  transformer_version: {transformer_version}")
    print_rank0(f"  resolution: {resolution}")
    print_rank0(f"  task_type: {task_type}")
    print_rank0(f"  aspect_ratio: {args.aspect_ratio}")
    print_rank0(f"  video_length: {args.video_length}")
    print_rank0(f"  num_inference_steps: {args.num_inference_steps}")
    print_rank0(f"  guidance_scale: {args.guidance_scale}")
    print_rank0(f"  seed: {args.seed}")
    
    # ========================================================================
    # ğŸ¤– åŠ è½½ Transformer æ¨¡å‹
    # ========================================================================
    # 
    # ã€HunyuanVideo_1_5_DiffusionTransformerã€‘
    # 
    # è¿™æ˜¯ä¸€ä¸ªåŸºäº DiT (Diffusion Transformer) æ¶æ„çš„æ¨¡å‹ï¼š
    # 
    # ç»“æ„æ¦‚è§ˆï¼š
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Input: latents (B, 33, T, H, W)                          â”‚
    # â”‚        text embeddings (B, L, D)                         â”‚
    # â”‚        timestep (B,)                                     â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Patchify + Position Embedding                            â”‚
    # â”‚ å°†è§†é¢‘åˆ‡æˆ patchesï¼Œæ·»åŠ ä½ç½®ç¼–ç                           â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Transformer Blocks Ã— 53                                  â”‚
    # â”‚ æ¯ä¸ªå—åŒ…å«:                                               â”‚
    # â”‚   - Self-Attention (è§†é¢‘ patches ä¹‹é—´)                   â”‚
    # â”‚   - Cross-Attention (è§†é¢‘ â†” æ–‡æœ¬)                        â”‚
    # â”‚   - FFN (å‰é¦ˆç½‘ç»œ)                                       â”‚
    # â”‚   - Time Embedding æ³¨å…¥                                  â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Unpatchify                                               â”‚
    # â”‚ å°† patches é‡ç»„ä¸ºè§†é¢‘ latents                             â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”‚ Output: noise prediction (B, 16, T, H, W)                â”‚
    # 
    # ã€ä¸ºä»€ä¹ˆç›´æ¥åŠ è½½è€Œä¸ç”¨ pipelineï¼Ÿã€‘
    # 
    # create_pipeline ä¼šåŠ è½½æ‰€æœ‰ç»„ä»¶ï¼Œä½†æˆ‘ä»¬åªéœ€è¦ Transformerï¼š
    # - Text Encoder: åœ¨ Stage 1 å·²ç»ç”¨è¿‡äº†
    # - VAE: åœ¨ Stage 3 æ‰ä¼šç”¨
    # - åªåŠ è½½éœ€è¦çš„å¯ä»¥èŠ‚çœ ~20GB å†…å­˜
    # ========================================================================
    
    print_rank0(f"\nç›´æ¥åŠ è½½ Transformerï¼ˆä¸åŠ è½½å…¶ä»–ç»„ä»¶ï¼‰...")
    
    # ç¡®å®šæ•°æ®ç±»å‹
    dtype = config.get('dtype', 'bf16')
    if dtype == 'bf16':
        transformer_dtype = torch.bfloat16  # æ¨èï¼šæ›´å¿«ã€å†…å­˜æ›´å°‘
    else:
        transformer_dtype = torch.float32
    
    # æ„å»º Transformer è·¯å¾„
    transformer_path = os.path.join(model_path, "transformer", transformer_version)
    print_rank0(f"  åŠ è½½è·¯å¾„: {transformer_path}")
    
    # åŠ è½½ Transformer
    transformer = HunyuanVideo_1_5_DiffusionTransformer.from_pretrained(
        transformer_path,
        torch_dtype=transformer_dtype,
        low_cpu_mem_usage=True,  # ä¼˜åŒ–å†…å­˜ä½¿ç”¨
    )
    
    # ç§»åŠ¨åˆ° GPU å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    device = torch.device('cuda')
    transformer = transformer.to(device)
    transformer.eval()  # å…³é—­ dropout ç­‰è®­ç»ƒä¸“ç”¨å±‚
    
    print_rank0(f"  âœ“ Transformer åŠ è½½å®Œæˆ")
    print_rank0(f"  attn_mode: {transformer.attn_mode}")  # æ³¨æ„åŠ›æ¨¡å¼
    print_rank0(f"  use_meanflow: {transformer.config.use_meanflow}")  # æ˜¯å¦ä½¿ç”¨ meanflow
    print_rank0(f"  dtype: {transformer.dtype}")
    
    # ========================================================================
    # â±ï¸ åŠ è½½ Schedulerï¼ˆè°ƒåº¦å™¨ï¼‰
    # ========================================================================
    # 
    # ã€ä»€ä¹ˆæ˜¯ Schedulerï¼Ÿã€‘
    # 
    # Scheduler æ§åˆ¶æ‰©æ•£è¿‡ç¨‹çš„"èŠ‚å¥"ï¼š
    # - å†³å®šæ¯ä¸€æ­¥æ·»åŠ /å»é™¤å¤šå°‘å™ªå£°
    # - å†³å®šæ—¶é—´æ­¥çš„åˆ†å¸ƒ
    # - ä¸åŒçš„ scheduler æœ‰ä¸åŒçš„é€Ÿåº¦/è´¨é‡æƒè¡¡
    # 
    # ã€FlowMatchDiscreteSchedulerã€‘
    # 
    # è¿™æ˜¯ä¸“é—¨ä¸º Flow Matching è®¾è®¡çš„è°ƒåº¦å™¨ï¼š
    # 
    # æ ¸å¿ƒæ¦‚å¿µï¼š
    # - ä¸ç›´æ¥é¢„æµ‹å™ªå£°ï¼Œè€Œæ˜¯é¢„æµ‹"æµ"ï¼ˆä»å™ªå£°åˆ°æ•°æ®çš„æ–¹å‘ï¼‰
    # - ä½¿ç”¨ ODE æ±‚è§£å™¨ï¼ˆå¦‚ Eulerï¼‰æ¥è¿­ä»£
    # 
    # å…³é”®å‚æ•°ï¼š
    # - shift (flow_shift): æ§åˆ¶æ—¶é—´æ­¥çš„åˆ†å¸ƒåç§»
    #   - è¾ƒå¤§çš„å€¼ï¼šåæœŸæ­¥éª¤æ›´å¯†é›†ï¼ˆæ›´æ³¨é‡ç»†èŠ‚ï¼‰
    #   - è¾ƒå°çš„å€¼ï¼šæ­¥éª¤æ›´å‡åŒ€åˆ†å¸ƒ
    # 
    # - reverse: True è¡¨ç¤ºä»å™ªå£°åˆ°æ•°æ®ï¼ˆæ¨ç†ï¼‰
    #            False è¡¨ç¤ºä»æ•°æ®åˆ°å™ªå£°ï¼ˆè®­ç»ƒï¼‰
    # 
    # - solver: ODE æ±‚è§£å™¨ç±»å‹
    #   - "euler": ä¸€é˜¶æ¬§æ‹‰æ³•ï¼ˆæœ€ç®€å•ã€æœ€å¿«ï¼‰
    #   - "heun": äºŒé˜¶æ–¹æ³•ï¼ˆæ›´å‡†ç¡®ã€ä½†æ…¢ï¼‰
    # ========================================================================
    
    scheduler_path = os.path.join(model_path, "scheduler")
    scheduler = FlowMatchDiscreteScheduler.from_pretrained(scheduler_path)
    
    # è·å– pipeline é…ç½®ä¸­çš„è°ƒåº¦å™¨å‚æ•°
    # PIPELINE_CONFIGS åŒ…å«å„ç‰ˆæœ¬çš„é»˜è®¤é…ç½®
    pipeline_config = PIPELINE_CONFIGS.get(transformer_version, PIPELINE_CONFIGS['720p_t2v'])
    flow_shift = pipeline_config['flow_shift']  # æ—¶é—´æ­¥åç§»
    default_guidance_scale = pipeline_config['guidance_scale']  # é»˜è®¤ CFG å¼ºåº¦
    
    print_rank0(f"  flow_shift: {flow_shift}")
    print_rank0(f"  default_guidance_scale: {default_guidance_scale}")
    
    # ä½¿ç”¨æ­£ç¡®çš„ flow_shift é‡å»º scheduler
    scheduler = FlowMatchDiscreteScheduler(
        shift=flow_shift,     # æ—¶é—´æ­¥åç§»
        reverse=True,         # æ¨ç†æ¨¡å¼ï¼ˆä»å™ªå£°åˆ°æ•°æ®ï¼‰
        solver="euler",       # ä½¿ç”¨æ¬§æ‹‰æ±‚è§£å™¨
    )
    
    # ========================================================================
    # ğŸ“ è®¾ç½®ç”Ÿæˆå‚æ•°
    # ========================================================================
    
    guidance_scale = args.guidance_scale
    seed = args.seed
    
    # CFG (Classifier-Free Guidance) åˆ¤æ–­
    # å½“ guidance_scale > 1.0 æ—¶å¯ç”¨ CFG
    # guidance_scale = 1.0 æ„å‘³ç€ä¸ä½¿ç”¨å¼•å¯¼ï¼ˆçº¯æ— æ¡ä»¶ç”Ÿæˆï¼‰
    do_classifier_free_guidance = guidance_scale > 1.0
    
    # Meanflow è®¾ç½®
    use_meanflow = transformer.config.use_meanflow
    
    target_dtype = transformer_dtype
    
    # è®¡ç®—å®é™…åˆ†è¾¨ç‡
    height, width = get_closest_resolution(args.aspect_ratio, resolution)
    print_rank0(f"\nåˆ†è¾¨ç‡: {width}x{height}")
    
    # ========================================================================
    # ğŸŒ± è®¾ç½®éšæœºç§å­
    # ========================================================================
    # 
    # ã€ä¸ºä»€ä¹ˆéœ€è¦åŒæ­¥ç§å­ï¼Ÿã€‘
    # 
    # åœ¨å¤š GPU (Sequence Parallelism) æ¨¡å¼ä¸‹ï¼š
    # - æ¯ä¸ª GPU éœ€è¦ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­
    # - å¦åˆ™ç”Ÿæˆçš„å™ªå£°ä¼šä¸ä¸€è‡´
    # - å¯¼è‡´è§†é¢‘åœ¨ä¸åŒ GPU çš„ç‰‡æ®µä¸è¿è´¯
    # 
    # é€šè¿‡ broadcast_object_list ä» rank 0 å¹¿æ’­ç§å­åˆ°æ‰€æœ‰è¿›ç¨‹
    # ========================================================================
    
    if get_parallel_state().sp_enabled:
        if dist.is_initialized():
            obj_list = [seed]
            # è·å– SP ç»„çš„æº rankï¼ˆrank 0ï¼‰
            group_src_rank = dist.get_global_rank(get_parallel_state().sp_group, 0)
            # å¹¿æ’­ç§å­åˆ°æ‰€æœ‰è¿›ç¨‹
            dist.broadcast_object_list(obj_list, src=group_src_rank, group=get_parallel_state().sp_group)
            seed = obj_list[0]
    
    # åˆ›å»º CPU ä¸Šçš„éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆä¸ºäº†å¯é‡ç°æ€§ï¼‰
    generator = torch.Generator(device=torch.device('cpu')).manual_seed(seed)
    
    # ========================================================================
    # ğŸ“ è®¡ç®— Latent å°ºå¯¸å’Œ Token æ•°é‡
    # ========================================================================
    
    video_length = args.video_length
    
    # è®¡ç®— latent å°ºå¯¸
    latent_target_length, latent_height, latent_width = get_latent_size(video_length, height, width)
    
    # Token æ•°é‡ = T Ã— H Ã— Wï¼ˆæ¯ä¸ª latent ä½ç½®æ˜¯ä¸€ä¸ª tokenï¼‰
    n_tokens = latent_target_length * latent_height * latent_width
    
    print_rank0(f"Latent å°ºå¯¸: {latent_target_length}x{latent_height}x{latent_width}")
    print_rank0(f"Token æ•°é‡: {n_tokens}")
    
    # ========================================================================
    # â° è®¾ç½®æ—¶é—´æ­¥
    # ========================================================================
    # 
    # ã€æ—¶é—´æ­¥å¦‚ä½•å·¥ä½œï¼Ÿã€‘
    # 
    # æ‰©æ•£æ¨¡å‹çš„æ¨ç†æ˜¯ä» t=Tï¼ˆçº¯å™ªå£°ï¼‰åˆ° t=0ï¼ˆæ¸…æ™°å›¾åƒï¼‰çš„è¿‡ç¨‹ã€‚
    # 
    # set_timesteps åšçš„äº‹æƒ…ï¼š
    # 1. æ ¹æ®æ¨ç†æ­¥æ•°å°† [0, 1] åŒºé—´åˆ†æˆ N ä»½
    # 2. åº”ç”¨ flow_shift è°ƒæ•´åˆ†å¸ƒ
    # 3. ç”Ÿæˆæ¯ä¸€æ­¥çš„æ—¶é—´å€¼
    # 
    # n_tokens å‚æ•°ç”¨äºæŸäº›è‡ªé€‚åº”è°ƒåº¦å™¨
    # ========================================================================
    
    scheduler.set_timesteps(args.num_inference_steps, device=device, n_tokens=n_tokens)
    timesteps = scheduler.timesteps
    
    # è·å–ä»»åŠ¡ç±»å‹ mask
    multitask_mask = get_task_mask(task_type, latent_target_length)
    
    # ========================================================================
    # ğŸ“ å‡†å¤‡ Text Embeddings
    # ========================================================================
    # 
    # ã€Embeddings çš„ç»“æ„ã€‘
    # 
    # Stage 1 ç”Ÿæˆäº†ä¸¤ç±»æ–‡æœ¬åµŒå…¥ï¼š
    # 
    # 1. LLM (LLaVA) Embeddings:
    #    - prompt_embeds: æ­£å‘æç¤ºè¯çš„åµŒå…¥ (B, seq_len, hidden_dim)
    #    - negative_prompt_embeds: è´Ÿå‘æç¤ºè¯çš„åµŒå…¥
    #    - prompt_embeds_mask: æ³¨æ„åŠ› mask
    # 
    # 2. ByT5 Embeddings (å¯é€‰):
    #    - prompt_embeds_2: ByT5 ç¼–ç çš„æç¤ºè¯
    #    - ç”¨äºæä¾›å­—ç¬¦çº§åˆ«çš„æ–‡æœ¬ç†è§£
    # 
    # ã€CFG çš„ Embedding å¤„ç†ã€‘
    # 
    # å¯ç”¨ CFG æ—¶ï¼Œéœ€è¦åŒæ—¶å¤„ç†æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„æ¨ç†ï¼š
    # - å°† negative å’Œ positive embeddings æ‹¼æ¥
    # - batch ç»´åº¦åŠ å€ï¼š[negative_embeds, positive_embeds]
    # - åç»­æ¨¡å‹ä¼šè¾“å‡ºä¸¤ä¸ªé¢„æµ‹ï¼Œç”¨äº CFG å…¬å¼
    # ========================================================================
    
    print_rank0(f"\nå‡†å¤‡ embeddings...")
    
    # åŠ è½½ LLM embeddings
    prompt_embeds = embeddings_dict['prompt_embeds'].to(device=device, dtype=transformer_dtype)
    negative_prompt_embeds = embeddings_dict['negative_prompt_embeds'].to(device=device, dtype=transformer_dtype)
    prompt_mask = embeddings_dict['prompt_embeds_mask'].to(device=device)
    negative_prompt_mask = embeddings_dict['negative_prompt_embeds_mask'].to(device=device)
    
    # åŠ è½½ ByT5 embeddingsï¼ˆå¯èƒ½ä¸º Noneï¼‰
    prompt_embeds_2 = embeddings_dict.get('prompt_embeds_2')
    negative_prompt_embeds_2 = embeddings_dict.get('negative_prompt_embeds_2')
    prompt_embeds_mask_2 = embeddings_dict.get('prompt_embeds_mask_2')
    negative_prompt_embeds_mask_2 = embeddings_dict.get('negative_prompt_embeds_mask_2')
    
    # CFG: åˆå¹¶æ­£å‘å’Œè´Ÿå‘ embeddings
    if do_classifier_free_guidance:
        # æ‹¼æ¥é¡ºåºï¼š[negative, positive]
        # è¿™æ ·åç»­ chunk(2) æ—¶ä¼šå¾—åˆ° [negative_pred, positive_pred]
        prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])
        prompt_mask = torch.cat([negative_prompt_mask, prompt_mask])
    
    # å‡†å¤‡ ByT5 embeddingsï¼ˆå¦‚æœæœ‰ï¼‰
    extra_kwargs = {}
    if prompt_embeds_2 is not None:
        # ByT5 ä½¿ç”¨ float32 ç²¾åº¦ï¼ˆæ›´é«˜ç²¾åº¦çš„å­—ç¬¦çº§ç†è§£ï¼‰
        prompt_embeds_2 = prompt_embeds_2.to(device=device, dtype=torch.float32)
        prompt_embeds_mask_2 = prompt_embeds_mask_2.to(device=device)
        
        if do_classifier_free_guidance:
            negative_prompt_embeds_2 = negative_prompt_embeds_2.to(device=device, dtype=torch.float32)
            negative_prompt_embeds_mask_2 = negative_prompt_embeds_mask_2.to(device=device)
            byt5_text_states = torch.cat([negative_prompt_embeds_2, prompt_embeds_2])
            byt5_text_mask = torch.cat([negative_prompt_embeds_mask_2, prompt_embeds_mask_2])
        else:
            byt5_text_states = prompt_embeds_2
            byt5_text_mask = prompt_embeds_mask_2
        
        extra_kwargs = {
            "byt5_text_states": byt5_text_states,
            "byt5_text_mask": byt5_text_mask,
        }
    
    print_rank0(f"  prompt_embeds shape: {prompt_embeds.shape}")
    print_rank0(f"  prompt_mask shape: {prompt_mask.shape}")
    if byt5_text_states is not None:
        print_rank0(f"  byt5_text_states shape: {byt5_text_states.shape}")
    
    # 720p_t2v ä¸ä½¿ç”¨é¢å¤–çš„ prompt_embeds_2 è¾“å…¥
    # ï¼ˆByT5 embeddings é€šè¿‡ extra_kwargs ä¼ é€’ï¼‰
    prompt_embeds_2 = None
    
    # ========================================================================
    # ğŸ² å‡†å¤‡ Latents
    # ========================================================================
    
    # è·å– latent é€šé“æ•°ï¼ˆä» Transformer é…ç½®ï¼‰
    num_channels_latents = transformer.config.in_channels  # é€šå¸¸æ˜¯ 16
    
    # ç”Ÿæˆéšæœºå™ªå£° latents
    latents = prepare_latents(
        1,                    # batch_size
        num_channels_latents, # é€šé“æ•° (16)
        latent_height,        # latent é«˜åº¦
        latent_width,         # latent å®½åº¦
        latent_target_length, # latent æ—¶é—´é•¿åº¦
        target_dtype,
        device,
        generator,
    )
    
    # å‡†å¤‡æ¡ä»¶ latents
    cond_latents = prepare_cond_latents(task_type, None, latents, multitask_mask)
    
    # ========================================================================
    # ğŸ‘ï¸ å‡†å¤‡ Vision States
    # ========================================================================
    # 
    # ã€ä»€ä¹ˆæ˜¯ Vision Statesï¼Ÿã€‘
    # 
    # Vision states æ˜¯æ¥è‡ªè§†è§‰ç¼–ç å™¨çš„ç‰¹å¾ï¼ˆå¦‚ CLIP ViTï¼‰ï¼š
    # - ç”¨äº i2v (Image-to-Video) ä»»åŠ¡
    # - ä¸ºæ¨¡å‹æä¾›è§†è§‰ä¸Šä¸‹æ–‡
    # 
    # å¯¹äº t2v (Text-to-Video)ï¼š
    # - æ²¡æœ‰è¾“å…¥å›¾åƒ
    # - ä½¿ç”¨å…¨é›¶å‘é‡ä½œä¸ºå ä½ç¬¦
    # 
    # å‚æ•°:
    # - vision_num_tokens: è§†è§‰ tokens æ•°é‡ (729 = 27Ã—27 for ViT-L/14)
    # - vision_dim: è§†è§‰ç‰¹å¾ç»´åº¦ (1152)
    # ========================================================================
    
    vision_num_tokens = 729  # 27Ã—27 patches
    vision_dim = 1152        # è§†è§‰ç‰¹å¾ç»´åº¦
    
    # t2v æ¨¡å¼ï¼šä½¿ç”¨é›¶å‘é‡
    vision_states = torch.zeros(
        latents.shape[0],     # batch_size
        vision_num_tokens,    # token æ•°é‡
        vision_dim            # ç‰¹å¾ç»´åº¦
    ).to(device=device, dtype=target_dtype)
    
    # CFG æ¨¡å¼éœ€è¦åŠ å€
    if do_classifier_free_guidance:
        vision_states = vision_states.repeat(2, 1, 1)
    
    print_rank0(f"  latents shape: {latents.shape}")
    print_rank0(f"  cond_latents shape: {cond_latents.shape}")
    print_rank0(f"  vision_states shape: {vision_states.shape}")
    
    # ========================================================================
    # ğŸ”„ Denoising Loopï¼ˆå»å™ªå¾ªç¯ï¼‰- æ ¸å¿ƒï¼
    # ========================================================================
    # 
    # è¿™æ˜¯æ‰©æ•£æ¨¡å‹æ¨ç†çš„æ ¸å¿ƒï¼šé€æ­¥å°†å™ªå£°è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„å†…å®¹ã€‚
    # 
    # ã€å·¥ä½œæµç¨‹ã€‘
    # 
    # for t in timesteps (ä» T åˆ° 0):
    #     1. å‡†å¤‡è¾“å…¥
    #        - æ‹¼æ¥ latents å’Œæ¡ä»¶ latents
    #        - å¯¹äº CFGï¼Œå¤åˆ¶è¾“å…¥
    #        - ç¼©æ”¾è¾“å…¥ï¼ˆscheduler è¦æ±‚ï¼‰
    #     
    #     2. Transformer å‰å‘ä¼ æ’­
    #        - è¾“å…¥: latents, timestep, text embeddings
    #        - è¾“å‡º: noise predictionï¼ˆé¢„æµ‹çš„å™ªå£°/æµï¼‰
    #     
    #     3. åº”ç”¨ CFG
    #        - noise = uncond + scale Ã— (cond - uncond)
    #     
    #     4. Scheduler æ›´æ–°
    #        - ä½¿ç”¨é¢„æµ‹æ›´æ–° latents
    #        - latents = scheduler.step(noise, t, latents)
    # 
    # ã€Meanflow ç‰¹æ®Šå¤„ç†ã€‘
    # 
    # å¦‚æœå¯ç”¨ meanflowï¼Œè¿˜éœ€è¦ä¼ é€’ timestep_rï¼š
    # - è¿™æ˜¯ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥
    # - ç”¨äºæ”¹å–„è§†é¢‘çš„æ—¶é—´è¿è´¯æ€§
    # ========================================================================
    
    print_rank0(f"\nå¼€å§‹ Transformer æ¨ç†...")
    print_rank0(f"  ä½¿ç”¨ Meanflow: {use_meanflow}")
    print_rank0(f"  ä½¿ç”¨ CFG: {do_classifier_free_guidance}")
    print_rank0(f"  SP çŠ¶æ€: sp_enabled={get_parallel_state().sp_enabled}, sp_size={get_parallel_state().sp}")
    
    # æ‰“å° GPU å†…å­˜ä½¿ç”¨ï¼ˆè°ƒè¯•ç”¨ï¼‰
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024**3)
        reserved = torch.cuda.memory_reserved() / (1024**3)
        print_rank0(f"  GPU å†…å­˜: allocated={allocated:.2f}GB, reserved={reserved:.2f}GB")
    
    start_time = time.perf_counter()
    num_inference_steps = len(timesteps)
    
    # ä½¿ç”¨ no_grad() ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†ä¸éœ€è¦æ¢¯åº¦ï¼‰
    with torch.no_grad():
        for i, t in enumerate(timesteps):
            # è¿›åº¦æ—¥å¿—
            if i % 10 == 0 or i == 0:
                print_rank0(f"  æ­¥éª¤ {i+1}/{num_inference_steps}")
                if torch.cuda.is_available():
                    allocated = torch.cuda.memory_allocated() / (1024**3)
                    print_rank0(f"    GPU allocated: {allocated:.2f}GB")
            
            # ================================================================
            # æ­¥éª¤ 1: å‡†å¤‡æ¨¡å‹è¾“å…¥
            # ================================================================
            
            # æ‹¼æ¥ä¸» latents å’Œæ¡ä»¶ latents
            # ç»“æœ: (B, 33, T, H, W)  [16 é€šé“ + 17 é€šé“]
            latents_concat = torch.concat([latents, cond_latents], dim=1)
            
            # CFG: å¤åˆ¶è¾“å…¥ï¼ˆæ— æ¡ä»¶ + æœ‰æ¡ä»¶ï¼‰
            if do_classifier_free_guidance:
                latent_model_input = torch.cat([latents_concat] * 2)  # (2B, 33, T, H, W)
            else:
                latent_model_input = latents_concat
            
            # Scheduler ç¼©æ”¾ï¼ˆæŸäº› scheduler éœ€è¦ï¼‰
            latent_model_input = scheduler.scale_model_input(latent_model_input, t)
            
            # æ‰©å±• timestep åˆ° batch ç»´åº¦
            t_expand = t.repeat(latent_model_input.shape[0])
            
            # ================================================================
            # æ­¥éª¤ 2: Meanflow timestep_r å¤„ç†
            # ================================================================
            #
            # Meanflow æŠ€æœ¯éœ€è¦çŸ¥é“"ä¸‹ä¸€ä¸ª"æ—¶é—´æ­¥
            # è¿™å¸®åŠ©æ¨¡å‹ç†è§£æ—¶é—´æµçš„æ–¹å‘
            #
            # æœ€åä¸€æ­¥ç‰¹æ®Šå¤„ç†ï¼šä¸‹ä¸€æ­¥æ˜¯ t=0ï¼ˆå®Œå…¨æ¸…æ™°ï¼‰
            
            if use_meanflow:
                if i == len(timesteps) - 1:
                    # æœ€åä¸€æ­¥ï¼šç›®æ ‡æ˜¯ t=0
                    timesteps_r = torch.tensor([0.0], device=device)
                else:
                    # å…¶ä»–æ­¥ï¼šä½¿ç”¨ä¸‹ä¸€ä¸ª timestep
                    timesteps_r = timesteps[i + 1]
                timesteps_r = timesteps_r.repeat(latent_model_input.shape[0])
            else:
                timesteps_r = None
            
            # ================================================================
            # æ­¥éª¤ 3: Embedded Guidance
            # ================================================================
            #
            # æŸäº›æ¨¡å‹æ”¯æŒ "embedded guidance"ï¼š
            # - å°† guidance scale ä½œä¸ºè¾“å…¥ä¼ ç»™æ¨¡å‹
            # - è®©æ¨¡å‹å†…éƒ¨å¤„ç† CFG
            #
            # HunyuanVideo-1.5 ç›®å‰ä¸ä½¿ç”¨æ­¤åŠŸèƒ½
            guidance_expand = None
            
            # ================================================================
            # æ­¥éª¤ 4: Transformer å‰å‘ä¼ æ’­
            # ================================================================
            #
            # ã€è¾“å…¥å‚æ•°è¯¦è§£ã€‘
            #
            # latent_model_input: è¾“å…¥ latents
            #   - shape: (B, 33, T, H, W) æˆ– CFG æ—¶ (2B, 33, T, H, W)
            #   - åŒ…å«ä¸» latents (16é€šé“) + æ¡ä»¶ latents (17é€šé“)
            #
            # t_expand: æ—¶é—´æ­¥
            #   - shape: (B,) æˆ– (2B,)
            #   - å½“å‰æ‰©æ•£æ—¶é—´æ­¥
            #
            # prompt_embeds: æ–‡æœ¬åµŒå…¥ï¼ˆä¸»ï¼‰
            #   - shape: (B, seq_len, hidden_dim) æˆ– CFG æ—¶ (2B, ...)
            #   - æ¥è‡ª LLaVA çš„æ–‡æœ¬ç†è§£
            #
            # prompt_embeds_2: æ–‡æœ¬åµŒå…¥ï¼ˆè¾…åŠ©ï¼‰
            #   - å¯¹äº 720p_t2v ä¸º None
            #   - å…¶ä»–ç‰ˆæœ¬å¯èƒ½ä½¿ç”¨ CLIP
            #
            # prompt_mask: æ³¨æ„åŠ› mask
            #   - æŒ‡ç¤ºå“ªäº› token æ˜¯çœŸå®çš„ï¼ˆé paddingï¼‰
            #
            # timestep_r: ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼ˆMeanflowï¼‰
            #
            # vision_states: è§†è§‰ç‰¹å¾
            #   - t2v æ—¶ä¸ºé›¶å‘é‡
            #   - i2v æ—¶ä¸ºå›¾åƒ CLIP ç‰¹å¾
            #
            # mask_type: ä»»åŠ¡ç±»å‹æ ‡è¯†
            #
            # guidance: embedded guidanceï¼ˆæœªä½¿ç”¨ï¼‰
            #
            # extra_kwargs: é¢å¤–å‚æ•°
            #   - åŒ…å« ByT5 embeddings
            #
            # ã€è¾“å‡ºã€‘
            #
            # output[0]: noise prediction
            #   - shape: (B, 16, T, H, W) æˆ– (2B, ...)
            #   - é¢„æµ‹çš„å™ªå£°/æµå‘é‡
            
            with torch.autocast(device_type="cuda", dtype=target_dtype, enabled=True):
                output = transformer(
                    latent_model_input,   # è¾“å…¥ latents
                    t_expand,             # æ—¶é—´æ­¥
                    prompt_embeds,        # LLM æ–‡æœ¬åµŒå…¥
                    prompt_embeds_2,      # è¾…åŠ©æ–‡æœ¬åµŒå…¥ (None for 720p_t2v)
                    prompt_mask,          # æ³¨æ„åŠ› mask
                    timestep_r=timesteps_r,        # Meanflow æ—¶é—´æ­¥
                    vision_states=vision_states,   # è§†è§‰ç‰¹å¾
                    mask_type=task_type,           # ä»»åŠ¡ç±»å‹
                    guidance=guidance_expand,      # Embedded guidance (None)
                    return_dict=False,             # è¿”å›å…ƒç»„è€Œéå­—å…¸
                    extra_kwargs=extra_kwargs,     # ByT5 ç­‰é¢å¤–å‚æ•°
                )
                noise_pred = output[0]
            
            # ================================================================
            # æ­¥éª¤ 5: åº”ç”¨ CFG (Classifier-Free Guidance)
            # ================================================================
            #
            # CFG å…¬å¼:
            #   output = uncond + scale Ã— (cond - uncond)
            #
            # ç›´è§‰è§£é‡Š:
            # - uncond: æ¨¡å‹"è‡ªç”±å‘æŒ¥"çš„é¢„æµ‹
            # - cond: æ¨¡å‹"éµå¾ªæç¤ºè¯"çš„é¢„æµ‹
            # - (cond - uncond): æç¤ºè¯å¸¦æ¥çš„"æ–¹å‘"
            # - scale: æ”¾å¤§è¿™ä¸ªæ–¹å‘
            #
            # æ•ˆæœ:
            # - scale = 1.0: ç­‰äºæ™®é€šæ¡ä»¶ç”Ÿæˆ
            # - scale = 7.0: æ›´å¼ºè°ƒæç¤ºè¯
            # - scale > 15: å¯èƒ½è¿‡åº¦ï¼Œäº§ç”Ÿä¼ªå½±
            
            if do_classifier_free_guidance:
                # åˆ†ç¦»æ— æ¡ä»¶å’Œæœ‰æ¡ä»¶çš„é¢„æµ‹
                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
                # åº”ç”¨ CFG å…¬å¼
                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)
            
            # ================================================================
            # æ­¥éª¤ 6: Scheduler æ›´æ–° Latents
            # ================================================================
            #
            # ã€scheduler.step() åšäº†ä»€ä¹ˆï¼Ÿã€‘
            #
            # ä½¿ç”¨é¢„æµ‹çš„å™ªå£°/æµæ¥æ›´æ–° latentsï¼š
            #
            # å¯¹äº Flow Matching (Euler solver):
            #   z_{t-1} = z_t + Î”t Ã— flow_prediction
            #
            # å…¶ä¸­:
            # - z_t: å½“å‰ latents
            # - Î”t: æ—¶é—´æ­¥é•¿
            # - flow_prediction: æ¨¡å‹é¢„æµ‹çš„"æµ"æ–¹å‘
            #
            # è¿”å›å€¼:
            # - [0]: æ›´æ–°åçš„ latents
            # - [1]: å¯é€‰çš„å…¶ä»–ä¿¡æ¯ï¼ˆæˆ‘ä»¬ä¸ä½¿ç”¨ï¼‰
            
            latents = scheduler.step(noise_pred, t, latents, generator=generator, return_dict=False)[0]
    
    # è®°å½•æ¨ç†æ—¶é—´
    elapsed = time.perf_counter() - start_time
    print_rank0(f"\nâœ“ Transformer æ¨ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f} ç§’")
    print_rank0(f"  Latents shape: {latents.shape}")
    print_rank0(f"  Latents dtype: {latents.dtype}")
    
    # ========================================================================
    # ğŸ’¾ ä¿å­˜è¾“å‡º
    # ========================================================================
    #
    # åªæœ‰ rank 0 ä¿å­˜æ–‡ä»¶ï¼ˆé¿å…å¤šè¿›ç¨‹å†™å…¥å†²çªï¼‰
    #
    # è¾“å‡ºå†…å®¹:
    # 1. latents.safetensors: å»å™ªåçš„ latents
    # 2. config.json: æ›´æ–°çš„ç”Ÿæˆé…ç½®
    # ========================================================================
    
    if get_rank() == 0:
        print_rank0(f"\nä¿å­˜ latents åˆ°: {output_paths['latents']}")
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            'height': str(height),
            'width': str(width),
            'video_length': str(video_length),
            'num_inference_steps': str(args.num_inference_steps),
            'guidance_scale': str(guidance_scale),
            'seed': str(seed),
            'elapsed_time': str(elapsed),
        }
        
        # ä¿å­˜ latents
        save_latents_to_safetensors(latents.cpu(), output_paths['latents'], metadata)
        
        # æ›´æ–°å¹¶ä¿å­˜é…ç½®
        config['height'] = height
        config['width'] = width
        config['stage2_elapsed_time'] = elapsed
        save_generation_config(config, output_paths['config'])
        
        print_rank0(f"\n{'='*60}")
        print_rank0("Stage 2 å®Œæˆï¼")
        print_rank0(f"{'='*60}")
        print_rank0(f"è¾“å‡º: {output_paths['latents']}")
        print_rank0(f"ä¸‹ä¸€æ­¥: è¿è¡Œ stage3_vae_decoder.py")
    
    # ========================================================================
    # ğŸ§¹ æ¸…ç†èµ„æº
    # ========================================================================
    
    del transformer
    torch.cuda.empty_cache()
    
    print_rank0("\nâœ“ Stage 2 æ‰§è¡Œå®Œæˆ")


# ============================================================================
# ğŸ“š é™„å½•ï¼šå…³é”®æ¦‚å¿µæ·±å…¥è§£é‡Š
# ============================================================================
#
# ã€A. æ‰©æ•£æ¨¡å‹ (Diffusion Model) åŸºç¡€ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³æ˜¯å­¦ä¹ é€†è½¬"åŠ å™ª"è¿‡ç¨‹ï¼š
#
# å‰å‘è¿‡ç¨‹ï¼ˆè®­ç»ƒæ—¶ï¼‰:
#   x_0 â†’ x_1 â†’ x_2 â†’ ... â†’ x_T
#   æ¸…æ™°     é€æ¸åŠ å™ª        çº¯å™ªå£°
#
# é€†å‘è¿‡ç¨‹ï¼ˆæ¨ç†æ—¶ï¼‰:
#   x_T â†’ x_{T-1} â†’ ... â†’ x_1 â†’ x_0
#   çº¯å™ªå£°   é€æ¸å»å™ª        æ¸…æ™°
#
# æ¨¡å‹å­¦ä¹ çš„æ˜¯ï¼šç»™å®šå½“å‰çŠ¶æ€ x_t å’Œæ—¶é—´ tï¼Œé¢„æµ‹ä¸‹ä¸€æ­¥åº”è¯¥å‡å»å¤šå°‘å™ªå£°ã€‚
#
#
# ã€B. Flow Matching vs DDPMã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# ä¼ ç»Ÿ DDPM:
#   - é¢„æµ‹æ¯ä¸€æ­¥æ·»åŠ çš„å™ªå£° Îµ
#   - x_{t-1} = (x_t - Î²_t Ã— Îµ) / âˆš(1-Î²_t) + å™ªå£°
#   - æ•°å­¦è¾ƒå¤æ‚
#
# Flow Matching:
#   - ç›´æ¥å­¦ä¹ ä» x_T åˆ° x_0 çš„"æµ"ï¼ˆvelocity fieldï¼‰
#   - x_{t-Î”t} = x_t + Î”t Ã— v(x_t, t)
#   - æ›´ç®€æ´ï¼Œå¯ä»¥ç”¨ç®€å•çš„ ODE æ±‚è§£å™¨
#
# HunyuanVideo ä½¿ç”¨ Flow Matchingï¼Œå› æ­¤ scheduler æ˜¯ FlowMatchDiscreteSchedulerã€‚
#
#
# ã€C. ä¸ºä»€ä¹ˆä½¿ç”¨ Transformer è€Œä¸æ˜¯ U-Netï¼Ÿã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# ä¼ ç»Ÿå›¾åƒæ‰©æ•£ï¼ˆå¦‚ Stable Diffusionï¼‰ä½¿ç”¨ U-Netï¼š
#   - ä¼˜ç‚¹ï¼šå¼ºå¤§çš„å¤šå°ºåº¦ç‰¹å¾æå–
#   - ç¼ºç‚¹ï¼šéš¾ä»¥æ‰©å±•ï¼Œé•¿è·ç¦»ä¾èµ–æœ‰é™
#
# DiT (Diffusion Transformer):
#   - ä¼˜ç‚¹ï¼š
#     * å…¨å±€æ³¨æ„åŠ›ï¼Œæ— è§†è·ç¦»
#     * æ›´å¥½çš„å¯æ‰©å±•æ€§
#     * ä¸ LLM æŠ€æœ¯æ ˆä¸€è‡´
#   - ç¼ºç‚¹ï¼š
#     * è®¡ç®—é‡å¤§
#     * éœ€è¦æ›´å¤šæ˜¾å­˜
#
# å¯¹äºè§†é¢‘ç”Ÿæˆï¼ŒTransformer çš„å…¨å±€æ³¨æ„åŠ›ç‰¹åˆ«é‡è¦ï¼š
#   - å¯ä»¥å»ºæ¨¡è·¨å¸§çš„æ—¶é—´ä¾èµ–
#   - ç¡®ä¿è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§
#
#
# ã€D. Sequence Parallelism (SP) vs Tensor Parallelism (TP)ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# é—®é¢˜ï¼šè§†é¢‘å¤ªé•¿/åˆ†è¾¨ç‡å¤ªé«˜ï¼Œå•å¡æ”¾ä¸ä¸‹ã€‚æ€ä¹ˆåŠï¼Ÿ
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é¦–å…ˆæ‰¿è®¤ï¼šTP å’Œ SP åœ¨ç†è®ºä¸Šçš„æ•ˆç‡å·®ä¸å¤šï¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ä½ é—®å¾—å¾ˆå¥½ï¼š
# - Attention: TP åˆ† headï¼ŒSP åˆ† token â†’ éƒ½æ˜¯ 1/8
# - FFN: TP å¯ä»¥æŒ‰ feature ç»´åº¦åˆ†ï¼ŒSP æŒ‰ token åˆ† â†’ ä¹Ÿéƒ½æ˜¯ 1/8
# - LayerNorm: ç¡®å®æœ‰å·®å¼‚ï¼Œä½†å æ¯”å¾ˆå°
#
# æ‰€ä»¥ä»çº¯ç²¹çš„å†…å­˜/è®¡ç®—æ•ˆç‡è§’åº¦ï¼ŒTP å’Œ SP ç¡®å®å·®ä¸å¤šï¼
#
# é‚£ä¸ºä»€ä¹ˆ HunyuanVideo è¿˜æ˜¯é€‰ SPï¼Ÿè¿™é‡Œæœ‰å‡ ä¸ªæ›´å®é™…çš„è€ƒè™‘ï¼š
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŸå›  1: Attention çš„ head æ•°é‡é™åˆ¶äº† TP çš„æ‰©å±•æ€§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   HunyuanVideo: 24 heads
#   - TP: æœ€å¤š 24 GPUï¼ˆæ¯ä¸ª GPU è‡³å°‘ 1 ä¸ª headï¼‰
#   - å®é™…ä¸Šéœ€è¦èƒ½è¢«æ•´é™¤ï¼š8, 12, 24 GPU
#
#   SP: åªå—åºåˆ—é•¿åº¦é™åˆ¶
#   - 46,800 tokens â†’ ç†è®ºä¸Šå¯ä»¥åˆ†åˆ°å¾ˆå¤š GPU
#   - æ›´çµæ´»çš„æ‰©å±•æ€§
#
#   è™½ç„¶ FFN çš„ TP ä¸å— head æ•°é‡é™åˆ¶ï¼Œä½†æ•´ä¸ªæ¨¡å‹çš„ TP åº¦è¦ä¸€è‡´
#   ä¸èƒ½ attention ç”¨ 8 è·¯ï¼ŒFFN ç”¨ 64 è·¯
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŸå›  2: è§†é¢‘çš„æ—¶ç©ºç»“æ„å¤©ç„¶é€‚åˆ SP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   è§†é¢‘ latent: (B, C, T, H, W) = (1, 16, 13, 45, 80)
#
#   SP æŒ‰æ—¶é—´ç»´åº¦åˆ†å‰²éå¸¸è‡ªç„¶ï¼š
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ GPU 0: å¸§ 0-1   (åŒ…å«æ‰€æœ‰ç©ºé—´ä½ç½®)                                  â”‚
#   â”‚ GPU 1: å¸§ 2-3                                                        â”‚
#   â”‚ ...                                                                  â”‚
#   â”‚                                                                      â”‚
#   â”‚ ä¼˜åŠ¿:                                                                â”‚
#   â”‚   - ç›¸é‚»å¸§åœ¨åŒä¸€ GPUï¼Œæ—¶é—´å±€éƒ¨æ€§å¥½                                  â”‚
#   â”‚   - ä¾¿äºè§†é¢‘ç‰¹æœ‰çš„æ—¶é—´å¤„ç†ï¼ˆå¦‚ Meanflowï¼‰                           â”‚
#   â”‚   - é€»è¾‘æ¸…æ™°ï¼šæ¯ä¸ª GPU è´Ÿè´£ä¸€æ®µè¿ç»­çš„è§†é¢‘                           â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
#   TP åˆ†å‰²çš„æ˜¯ feature/head ç»´åº¦ï¼š
#   - æ¯ä¸ª GPU çœ‹åˆ°æ‰€æœ‰å¸§ï¼Œä½†åªæœ‰éƒ¨åˆ†ç‰¹å¾
#   - å¯¹è§†é¢‘çš„æ—¶é—´ç»“æ„æ²¡æœ‰ç‰¹æ®Šä¼˜åŠ¿
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŸå›  3: Ring Attention / SP æ˜¯ä¸“é—¨ä¸ºé•¿åºåˆ—è®¾è®¡çš„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   TP (Tensor Parallelism):
#   - æ¥è‡ª Megatron-LMï¼Œä¸»è¦ä¸º LLM è®­ç»ƒè®¾è®¡
#   - é’ˆå¯¹"æ¨¡å‹å¤§ã€åºåˆ—çŸ­"çš„åœºæ™¯
#   - ä¾§é‡äºåˆ†å‰²æ¨¡å‹å‚æ•°
#
#   SP / Ring Attention:
#   - ä¸“é—¨ä¸º"åºåˆ—é•¿"åœºæ™¯è®¾è®¡
#   - è®ºæ–‡: "Ring Attention with Blockwise Transformers for Near-Infinite Context"
#   - å¯ä»¥å¤„ç†æé•¿åºåˆ—ï¼ˆç†è®ºä¸Šæ— é™é•¿ï¼‰
#   - ä¾§é‡äºåˆ†å‰²æ•°æ®/æ¿€æ´»
#
#   è§†é¢‘ç”Ÿæˆæ°å¥½æ˜¯"æ¨¡å‹ä¸ç®—ç‰¹åˆ«å¤§ã€ä½†åºåˆ—è¶…é•¿"çš„åœºæ™¯
#   â†’ SP/Ring Attention æ›´åˆé€‚
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŸå›  4: é€šä¿¡æ¨¡å¼çš„åŒºåˆ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   TP é€šä¿¡æ¨¡å¼: AllReduce
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ æ¯å±‚éœ€è¦:                                                            â”‚
#   â”‚   - Attention å: AllReduce (åˆå¹¶å„ head çš„ç»“æœ)                    â”‚
#   â”‚   - FFN å: AllReduce (åˆå¹¶å„ feature çš„ç»“æœ)                       â”‚
#   â”‚                                                                      â”‚
#   â”‚ AllReduce ç‰¹ç‚¹:                                                      â”‚
#   â”‚   - éœ€è¦ç­‰å¾…æ‰€æœ‰ GPU å®Œæˆ                                           â”‚
#   â”‚   - åŒæ­¥æ“ä½œï¼Œéš¾ä»¥ä¸è®¡ç®—é‡å                                         â”‚
#   â”‚   - é€šä¿¡é‡: O(n Ã— h)                                                â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
#   SP/Ring Attention é€šä¿¡æ¨¡å¼: AllGather + ReduceScatter (æˆ– Ring ä¼ é€’)
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚                                                                      â”‚
#   â”‚ ã€æ³¨æ„ã€‘è¿™ä¸æ˜¯ MoE é‚£ç§ AllToAllï¼                                   â”‚
#   â”‚                                                                      â”‚
#   â”‚ MoE çš„ AllToAll:                                                    â”‚
#   â”‚   æ¯ä¸ª GPU å‘é€ä¸åŒæ•°æ®åˆ°ä¸åŒ GPUï¼Œåƒ"æ´—ç‰Œ/ç½®æ¢"                    â”‚
#   â”‚   GPU0 â†’ GPU1: data_01                                              â”‚
#   â”‚   GPU0 â†’ GPU2: data_02                                              â”‚
#   â”‚   GPU1 â†’ GPU0: data_10                                              â”‚
#   â”‚   ...                                                                â”‚
#   â”‚                                                                      â”‚
#   â”‚ SP çš„é€šä¿¡æ›´åƒ AllGather + Scatter:                                  â”‚
#   â”‚   æ”¶é›†é˜¶æ®µ: æ¯ä¸ª GPU æ”¶é›†æ‰€æœ‰ GPU çš„ KV                             â”‚
#   â”‚   åˆ†å‘é˜¶æ®µ: æŠŠç»“æœ scatter å›å„è‡ªçš„ token ä½ç½®                      â”‚
#   â”‚                                                                      â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
#   Ring Attention çš„å…·ä½“å®ç°:
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚                                                                      â”‚
#   â”‚ æŠŠ GPU æ’æˆç¯: GPU0 â†’ GPU1 â†’ GPU2 â†’ ... â†’ GPU7 â†’ GPU0               â”‚
#   â”‚                                                                      â”‚
#   â”‚ æ¯ä¸ª GPU æŒæœ‰:                                                      â”‚
#   â”‚   - æœ¬åœ° Q: Q_i (åªæœ‰è‡ªå·±çš„)                                        â”‚
#   â”‚   - æœ¬åœ° KV: KV_i (åˆå§‹åªæœ‰è‡ªå·±çš„)                                  â”‚
#   â”‚                                                                      â”‚
#   â”‚ Step 0:                                                              â”‚
#   â”‚   GPU_i è®¡ç®—: Q_i @ KV_i  (æœ¬åœ° attention)                          â”‚
#   â”‚   åŒæ—¶: æŠŠ KV_i å‘é€ç»™ GPU_{i+1}                                    â”‚
#   â”‚                                                                      â”‚
#   â”‚ Step 1:                                                              â”‚
#   â”‚   GPU_i æ”¶åˆ° KV_{i-1}                                               â”‚
#   â”‚   GPU_i è®¡ç®—: Q_i @ KV_{i-1}  (ä¸å‰ä¸€ä¸ª GPU çš„ KV)                  â”‚
#   â”‚   åŒæ—¶: æŠŠ KV_{i-1} ç»§ç»­ä¼ ç»™ GPU_{i+1}                              â”‚
#   â”‚                                                                      â”‚
#   â”‚ ... é‡å¤ P-1 è½® ...                                                  â”‚
#   â”‚                                                                      â”‚
#   â”‚ æœ€ç»ˆ: æ¯ä¸ª GPU å·²ç»çœ‹è¿‡äº†æ‰€æœ‰ KVï¼Œç´¯åŠ å¾—åˆ°å®Œæ•´ attention ç»“æœ       â”‚
#   â”‚                                                                      â”‚
#   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
#   â”‚ â”‚           Ring Attention æµæ°´çº¿ç¤ºæ„å›¾                          â”‚ â”‚
#   â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
#   â”‚ â”‚                                                                 â”‚ â”‚
#   â”‚ â”‚   GPU0    GPU1    GPU2    GPU3    ...                          â”‚ â”‚
#   â”‚ â”‚    â”‚       â”‚       â”‚       â”‚                                    â”‚ â”‚
#   â”‚ â”‚ t0:è®¡ç®—    è®¡ç®—    è®¡ç®—    è®¡ç®—     (Q_i @ KV_i)                â”‚ â”‚
#   â”‚ â”‚    â”‚â”€â”€KV_0â”€â†’â”‚â”€â”€KV_1â”€â†’â”‚â”€â”€KV_2â”€â†’â”‚      (ä¼ é€’ KV)                 â”‚ â”‚
#   â”‚ â”‚ t1:è®¡ç®—    è®¡ç®—    è®¡ç®—    è®¡ç®—     (Q_i @ KV_{i-1})           â”‚ â”‚
#   â”‚ â”‚    â”‚â”€â”€KV_7â”€â†’â”‚â”€â”€KV_0â”€â†’â”‚â”€â”€KV_1â”€â†’â”‚      (ç»§ç»­ä¼ é€’)                â”‚ â”‚
#   â”‚ â”‚ t2:...                                                          â”‚ â”‚
#   â”‚ â”‚                                                                 â”‚ â”‚
#   â”‚ â”‚ å…³é”®: è®¡ç®—å’Œé€šä¿¡å®Œç¾é‡å ï¼                                     â”‚ â”‚
#   â”‚ â”‚       å½“ GPU_i è®¡ç®— Q_i @ KV_j æ—¶ï¼Œ                            â”‚ â”‚
#   â”‚ â”‚       åŒæ—¶åœ¨æ¥æ”¶ KV_{j-1} å’Œå‘é€ KV_j                          â”‚ â”‚
#   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
#   â”‚                                                                      â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
#   Ring Attention çš„ä¼˜åŠ¿:
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚                                                                      â”‚
#   â”‚ 1. é€šä¿¡å®Œå…¨éšè—åœ¨è®¡ç®—ä¸­                                             â”‚
#   â”‚    - åªè¦è®¡ç®—æ—¶é—´ â‰¥ é€šä¿¡æ—¶é—´ï¼Œé€šä¿¡å¼€é”€ = 0                          â”‚
#   â”‚    - å¯¹äºå¤§çŸ©é˜µä¹˜æ³•ï¼ˆattentionï¼‰ï¼Œè¿™ä¸ªæ¡ä»¶é€šå¸¸æ»¡è¶³                  â”‚
#   â”‚                                                                      â”‚
#   â”‚ 2. åªéœ€è¦ P2P é€šä¿¡                                                  â”‚
#   â”‚    - æ¯ä¸ª GPU åªå’Œç›¸é‚»ä¸¤ä¸ª GPU é€šä¿¡                                 â”‚
#   â”‚    - ä¸éœ€è¦å…¨å±€åŒæ­¥                                                 â”‚
#   â”‚    - å¯¹ç½‘ç»œå¸¦å®½è¦æ±‚ä½                                               â”‚
#   â”‚                                                                      â”‚
#   â”‚ 3. å†…å­˜å ç”¨æ’å®š                                                     â”‚
#   â”‚    - ä»»ä½•æ—¶åˆ»åªæŒæœ‰ 2 ä»½ KVï¼ˆæœ¬åœ° + æ­£åœ¨æ¥æ”¶çš„ï¼‰                    â”‚
#   â”‚    - ä¸éœ€è¦ä¸€æ¬¡æ€§ AllGather æ‰€æœ‰ KV                                 â”‚
#   â”‚                                                                      â”‚
#   â”‚ 4. æ”¯æŒä»»æ„é•¿åº¦åºåˆ—                                                 â”‚
#   â”‚    - åªè¦èƒ½åˆ†åˆ°æ›´å¤š GPUï¼Œå°±èƒ½å¤„ç†æ›´é•¿åºåˆ—                           â”‚
#   â”‚    - ç†è®ºä¸Šæ— é™é•¿ï¼ˆè®ºæ–‡æ ‡é¢˜: "Near-Infinite Context"ï¼‰              â”‚
#   â”‚                                                                      â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
#   å¯¹äºé•¿åºåˆ—è§†é¢‘ï¼ŒRing Attention å¼çš„ SP æ•ˆç‡å¾ˆé«˜
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŸå›  5: å˜é•¿åºåˆ—æ”¯æŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   è§†é¢‘ç”Ÿæˆå¯èƒ½æœ‰ä¸åŒé•¿åº¦ï¼š
#   - 49 å¸§ â†’ 13 latent å¸§
#   - 97 å¸§ â†’ 25 latent å¸§
#   - 145 å¸§ â†’ 37 latent å¸§
#
#   SP å¤©ç„¶æ”¯æŒå˜é•¿ï¼š
#   - ç›´æ¥æŒ‰ token æ•°åˆ†é…
#   - ä¸åŒ GPU å¯ä»¥æœ‰ç•¥å¾®ä¸åŒçš„è´Ÿè½½
#
#   TP å¯¹å˜é•¿æ”¯æŒè¾ƒå·®ï¼š
#   - head æ•°é‡å›ºå®š
#   - FFN ç»´åº¦å›ºå®š
#   - å˜é•¿æ—¶éœ€è¦ padding
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŸå›  6: å®ç°å¤æ‚åº¦å’Œç”Ÿæ€
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   TP å®ç°:
#   - éœ€è¦ä¿®æ”¹æ¯ä¸€å±‚çš„å®ç°
#   - Linear, LayerNorm, Attention éƒ½è¦ç‰¹æ®Šå¤„ç†
#   - Megatron-LM é£æ ¼çš„ä»£ç ä¾µå…¥æ€§å¼º
#
#   SP å®ç°:
#   - ä¸»è¦ä¿®æ”¹ Attention å±‚
#   - å…¶ä»–å±‚ä¿æŒä¸å˜ï¼ˆåªæ˜¯å¤„ç†æ›´å°‘çš„ tokenï¼‰
#   - æ›´å®¹æ˜“é›†æˆåˆ°ç°æœ‰ä»£ç 
#
#   HunyuanVideo å¯èƒ½ç»§æ‰¿è‡ªä½¿ç”¨ SP çš„ä»£ç åº“ï¼Œæ”¹åŠ¨æˆæœ¬æ›´ä½
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ€»ç»“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#   ä»çº¯ç²¹æ•ˆç‡è§’åº¦ï¼ŒTP å’Œ SP ç¡®å®å·®ä¸å¤šï¼ˆä½ çš„ç›´è§‰æ˜¯å¯¹çš„ï¼ï¼‰
#
#   HunyuanVideo é€‰æ‹© SP çš„åŸå› æ›´å¤šæ˜¯ï¼š
#   1. Head æ•°é‡ (24) é™åˆ¶äº† TP çš„æ‰©å±•æ€§
#   2. è§†é¢‘çš„æ—¶ç©ºç»“æ„é€‚åˆæŒ‰æ—¶é—´åˆ†å‰²
#   3. SP/Ring Attention ä¸“é—¨ä¸ºé•¿åºåˆ—è®¾è®¡
#   4. é€šä¿¡æ¨¡å¼æ›´å®¹æ˜“ä¸è®¡ç®—é‡å 
#   5. å˜é•¿åºåˆ—æ”¯æŒæ›´å¥½
#   6. å®ç°æ›´ç®€å•ï¼Œä¸ç°æœ‰ä»£ç å…¼å®¹
#
#   æœ¬è´¨ä¸Šï¼š
#   - TP: ä¸º"æ¨¡å‹å¤§"è®¾è®¡ï¼Œåˆ†å‰²å‚æ•°
#   - SP: ä¸º"åºåˆ—é•¿"è®¾è®¡ï¼Œåˆ†å‰²æ•°æ®
#
#   è§†é¢‘ç”Ÿæˆæ˜¯"åºåˆ—é•¿"é—®é¢˜ â†’ SP æ˜¯æ›´è‡ªç„¶çš„é€‰æ‹©
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#
# ã€E. ä¸ºä»€ä¹ˆ Latent æ˜¯ 5D å¼ é‡ï¼Ÿã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# è§†é¢‘ latent shape: (B, C, T, H, W)
#
# - B (Batch): æ‰¹æ¬¡å¤§å°ï¼Œé€šå¸¸ä¸º 1
# - C (Channels): æ½œåœ¨é€šé“æ•°ï¼Œ16
# - T (Time/Frames): æ—¶é—´ç»´åº¦ï¼ˆå¸§æ•°ï¼‰
# - H (Height): ç©ºé—´é«˜åº¦
# - W (Width): ç©ºé—´å®½åº¦
#
# ç›¸æ¯”å›¾åƒ (B, C, H, W)ï¼Œå¤šäº†æ—¶é—´ç»´åº¦ Tã€‚
#
# Transformer å†…éƒ¨ä¼šå°† (T, H, W) å±•å¹³ä¸º token åºåˆ—ï¼š
#   tokens = T Ã— H Ã— W
#   ä¾‹å¦‚: 13 Ã— 45 Ã— 80 = 46,800 tokens
#
#
# ã€F. ByT5 çš„ä½œç”¨ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# HunyuanVideo-1.5 ä½¿ç”¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼š
#
# 1. LLaVA (ä¸»):
#    - å¤§å‹è¯­è¨€æ¨¡å‹
#    - ç†è§£è¯­ä¹‰å«ä¹‰
#    - "ä¸€åªçŒ«åœ¨èŠ±å›­é‡Œ" â†’ ç†è§£åœºæ™¯
#
# 2. ByT5 (è¾…åŠ©):
#    - å­—èŠ‚çº§æ–‡æœ¬ç¼–ç å™¨
#    - æ•æ‰å­—ç¬¦çº§ç»†èŠ‚
#    - å¯¹æ‹¼å†™ã€æ ¼å¼æ•æ„Ÿ
#    - å¸®åŠ©ç”Ÿæˆå‡†ç¡®çš„æ–‡å­—/ç¬¦å·
#
# ä¸¤è€…ç»“åˆå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚çš„æç¤ºè¯ã€‚
#
# ============================================================================
# ============================================================================

if __name__ == "__main__":
    main()