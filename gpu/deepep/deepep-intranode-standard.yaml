apiVersion: v1
kind: Pod
metadata:
  name: privileged-sleeping-pod
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: cloud.google.com/gke-accelerator
              operator: Exists
            - key: cloud.google.com/gke-nodepool
              operator: In
              values:
                - a4-highgpu-ubuntu-02
            - key: cloud.google.com/gke-os-distribution
              operator: In
              values:
                - ubuntu
  tolerations:
  - operator: "Exists"
  hostNetwork: true
  hostPID: true
  containers:
  - name: test
    image: nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04
    resources:
      limits:
        nvidia.com/gpu: "8"
    volumeMounts:
      - name: nvidia
        mountPath: /usr/local/nvidia
      - name: shared-memory
        mountPath: /dev/shm
    command:
      - '/bin/bash'
      - '-c'
      - |
        export DEBIAN_FRONTEND=noninteractive
        export PYTHONPATH=/usr/local/nvidia/deepep:$PYTHONPATH
        export LD_LIBRARY_PATH=/usr/local/nvidia/lib64:$LD_LIBRARY_PATH

        apt-get update -y && apt install git python3-pip -y -qq 
        apt install python3.12-dev python3.12 ninja-build cmake build-essential devscripts debhelper dkms -y -qq
        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128  --break-system-packages

        git clone https://github.com/deepseek-ai/DeepEP.git && cd ./DeepEP
        python3 tests/test_low_latency.py
        # uncomment to run intranode test
        # python3 tests/test_intranode.py
        sleep infinity
    securityContext:
      privileged: true
  volumes:
    - name: nvidia
      hostPath:
        path: /home/kubernetes/bin/nvidia
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: 250Gi