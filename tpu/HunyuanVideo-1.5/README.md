# HunyuanVideo-1.5 TPU/GPU è¿è¡ŒæŒ‡å—

åœ¨ TPU v6e-8 æˆ– GPU H100 ä¸Šè¿è¡Œ HunyuanVideo-1.5 æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆã€‚

---

## ğŸ›  ç¯å¢ƒé…ç½®ï¼ˆå¿…è¯»ï¼‰

### å‰ç½®æ¡ä»¶

1. **Hugging Face Token**ï¼šä» [Hugging Face Settings](https://huggingface.co/settings/tokens) è·å– Access Token

2. **è®¾ç½®ç¯å¢ƒå˜é‡**ï¼š
   ```bash
   # è®¾ç½® Hugging Face Tokenï¼ˆå¿…éœ€ï¼‰
   export HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   
   # è®¾ç½® Hugging Face ç¼“å­˜ç›®å½•ï¼ˆæ¨èä½¿ç”¨ /dev/shm åŠ é€Ÿï¼‰
   export HF_HOME=/dev/shm
   ```

3. **å°†ç¯å¢ƒå˜é‡æ·»åŠ åˆ° ~/.bashrcï¼ˆæŒä¹…åŒ–ï¼‰**ï¼š
   ```bash
   echo 'export HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"' >> ~/.bashrc
   echo 'export HF_HOME=/dev/shm' >> ~/.bashrc
   source ~/.bashrc
   ```

---

### TPU ç¯å¢ƒå®‰è£…

åœ¨ Google Cloud TPU v6e-8 ä¸Šè¿è¡Œï¼š

```bash
# 1. å®‰è£…åŸºç¡€ä¾èµ–
pip install --upgrade pip
pip install numpy scipy pillow imageio loguru einops safetensors

# 2. å®‰è£… JAXï¼ˆTPU ç‰ˆæœ¬ï¼‰
pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html

# 3. å®‰è£… PyTorch + torchax
pip install torch torchvision
pip install torchax

# 4. å®‰è£… transformers å’Œ diffusers
pip install transformers accelerate
pip install diffusers

# 5. å®‰è£… ffmpegï¼ˆè§†é¢‘ç¼–ç ï¼‰
sudo apt update && sudo apt install -y ffmpeg

# 6. å…‹éš† HunyuanVideo-1.5-TPU ä»£ç åº“ï¼ˆåŒ…å«æ¨¡å‹å®šä¹‰ï¼‰
git clone https://github.com/yangwhale/HunyuanVideo-1.5-TPU.git ~/HunyuanVideo-1.5-TPU

# 7. å…‹éš†æœ¬é¡¹ç›®
git clone https://github.com/yangwhale/gpu-tpu-pedia.git ~/gpu-tpu-pedia
```

---

### ä¸‹è½½æ¨¡å‹æƒé‡

HunyuanVideo-1.5 æƒé‡çº¦ 25GBï¼Œæ¨èä¸‹è½½åˆ° `/dev/shm`ï¼ˆå†…å­˜æ–‡ä»¶ç³»ç»Ÿï¼Œè¯»å–æ›´å¿«ï¼‰ã€‚

**æ–¹æ³• 1ï¼šä½¿ç”¨ huggingface-cliï¼ˆæ¨èï¼‰**

```bash
# å®‰è£… huggingface_hub
pip install huggingface_hub

# ç™»å½• Hugging Faceï¼ˆä½¿ç”¨ä¹‹å‰è®¾ç½®çš„ HF_TOKENï¼‰
huggingface-cli login --token $HF_TOKEN

# åˆ›å»ºç›®æ ‡ç›®å½•
mkdir -p /dev/shm/HunyuanVideo1.5

# ä¸‹è½½å®Œæ•´æ¨¡å‹ï¼ˆçº¦ 25GBï¼‰
huggingface-cli download tencent/HunyuanVideo-1.5 \
    --local-dir /dev/shm/HunyuanVideo1.5 \
    --local-dir-use-symlinks False
```

**æ–¹æ³• 2ï¼šä½¿ç”¨ Python è„šæœ¬**

```python
from huggingface_hub import snapshot_download
import os

# ç¡®ä¿è®¾ç½®äº† HF_TOKEN
os.environ["HF_TOKEN"] = "hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# ä¸‹è½½æ¨¡å‹
snapshot_download(
    repo_id="tencent/HunyuanVideo-1.5",
    local_dir="/dev/shm/HunyuanVideo1.5",
    local_dir_use_symlinks=False,
    token=os.environ["HF_TOKEN"]
)
```

**ä¸‹è½½å®Œæˆåçš„ç›®å½•ç»“æ„**ï¼š

```
/dev/shm/HunyuanVideo1.5/
â”œâ”€â”€ ckpt/                              # æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ hunyuan-video-t2v-720p/
â”‚   â”‚   â””â”€â”€ transformers/
â”‚   â”‚       â”œâ”€â”€ mp_rank_00_model_states.pt
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ llava-llama-3-8b-v1_1-transformers/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ text_encoder/                      # LLM Text Encoder
â”œâ”€â”€ text_encoder_2/                    # T5 Text Encoder
â”œâ”€â”€ vae/                               # VAE Decoder
â””â”€â”€ transformer/                       # Transformer æƒé‡
```

**éªŒè¯ä¸‹è½½**ï¼š

```bash
# æ£€æŸ¥æƒé‡æ–‡ä»¶
ls -la /dev/shm/HunyuanVideo1.5/ckpt/hunyuan-video-t2v-720p/transformers/

# åº”è¯¥çœ‹åˆ° mp_rank_00_model_states.pt ç­‰æ–‡ä»¶
```

---

### GPU ç¯å¢ƒå®‰è£…

åœ¨ NVIDIA H100 8å¡ä¸Šè¿è¡Œï¼š

```bash
# 1. å®‰è£…åŸºç¡€ä¾èµ–
pip install --upgrade pip
pip install numpy scipy pillow imageio loguru einops safetensors

# 2. å®‰è£… PyTorch + CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 3. å®‰è£… Flash Attention 2ï¼ˆH100 æ¨èï¼‰
pip install flash-attn --no-build-isolation

# 4. å®‰è£… transformers å’Œ diffusers
pip install transformers accelerate
pip install diffusers

# 5. å®‰è£… ffmpeg
sudo apt update && sudo apt install -y ffmpeg

# 6. å…‹éš† HunyuanVideo-1.5-TPU ä»£ç åº“
git clone https://github.com/yangwhale/HunyuanVideo-1.5-TPU.git ~/HunyuanVideo-1.5-TPU

# 7. å…‹éš†æœ¬é¡¹ç›®
git clone https://github.com/yangwhale/gpu-tpu-pedia.git ~/gpu-tpu-pedia

# 8. ä¸‹è½½æ¨¡å‹æƒé‡ï¼ˆåŒ TPU ç¯å¢ƒï¼‰
mkdir -p /dev/shm/HunyuanVideo1.5
huggingface-cli download tencent/HunyuanVideo-1.5 \
    --local-dir /dev/shm/HunyuanVideo1.5 \
    --local-dir-use-symlinks False
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆ Aï¼šTPU è¿è¡Œï¼ˆæ¨èï¼‰

```bash
cd ~/gpu-tpu-pedia/tpu/HunyuanVideo-1.5/generate_hunyuan_flax_staged

# è¿è¡Œ 121å¸§ 720p è§†é¢‘ç”Ÿæˆï¼ˆçº¦ 6 åˆ†é’Ÿï¼‰
python stage2_transformer.py \
    --video_length 121 \
    --num_inference_steps 50 \
    --warmup_steps 2
```

### æ–¹æ¡ˆ Bï¼šGPU è¿è¡Œ

```bash
cd ~/gpu-tpu-pedia/tpu/HunyuanVideo-1.5/generate_hunyuan_gpu_staged

# ä¸‰é˜¶æ®µè¿è¡Œ
bash run_stage1.sh  # Text Encoderï¼ˆå•å¡ï¼‰
bash run_stage2.sh  # Transformerï¼ˆ8å¡ï¼‰
bash run_stage3.sh  # VAE Decoderï¼ˆ8å¡ï¼‰
```

---

## ğŸ“¦ ç›®å½•ç»“æ„

```
HunyuanVideo-1.5/
â”œâ”€â”€ ğŸ“ generate_hunyuan_flax_staged/   # â­ TPU æ¨èç‰ˆæœ¬
â”œâ”€â”€ ğŸ“ generate_hunyuan_gpu_staged/    # GPU H100 ç‰ˆæœ¬
â”œâ”€â”€ ğŸ“ generate_diffusers_flax_staged/ # TPU + Diffusers ç‰ˆæœ¬
â”œâ”€â”€ ğŸ“ docs/                           # æŠ€æœ¯æ–‡æ¡£
â”œâ”€â”€ generate_diffusers_flax.py         # TPU å•æ–‡ä»¶ç‰ˆæœ¬
â”œâ”€â”€ generate_diffusers_gpu.py          # GPU å•æ–‡ä»¶ç‰ˆæœ¬
â””â”€â”€ run_diffusers_gpu.sh               # GPU è¿è¡Œè„šæœ¬
```

### å„ç›®å½•è¯´æ˜

| ç›®å½• | å¹³å° | è¯´æ˜ | æ¨èåº¦ |
|------|------|------|--------|
| `generate_hunyuan_flax_staged/` | TPU | ä½¿ç”¨åŸç”Ÿ HunyuanVideo-1.5-TPUï¼ŒSplash Attention | â­â­â­ |
| `generate_hunyuan_gpu_staged/` | GPU | ä½¿ç”¨åŸç”Ÿ HunyuanVideo-1.5-TPUï¼ŒFlash Attention | â­â­â­ |
| `generate_diffusers_flax_staged/` | TPU | ä½¿ç”¨ diffusers-tpu åº“ | â­â­ |
| `docs/` | - | æŠ€æœ¯åˆ†ææ–‡æ¡£ | - |

---

## ğŸ“‚ ç›®å½•è¯¦è§£

### 1. `generate_hunyuan_flax_staged/` â€” TPU æ¨èç‰ˆæœ¬

**ä½¿ç”¨åœºæ™¯**ï¼šåœ¨ TPU v6e-8 ä¸Šè¿è¡Œ HunyuanVideo-1.5

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨åŸç”Ÿ HunyuanVideo-1.5-TPU ä»£ç åº“
- Splash Attentionï¼ˆTPU ä¼˜åŒ–ï¼‰
- TP + fc2/proj Replicated åˆ†ç‰‡ç­–ç•¥ï¼ˆ+10.2% æ€§èƒ½ï¼‰
- æ”¯æŒ DeepCache åŠ é€Ÿ

**æ–‡ä»¶è¯´æ˜**ï¼š
```
generate_hunyuan_flax_staged/
â”œâ”€â”€ stage2_transformer.py              # ä¸»æ¨ç†è„šæœ¬
â”œâ”€â”€ utils.py                           # å·¥å…·å‡½æ•°
â”œâ”€â”€ TORCHAX_MIGRATION_GUIDE.md         # â­ GPUâ†’TPU è¿ç§»å®Œæ•´æŒ‡å—
â”œâ”€â”€ GPU_TPU_COMPARISON.md              # GPU/TPU ä»£ç å¯¹æ¯”
â””â”€â”€ DEEPCACHE_EXPLAINED.md             # DeepCache åŸç†è¯´æ˜
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# å‰æï¼šéœ€è¦å…ˆåœ¨å…¶ä»–åœ°æ–¹è¿è¡Œ Stage 1 ç”Ÿæˆ embeddings
# æˆ–è€…ä½¿ç”¨ generate_diffusers_flax_staged/ çš„ stage1

# è¿è¡Œ Transformer æ¨ç†
python stage2_transformer.py \
    --input_dir ./stage_outputs \
    --video_length 121 \
    --num_inference_steps 50 \
    --seed 42

# å¯ç”¨ DeepCache åŠ é€Ÿï¼ˆ+70% é€Ÿåº¦ï¼Œè´¨é‡ç¨é™ï¼‰
python stage2_transformer.py \
    --enable_cache \
    --cache_start_step 11 \
    --cache_end_step 45 \
    --cache_step_interval 4
```

**æ€§èƒ½æ•°æ®ï¼ˆTPU v6e-8ï¼‰**ï¼š
| é…ç½® | æ¯æ­¥æ—¶é—´ | 50æ­¥æ€»æ—¶é—´ |
|------|----------|------------|
| 121å¸§ 720p | 7.29s | 6.1 åˆ†é’Ÿ |
| 121å¸§ 720p + DeepCache | ~4s | 3.5 åˆ†é’Ÿ |

---

### 2. `generate_hunyuan_gpu_staged/` â€” GPU H100 ç‰ˆæœ¬

**ä½¿ç”¨åœºæ™¯**ï¼šåœ¨ NVIDIA H100 8å¡ä¸Šè¿è¡Œ

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- ä½¿ç”¨åŸç”Ÿ HunyuanVideo-1.5-TPU ä»£ç åº“
- æ”¯æŒ Flash Attention 2/3ã€SageAttention
- Sequence Parallelism å¤šå¡å¹¶è¡Œ
- æ”¯æŒ DeepCache åŠ é€Ÿ

**æ–‡ä»¶è¯´æ˜**ï¼š
```
generate_hunyuan_gpu_staged/
â”œâ”€â”€ README.md                          # â­ å®Œæ•´ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ stage1_text_encoder.py             # Stage 1: æ–‡æœ¬ç¼–ç 
â”œâ”€â”€ stage2_transformer.py              # Stage 2: Transformer
â”œâ”€â”€ stage2_transformer_explained.py    # å¸¦è¯¦ç»†æ³¨é‡Šçš„ç‰ˆæœ¬
â”œâ”€â”€ stage3_vae_decoder.py              # Stage 3: VAE è§£ç 
â”œâ”€â”€ run_stage1.sh                      # è¿è¡Œè„šæœ¬
â”œâ”€â”€ run_stage2.sh
â”œâ”€â”€ run_stage3.sh
â””â”€â”€ utils.py
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
# å®Œæ•´ä¸‰é˜¶æ®µ Pipeline
bash run_stage1.sh  # å•å¡è¿è¡Œ Text Encoder
bash run_stage2.sh  # 8å¡è¿è¡Œ Transformer
bash run_stage3.sh  # 8å¡è¿è¡Œ VAE Decoder

# æˆ–ç›´æ¥è¿è¡Œ
python stage1_text_encoder.py --model_path /dev/shm/HunyuanVideo1.5 --prompt "Your prompt"
torchrun --nproc_per_node=8 stage2_transformer.py --input_dir ./stage_outputs
torchrun --nproc_per_node=8 stage3_vae_decoder.py --input_dir ./stage_outputs
```

**æ€§èƒ½æ•°æ®ï¼ˆH100 8å¡ï¼‰**ï¼š
| æ–¹æ¡ˆ | åŠ é€Ÿæ¯” | æ¯æ­¥æ—¶é—´ |
|------|--------|----------|
| Flash Attention 2 | 1.0x | 5.2s |
| DeepCache | 1.83x | 2.84s |
| SageAttention | 1.6x | 3.25s |

è¯¦è§ [`generate_hunyuan_gpu_staged/README.md`](generate_hunyuan_gpu_staged/README.md)

---

### 3. `generate_diffusers_flax_staged/` â€” TPU + Diffusers ç‰ˆæœ¬

**ä½¿ç”¨åœºæ™¯**ï¼šä½¿ç”¨ diffusers-tpu åº“åœ¨ TPU ä¸Šè¿è¡Œ

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š
- åŸºäº Hugging Face diffusers åº“
- éœ€è¦ä¿®æ”¹ç‰ˆ diffusers-tpu åº“
- Splash Attention + SDPA

**æ–‡ä»¶è¯´æ˜**ï¼š
```
generate_diffusers_flax_staged/
â”œâ”€â”€ README.md                          # ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ stage1_text_encoder.py             # Stage 1: Text Encoder
â”œâ”€â”€ stage2_transformer.py              # Stage 2: Transformer
â”œâ”€â”€ stage3_vae_decoder.py              # Stage 3: VAE Decoder
â””â”€â”€ utils.py
```

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd generate_diffusers_flax_staged

python stage1_text_encoder.py  # CPU è¿è¡Œ
python stage2_transformer.py   # TPU è¿è¡Œ
python stage3_vae_decoder.py   # TPU è¿è¡Œ
```

è¯¦è§ [`generate_diffusers_flax_staged/README.md`](generate_diffusers_flax_staged/README.md)

---

### 4. `docs/` â€” æŠ€æœ¯æ–‡æ¡£

æ·±å…¥åˆ†æ HunyuanVideo-1.5 çš„å®ç°ç»†èŠ‚ã€‚

| æ–‡æ¡£ | å†…å®¹ |
|------|------|
| `deepcache_explained.md` | DeepCache åŠ é€ŸåŸç†ä¸å®ç° |
| `dit_implementation_analysis.md` | DiT Transformer æ¶æ„åˆ†æ |
| `scheduler_explained.md` | Flow Matching Scheduler è¯¦è§£ |
| `splash_attention_kernel_analysis.md` | Splash Attention Kernel åˆ†æ |

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### TPU vs GPU

| å¹³å° | é…ç½® | 121å¸§ 720p 50æ­¥ | æ¯æ­¥æ—¶é—´ |
|------|------|-----------------|----------|
| TPU v6e-8 | TP + fc2 Replicated | 6.1 åˆ†é’Ÿ | 7.29s |
| GPU H100 8å¡ | Flash Attention 2 | 4.3 åˆ†é’Ÿ | 5.2s |
| GPU H100 8å¡ | DeepCache | 2.4 åˆ†é’Ÿ | 2.84s |

### åŠ é€Ÿæ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | åŠ é€Ÿæ¯” | è´¨é‡ | æ¨èåœºæ™¯ |
|------|--------|------|----------|
| æ ‡å‡†ï¼ˆæ— åŠ é€Ÿï¼‰ | 1.0x | âœ… æœ€ä¼˜ | ç”Ÿäº§ç¯å¢ƒ |
| DeepCache | 1.8x | âœ… è‰¯å¥½ | æ—¥å¸¸ä½¿ç”¨ |
| SageAttention | 1.6x | âš ï¸ æœ‰æŸ | å¿«é€Ÿé¢„è§ˆ |

---

## â“ å¸¸è§é—®é¢˜

### 1. æƒé‡ä¸‹è½½å¤±è´¥

```bash
# æ£€æŸ¥ HF_TOKEN æ˜¯å¦è®¾ç½®
echo $HF_TOKEN

# æ‰‹åŠ¨ç™»å½•
huggingface-cli login

# ä½¿ç”¨ä»£ç†ï¼ˆå¦‚éœ€ï¼‰
export HTTP_PROXY=http://your-proxy:port
export HTTPS_PROXY=http://your-proxy:port
```

### 2. OOMï¼ˆå†…å­˜ä¸è¶³ï¼‰

**TPU**ï¼š
- ä½¿ç”¨ `--video_length 49` å‡å°‘å¸§æ•°
- å¯ç”¨ DeepCache å‡å°‘å³°å€¼å†…å­˜

**GPU**ï¼š
- Stage 2ï¼šä¸è¦ä½¿ç”¨ `create_pipeline()`ï¼Œç›´æ¥åŠ è½½ Transformer
- Stage 3ï¼šå¿…é¡»ä½¿ç”¨ `torch.no_grad()`

### 3. é¦–æ¬¡è¿è¡Œå¾ˆæ…¢

è¿™æ˜¯ XLA/JAX ç¼–è¯‘é€ æˆçš„ï¼Œæ­£å¸¸ç°è±¡ã€‚åç»­è¿è¡Œä¼šä½¿ç”¨ç¼“å­˜ã€‚

```bash
# æ¸…é™¤ç¼–è¯‘ç¼“å­˜ï¼ˆå¦‚éœ€é‡æ–°ç¼–è¯‘ï¼‰
rm -rf /dev/shm/jax_cache
```

### 4. è§†é¢‘è´¨é‡é—®é¢˜

- ç¡®ä¿ä½¿ç”¨ bf16 ç²¾åº¦
- æ£€æŸ¥ Attention Mask æ˜¯å¦æ­£ç¡®å¤„ç†ï¼ˆK/V ç½®é›¶æ–¹æ¡ˆï¼‰
- å‚è€ƒ `TORCHAX_MIGRATION_GUIDE.md` çš„ä¿®å¤è¯´æ˜

### 5. æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶

```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la /dev/shm/HunyuanVideo1.5/

# æ£€æŸ¥ transformer æƒé‡
ls -la /dev/shm/HunyuanVideo1.5/ckpt/hunyuan-video-t2v-720p/transformers/
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [HunyuanVideo-1.5-TPU](https://github.com/yangwhale/HunyuanVideo-1.5-TPU) - åŸç”Ÿä»£ç åº“
- [torchax](https://github.com/pytorch/xla) - PyTorch â†’ JAX æ¡¥æ¥
- [JAX Splash Attention](https://github.com/jax-ml/jax) - TPU ä¼˜åŒ–æ³¨æ„åŠ›
- [diffusers-tpu](https://github.com/yangwhale/diffusers-tpu) - ä¿®æ”¹ç‰ˆ diffusers

---

## ğŸ“ License

ä¸ HunyuanVideo é¡¹ç›®ä¿æŒä¸€è‡´ã€‚