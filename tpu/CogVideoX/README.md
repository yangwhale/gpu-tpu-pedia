# CogVideoX TPU åŠ é€Ÿé¡¹ç›®

æœ¬é¡¹ç›®å®ç°äº† CogVideoX è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨ Google Cloud TPU ä¸Šçš„é«˜æ€§èƒ½æ¨ç†ï¼Œé€šè¿‡ JAX + torchax å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡å’Œå†…å­˜ä¼˜åŒ–ã€‚

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

CogVideoX æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œæœ¬é¡¹ç›®å°†å…¶è¿ç§»åˆ° TPU å¹³å°ï¼Œåˆ©ç”¨ä»¥ä¸‹æŠ€æœ¯å®ç°é«˜æ•ˆæ¨ç†ï¼š

- **JAX/torchax æ¡†æ¶**ï¼šæ›¿æ¢ PyTorchï¼Œå……åˆ†åˆ©ç”¨ TPU çš„ XLA ç¼–è¯‘ä¼˜åŒ–
- **Splash Attention**ï¼šTPU åŸç”Ÿçš„é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¯æŒé•¿åºåˆ—å¤„ç†
- **Flax VAE**ï¼šåŸç”Ÿ JAX å®ç°çš„ VAE è§£ç å™¨ï¼Œè§£å†³ OOM é—®é¢˜å¹¶æ”¯æŒé•¿è§†é¢‘ç”Ÿæˆ
- **æ¨¡å‹åˆ†ç‰‡**ï¼šæ™ºèƒ½çš„æƒé‡åˆ†ç‰‡ç­–ç•¥ï¼ˆFSDP/Tensor Parallelï¼‰ï¼Œæ”¯æŒå¤š TPU å¹¶è¡Œ
- **BFloat16 ä¼˜åŒ–**ï¼šå…¨æµç¨‹ BF16 è®¡ç®—ï¼Œå‡å°‘å†…å­˜å ç”¨å¹¶æå‡æ€§èƒ½

## ğŸš€ Quick Start

### 1. ç¯å¢ƒå®‰è£…

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install huggingface-hub
pip install -U transformers datasets evaluate accelerate timm flax numpy
pip install torchax
pip install jax[tpu]
pip install tensorflow-cpu

# å®‰è£…è¾…åŠ©å·¥å…·
pip install sentencepiece
sudo apt install ffmpeg -y
pip install imageio[ffmpeg]
pip install tpu-info
pip install matplotlib
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# è®¾ç½® Hugging Face ç¼“å­˜ç›®å½•ï¼ˆä½¿ç”¨å…±äº«å†…å­˜åŠ é€Ÿï¼‰
export HF_HOME=/dev/shm

# è®¾ç½® Hugging Face Tokenï¼ˆç”¨äºä¸‹è½½æ¨¡å‹ï¼‰
export HF_TOKEN=<your HF_TOKEN>
```

> **æç¤º**ï¼šä» [Hugging Face Settings](https://huggingface.co/settings/tokens) è·å–ä½ çš„ API Token

### 3. å…‹éš†å¹¶å®‰è£…é¡¹ç›®

```bash
# å…‹éš† diffusers-tpu é¡¹ç›®ï¼ˆåŒ…å« Flax VAE å®ç°ï¼‰
git clone https://github.com/yangwhale/diffusers-tpu.git
cd diffusers-tpu
pip install -e .

# å…‹éš†æœ¬é¡¹ç›®
git clone https://github.com/yangwhale/gpu-tpu-pedia.git
cd gpu-tpu-pedia/tpu/cogvideo/
```

### 4. è¿è¡Œè§†é¢‘ç”Ÿæˆ

```bash
python generate_torchax.py
```

ç”Ÿæˆçš„è§†é¢‘å°†ä¿å­˜ä¸º `output_video_torchax_vae.mp4`ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
cogvideo/
â”œâ”€â”€ README.md                     # æœ¬æ–‡æ¡£
â”œâ”€â”€ generate_torchax.py           # â­ ä¸»ç¨‹åºï¼šå®Œæ•´çš„ TPU è§†é¢‘ç”Ÿæˆæµç¨‹
â”œâ”€â”€ generate_gpu.py               # GPU PyTorch ç‰ˆæœ¬ï¼ˆå‚è€ƒï¼‰
â”œâ”€â”€ vae_decode_flax.py            # Flax VAE è§£ç æµ‹è¯•
â”œâ”€â”€ vae_decode_gpu.py             # GPU PyTorch VAE è§£ç æµ‹è¯•ï¼ˆå‚è€ƒï¼‰
â””â”€â”€ output_video_torchax_vae.mp4  # ç”Ÿæˆçš„è§†é¢‘ç¤ºä¾‹
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. Splash Attention ä¼˜åŒ–

[`generate_torchax.py`](generate_torchax.py:170-286) å®ç°äº† TPU ä¸“ç”¨çš„ Splash Attentionï¼š

```python
# é…ç½®å‚æ•°ï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
BQSIZE = 2048           # Query å—å¤§å°
BKVSIZE = 1024          # Key/Value å—å¤§å°
BKVCOMPUTESIZE = 512    # Key/Value è®¡ç®—å—å¤§å°
WINDOW_SIZE = None      # çª—å£å¤§å°ï¼ˆNone = å…¨å±€æ³¨æ„åŠ›ï¼‰
USE_K_SMOOTH = True     # K-smooth ä¼˜åŒ–
```

**ç‰¹æ€§**ï¼š
- å—çŠ¶è®¡ç®—ï¼Œé¿å… VMEM æº¢å‡º
- æ”¯æŒå±€éƒ¨çª—å£æ³¨æ„åŠ›ï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
- K-smooth æŠ€æœ¯æå‡æ•°å€¼ç¨³å®šæ€§
- è‡ªåŠ¨å¤„ç†åºåˆ—å¡«å……

### 2. æ™ºèƒ½æƒé‡åˆ†ç‰‡

æ”¯æŒä¸¤ç§åˆ†ç‰‡æ¨¡å¼ï¼š

#### FSDP æ¨¡å¼ï¼ˆæ¨èï¼Œé»˜è®¤ï¼‰
```python
USE_FSDP = True

# Attention å±‚åœ¨è¾“å‡ºç»´åº¦åˆ†ç‰‡
r'.*\.to_out.*\.weight$': (('tp', 'sp'), None)
```

#### Tensor Parallel æ¨¡å¼
```python
USE_FSDP = False

# Attention å±‚åœ¨è¾“å…¥ç»´åº¦åˆ†ç‰‡
r'.*\.to_q\.weight$': (('tp', 'sp'), None)
```

**æƒé‡åˆ†ç‰‡å‡½æ•°**ï¼š
- [`shard_weights_transformer()`](generate_torchax.py:414-449)ï¼šTransformer æ¨¡å‹åˆ†ç‰‡
- [`shard_weights_text_encoder()`](generate_torchax.py:452-479)ï¼šT5 æ–‡æœ¬ç¼–ç å™¨åˆ†ç‰‡
- [`shard_weights_vae()`](generate_torchax.py:482-503)ï¼šVAE æƒé‡åˆ†ç‰‡ï¼ˆå½“å‰å¤åˆ¶æ¨¡å¼ï¼‰

### 3. Flax VAE é›†æˆ

[`FlaxVAEProxy`](generate_torchax.py:637-689) ç±»å®ç°äº† PyTorch åˆ° Flax VAE çš„æ— ç¼åˆ‡æ¢ï¼š

**å…³é”®ä¼˜åŒ–**ï¼š
- å…¨æµç¨‹ BF16 è®¡ç®—ï¼Œé¿å…ä¸­é—´ FP32 æ•°ç»„
- é€å¸§è§£ç ï¼Œæ”¯æŒé•¿è§†é¢‘ï¼ˆé¿å… OOMï¼‰
- å†…å­˜é«˜æ•ˆçš„æ•°æ®è½¬æ¢ï¼ˆä½¿ç”¨ numpy viewï¼‰
- å¯é€‰çš„ Tiling è§£ç ï¼ˆå¤„ç†è¶…é«˜åˆ†è¾¨ç‡ï¼‰

```python
# åœ¨ Pipeline ä¸­æ›¿æ¢ VAE
flax_vae = FlaxAutoencoderKLCogVideoX.from_pretrained(
    model_id, subfolder="vae", dtype=jnp.bfloat16
)
pipe.vae = FlaxVAEProxy(flax_vae)
```

### 4. å®Œæ•´çš„ Pipeline è®¾ç½®

[`setup_pipeline_for_jax()`](generate_torchax.py:506-634) å‡½æ•°æ‰§è¡Œå®Œæ•´çš„ TPU é…ç½®ï¼š

1. **åˆ›å»ºè®¾å¤‡ç½‘æ ¼**ï¼šæ”¯æŒ TP/DP/SP ä¸‰ç»´å¹¶è¡Œ
2. **æ³¨å†Œè‡ªå®šä¹‰ç®—å­**ï¼šSplash Attention æ›¿æ¢æ ‡å‡† SDPA
3. **æƒé‡è¿ç§»å’Œåˆ†ç‰‡**ï¼š
   - Transformer â†’ XLA + åˆ†ç‰‡
   - Text Encoder â†’ XLA + åˆ†ç‰‡
   - VAE â†’ Flax åŸç”Ÿå®ç°
4. **JIT ç¼–è¯‘**ï¼šç¼–è¯‘ Transformer å’Œ Text Encoder

## âš™ï¸ é…ç½®å‚æ•°

### Mesh åˆ†ç‰‡é…ç½®

```python
USE_DP = False          # Data Parallelismï¼ˆå¤š batch å¹¶è¡Œï¼‰
SP_NUM = 1              # Spatial Parallelismï¼ˆç©ºé—´ç»´åº¦å¹¶è¡Œï¼‰
USE_FSDP = True         # FSDP vs Tensor Parallel æ¨¡å¼
```

**è®¾å¤‡åˆ†é…ç¤ºä¾‹**ï¼ˆ8 TPU coresï¼‰ï¼š
- é»˜è®¤ï¼š`(tp=8, dp=1, sp=1)` - çº¯ Tensor Parallel
- `USE_DP=True`ï¼š`(tp=4, dp=2, sp=1)` - TP + DP æ··åˆ
- `SP_NUM=2`ï¼š`(tp=4, dp=1, sp=2)` - TP + SP æ··åˆ

### VAE Tiling é…ç½®

å¤„ç†è¶…å¤§åˆ†è¾¨ç‡è§†é¢‘æ—¶å¯å¯ç”¨ï¼ˆå½“å‰ç¦ç”¨ç”¨äºæµ‹è¯•ï¼‰ï¼š

```python
flax_vae.enable_tiling(
    tile_sample_min_height=192,      # ç“¦ç‰‡æœ€å°é«˜åº¦
    tile_sample_min_width=340,       # ç“¦ç‰‡æœ€å°å®½åº¦
    tile_overlap_factor_height=1/6,  # é«˜åº¦é‡å å› å­
    tile_overlap_factor_width=1/5,   # å®½åº¦é‡å å› å­
)
```

## ğŸ“Š æ€§èƒ½ç‰¹æ€§

### 1. JIT ç¼–è¯‘åŠ é€Ÿ

- **ç¬¬ä¸€æ¬¡è¿è¡Œ**ï¼šåŒ…å« JIT ç¼–è¯‘ï¼ˆè¾ƒæ…¢ï¼‰
- **åç»­è¿è¡Œ**ï¼šä½¿ç”¨ç¼“å­˜çš„ç¼–è¯‘ç»“æœï¼ˆå¿«é€Ÿï¼‰
- **å…¸å‹åŠ é€Ÿæ¯”**ï¼š2-5xï¼ˆå–å†³äºæ¨¡å‹å¤§å°ï¼‰

### 2. å†…å­˜ä¼˜åŒ–

- **BF16 è®¡ç®—**ï¼šç›¸æ¯” FP32 å‡å°‘ 50% å†…å­˜
- **é€å¸§ VAE è§£ç **ï¼šé¿å…å¤§è§†é¢‘çš„ OOM
- **é«˜æ•ˆæ•°æ®è½¬æ¢**ï¼šä½¿ç”¨ numpy viewï¼Œé¿å…æ‹·è´

### 3. å¹¶è¡Œç­–ç•¥

æ”¯æŒä¸‰ç§å¹¶è¡Œç»´åº¦çš„çµæ´»ç»„åˆï¼š
- **Tensor Parallel (TP)**ï¼šè·¨è®¾å¤‡åˆ†ç‰‡æ¨¡å‹æƒé‡
- **Data Parallel (DP)**ï¼šå¹¶è¡Œå¤„ç†å¤šä¸ª batch
- **Spatial Parallel (SP)**ï¼šç©ºé—´ç»´åº¦å¹¶è¡Œï¼ˆé«˜åˆ†è¾¨ç‡ï¼‰

## ğŸ¬ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è§†é¢‘ç”Ÿæˆ

```python
from diffusers import CogVideoXPipeline

# åŠ è½½æ¨¡å‹
pipe = CogVideoXPipeline.from_pretrained("zai-org/CogVideoX1.5-5B")

# é…ç½®ä¸º TPU
pipe, env, mesh = setup_pipeline_for_jax(pipe)

# ç”Ÿæˆè§†é¢‘
prompt = "A cat walks on the grass, realistic style."
with mesh, env:
    result = pipe(
        prompt,
        num_inference_steps=50,
        num_frames=64,
        height=768,
        width=1360
    )
    frames = result.frames[0]

# ä¿å­˜è§†é¢‘
import imageio
imageio.mimsave('output.mp4', frames, fps=8)
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

ä½¿ç”¨ [`run_generation_benchmark()`](generate_torchax.py:692-739) å‡½æ•°ï¼š

```python
frames, times = run_generation_benchmark(
    pipe,
    prompt="A dog cooking cake in the kitchen",
    num_inference_steps=50,
    num_frames=64,
    height=768,
    width=1360,
    num_iterations=2
)

# æ‰“å°æ€§èƒ½æ‘˜è¦
print_performance_summary(times)
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
æ€»è¿­ä»£æ¬¡æ•°: 2
ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆå«ç¼–è¯‘ï¼‰: 45.2341 ç§’
åç»­è¿è¡Œå¹³å‡æ—¶é—´: 18.5672 ç§’
åŠ é€Ÿæ¯”: 2.44x
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### 1. VMEM æº¢å‡º

**ç—‡çŠ¶**ï¼š`RESOURCE_EXHAUSTED: Ran out of memory in memory space vmem`

**è§£å†³æ–¹æ¡ˆ**ï¼šå‡å° Splash Attention å—å¤§å°
```python
BQSIZE = 1024        # ä» 2048 å‡å°
BKVSIZE = 512        # ä» 1024 å‡å°
BKVCOMPUTESIZE = 256 # ä» 512 å‡å°
```

### 2. OOM é”™è¯¯

**ç—‡çŠ¶**ï¼šå†…å­˜ä¸è¶³é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å¯ç”¨ VAE Tilingï¼ˆå¤„ç†å¤§è§†é¢‘ï¼‰
2. å‡å°‘è§†é¢‘å¸§æ•°æˆ–åˆ†è¾¨ç‡
3. ä½¿ç”¨ Data Parallel æ¨¡å¼åˆ†æ•£å†…å­˜

### 3. ç¼–è¯‘ç¼“å­˜

å¯ç”¨ JAX ç¼–è¯‘ç¼“å­˜ä»¥åŠ é€Ÿé‡å¤è¿è¡Œï¼š

```python
jax.config.update("jax_compilation_cache_dir", "/dev/shm/jax_cache")
jax.config.update("jax_persistent_cache_min_entry_size_bytes", -1)
```

## ğŸ“š ç›¸å…³èµ„æº

- [CogVideoX å®˜æ–¹ä»“åº“](https://github.com/THUDM/CogVideo)
- [Diffusers TPU ç‰ˆæœ¬](https://github.com/yangwhale/diffusers-tpu)
- [JAX æ–‡æ¡£](https://jax.readthedocs.io/)
- [Flax æ–‡æ¡£](https://flax.readthedocs.io/)
- [TPU å¼€å‘æŒ‡å—](https://cloud.google.com/tpu/docs)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªåŸå§‹é¡¹ç›®çš„è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- CogVideoX å›¢é˜Ÿ
- Hugging Face Diffusers å›¢é˜Ÿ
- Google JAX/Flax å›¢é˜Ÿ
- TPU ç¤¾åŒº

---

**æœ€åæ›´æ–°**ï¼š2025-11-04