#!/usr/bin/env python3
"""
================================================================================
HunyuanVideo-1.5 ä¸‰é˜¶æ®µç”Ÿæˆ - é˜¶æ®µ2ï¼šTransformer (DiT) (GPU ç‰ˆæœ¬)
================================================================================

è¿™ä¸ªæ–‡ä»¶æ˜¯ HunyuanVideo-1.5 è§†é¢‘ç”Ÿæˆæµæ°´çº¿çš„ç¬¬äºŒé˜¶æ®µï¼šTransformer æ¨ç†ã€‚

================================================================================
ğŸ“š å®Œæ•´è°ƒç”¨æµç¨‹æ¦‚è§ˆ
================================================================================

HunyuanVideo-1.5 ä½¿ç”¨"ä¸‰é˜¶æ®µ"æ¶æ„æ¥ç”Ÿæˆè§†é¢‘ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Text Encoding (æ–‡æœ¬ç¼–ç )                                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ è¾“å…¥: æ–‡æœ¬ prompt (å¦‚ "a cat walking in the garden")                          â”‚
â”‚ è¾“å‡º: text embeddings (æ–‡æœ¬åµŒå…¥å‘é‡) - å…± 8 ä¸ª tensor                         â”‚
â”‚                                                                             â”‚
â”‚ ä½¿ç”¨æ¨¡å‹ (é¡ºåºæ‰§è¡Œï¼Œå› ä¸ºæ˜¾å­˜é™åˆ¶):                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ æ­¥éª¤ 1: LLaVA (å¤§è¯­è¨€æ¨¡å‹)                                            â”‚  â”‚
â”‚   â”‚   - è¾“å…¥: prompt æ–‡æœ¬                                                 â”‚  â”‚
â”‚   â”‚   - è¾“å‡º: prompt_embeds (è¯­ä¹‰çº§åˆ«çš„ç†è§£)                              â”‚  â”‚
â”‚   â”‚   - å†…å­˜: ~14GB                                                       â”‚  â”‚
â”‚   â”‚   - å®Œæˆå: å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾æ˜¾å­˜                                         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â†“                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ æ­¥éª¤ 2: ByT5 (å­—èŠ‚çº§æ–‡æœ¬ç¼–ç å™¨)                                        â”‚  â”‚
â”‚   â”‚   - è¾“å…¥: prompt æ–‡æœ¬ (ç›¸åŒçš„è¾“å…¥ï¼Œç‹¬ç«‹å¤„ç†)                           â”‚  â”‚
â”‚   â”‚   - è¾“å‡º: prompt_embeds_2 (å­—ç¬¦çº§åˆ«çš„ç‰¹å¾)                            â”‚  â”‚
â”‚   â”‚   - å†…å­˜: ~5GB                                                        â”‚  â”‚
â”‚   â”‚   - å®Œæˆå: å¸è½½æ¨¡å‹ï¼Œé‡Šæ”¾æ˜¾å­˜                                         â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆæ˜¯é¡ºåºè€Œä¸æ˜¯å¹¶è¡Œï¼Ÿã€‘                                                  â”‚
â”‚   - LLaVA (~14GB) + ByT5 (~5GB) = ~19GB åŒæ—¶åŠ è½½                            â”‚
â”‚   - é¡ºåºæ‰§è¡Œå¯ä»¥åœ¨åŒä¸€å¼ å¡ä¸Šå®Œæˆï¼Œé™ä½ç¡¬ä»¶è¦æ±‚                                 â”‚
â”‚   - ä¸¤è€…å¤„ç†çš„æ˜¯ç›¸åŒçš„è¾“å…¥æ–‡æœ¬ï¼Œä½†æå–ä¸åŒå±‚æ¬¡çš„ç‰¹å¾                           â”‚
â”‚   - ä»é€»è¾‘ä¸Šå®ƒä»¬æ˜¯ç‹¬ç«‹çš„ï¼Œå¦‚æœæœ‰è¶³å¤Ÿæ˜¾å­˜ï¼Œç†è®ºä¸Šå¯ä»¥å¹¶è¡Œ                        â”‚
â”‚                                                                             â”‚
â”‚ æ€»å†…å­˜å³°å€¼: ~14GB (LLaVA æœ€å¤§)                                               â”‚
â”‚                                                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ ã€Stage 1 è¾“å‡ºçš„ 8 ä¸ª Tensor è¯¦è§£ã€‘                                          â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                             â”‚
â”‚ è¿™ 8 ä¸ª tensor åˆ†ä¸ºä¸¤ç»„ï¼šæ­£å‘ (positive) å’Œè´Ÿå‘ (negative)                    â”‚
â”‚ æ¯ç»„æœ‰ 4 ä¸ª tensorï¼šLLM embeddings + maskï¼ŒByT5 embeddings + mask            â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ç»„ 1: LLaVA (LLM) è¾“å‡º - è¯­ä¹‰çº§åˆ«çš„æ–‡æœ¬ç†è§£                              â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 1. prompt_embeds (1Ã—1000Ã—3584) - 3D                                     â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: (batch, seq_len, hidden_dim)                                â”‚ â”‚
â”‚ â”‚    â”œâ”€ 1: batch size                                                     â”‚ â”‚
â”‚ â”‚    â”œâ”€ 1000: æœ€å¤§ token åºåˆ—é•¿åº¦ (å›ºå®šé•¿åº¦ï¼ŒçŸ­çš„ä¼š padding)               â”‚ â”‚
â”‚ â”‚    â”œâ”€ 3584: LLaVA çš„éšè—å±‚ç»´åº¦                                          â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: æ­£å‘æç¤ºè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå‘Šè¯‰æ¨¡å‹"è¦ç”Ÿæˆä»€ä¹ˆ"                    â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 2. negative_prompt_embeds (1Ã—1000Ã—3584) - 3D                            â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: åŒä¸Š                                                        â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå‘Šè¯‰æ¨¡å‹"ä¸è¦ç”Ÿæˆä»€ä¹ˆ"                  â”‚ â”‚
â”‚ â”‚           ç”¨äº CFG (Classifier-Free Guidance) è®¡ç®—                      â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 3. prompt_embeds_mask (1Ã—1000) - 2D                                     â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: (batch, seq_len)                                            â”‚ â”‚
â”‚ â”‚    â”œâ”€ å€¼: 1 è¡¨ç¤ºçœŸå® tokenï¼Œ0 è¡¨ç¤º padding                               â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: æ³¨æ„åŠ› maskï¼Œè®©æ¨¡å‹å¿½ç•¥ padding éƒ¨åˆ†                         â”‚ â”‚
â”‚ â”‚           ä¾‹å¦‚: "a cat" åªæœ‰ 2 ä¸ª tokenï¼Œå…¶ä½™ 998 ä¸ªä½ç½®æ˜¯ padding       â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 4. negative_prompt_embeds_mask (1Ã—1000) - 2D                            â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„æ³¨æ„åŠ› mask                                      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ç»„ 2: ByT5 è¾“å‡º - å­—ç¬¦çº§åˆ«çš„æ–‡æœ¬ç‰¹å¾                                     â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 5. prompt_embeds_2 (1Ã—256Ã—1472) - 3D                                    â”‚ â”‚
â”‚ â”‚    â”œâ”€ ç»´åº¦: (batch, seq_len, hidden_dim)                                â”‚ â”‚
â”‚ â”‚    â”œâ”€ 256: æœ€å¤§å­—èŠ‚åºåˆ—é•¿åº¦ (ByT5 æŒ‰å­—èŠ‚/å­—ç¬¦å¤„ç†)                       â”‚ â”‚
â”‚ â”‚    â”œâ”€ 1472: ByT5 çš„éšè—å±‚ç»´åº¦                                           â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: å­—ç¬¦çº§åˆ«çš„æ–‡æœ¬è¡¨ç¤º                                          â”‚ â”‚
â”‚ â”‚           å¸®åŠ©æ¨¡å‹ç†è§£ç²¾ç¡®çš„æ‹¼å†™ã€æ ¼å¼ã€ç¬¦å·ç­‰                           â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 6. negative_prompt_embeds_2 (1Ã—256Ã—1472) - 3D                           â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„å­—ç¬¦çº§è¡¨ç¤º                                       â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 7. prompt_embeds_mask_2 (1Ã—256) - 2D                                    â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: ByT5 çš„æ³¨æ„åŠ› mask                                          â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚ 8. negative_prompt_embeds_mask_2 (1Ã—256) - 2D                           â”‚ â”‚
â”‚ â”‚    â””â”€ ç”¨é€”: è´Ÿå‘æç¤ºè¯çš„ ByT5 æ³¨æ„åŠ› mask                                â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆæœ‰ 2D å’Œ 3Dï¼Ÿã€‘                                                      â”‚
â”‚                                                                             â”‚
â”‚   3D Tensor (embeddings):                                                   â”‚
â”‚   â”œâ”€ shape: (batch, seq_len, hidden_dim)                                    â”‚
â”‚   â””â”€ åŒ…å«å®é™…çš„è¯­ä¹‰ä¿¡æ¯ï¼Œæ¯ä¸ª token ç”¨ä¸€ä¸ª hidden_dim ç»´å‘é‡è¡¨ç¤º             â”‚
â”‚                                                                             â”‚
â”‚   2D Tensor (masks):                                                        â”‚
â”‚   â”œâ”€ shape: (batch, seq_len)                                                â”‚
â”‚   â””â”€ åªéœ€è¦æ ‡è®°æ¯ä¸ªä½ç½®æ˜¯å¦æœ‰æ•ˆï¼Œä¸éœ€è¦é¢å¤–çš„ç»´åº¦                             â”‚
â”‚       0/1 æ ‡è®°è¶³çŸ£                                                          â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸¤ç§ Text Embedding å¦‚ä½•ç»“åˆä½¿ç”¨ï¼Ÿ- æºç åˆ†æã€‘                              â”‚
â”‚                                                                             â”‚
â”‚ âš ï¸  é‡è¦ï¼šä¸æ˜¯ä¸¤æ¬¡äº¤å‰æ³¨æ„åŠ›ï¼Œè€Œæ˜¯æ‹¼æ¥ååšä¸€æ¬¡è”åˆæ³¨æ„åŠ›ï¼                      â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                    å¤„ç†æµç¨‹ï¼ˆåœ¨ forward() ä¸­ï¼‰                            â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 1: LLaVA embeddings æŠ•å½±                                          â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚ â”‚
â”‚ â”‚  # ä½¿ç”¨ SingleTokenRefiner å¤„ç† LLaVA embeddings                        â”‚ â”‚
â”‚ â”‚  txt = self.txt_in(txt, t, text_mask)                                   â”‚ â”‚
â”‚ â”‚  # txt shape: (B, 1000, 3072) - æŠ•å½±åˆ° hidden_size                      â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 2: ByT5 embeddings æŠ•å½±                                           â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚ â”‚
â”‚ â”‚  if self.glyph_byT5_v2:                                                 â”‚ â”‚
â”‚ â”‚      byt5_text_states = extra_kwargs["byt5_text_states"]                â”‚ â”‚
â”‚ â”‚      byt5_txt = self.byt5_in(byt5_text_states)                          â”‚ â”‚
â”‚ â”‚      # byt5_txt shape: (B, 256, 3072) - ä¹ŸæŠ•å½±åˆ° hidden_size            â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 3: â˜… å…³é”® â˜… æ‹¼æ¥ä¸¤ç§ text tokens                                   â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚ â”‚
â”‚ â”‚  # reorder_txt_token() å‡½æ•°å°†ä¸¤è€…æ‹¼æ¥æˆä¸€ä¸ªåºåˆ—                          â”‚ â”‚
â”‚ â”‚  txt, text_mask = self.reorder_txt_token(                               â”‚ â”‚
â”‚ â”‚      byt5_txt,      # ByT5 tokens                                       â”‚ â”‚
â”‚ â”‚      txt,           # LLaVA tokens                                      â”‚ â”‚
â”‚ â”‚      byt5_text_mask,                                                    â”‚ â”‚
â”‚ â”‚      text_mask                                                          â”‚ â”‚
â”‚ â”‚  )                                                                      â”‚ â”‚
â”‚ â”‚  # æ‹¼æ¥å txt shape: (B, 256+1000, 3072) = (B, 1256, 3072)              â”‚ â”‚
â”‚ â”‚  # æ‹¼æ¥é¡ºåº: [ByT5æœ‰æ•ˆtokens, LLaVAæœ‰æ•ˆtokens, ByT5 padding, LLaVA pad] â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  æ­¥éª¤ 4: è”åˆæ³¨æ„åŠ›ï¼ˆä¸æ˜¯åˆ†å¼€çš„ä¸¤æ¬¡ï¼ï¼‰                                    â”‚ â”‚
â”‚ â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚ â”‚
â”‚ â”‚  for block in self.double_blocks:                                       â”‚ â”‚
â”‚ â”‚      img, txt = block(img, txt, ...)                                    â”‚ â”‚
â”‚ â”‚      # txt åŒ…å«æ‹¼æ¥åçš„ LLaVA+ByT5ï¼Œä½œä¸ºä¸€ä¸ªæ•´ä½“å‚ä¸æ³¨æ„åŠ›               â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚           MMDoubleStreamBlock å†…éƒ¨ç»“æ„ï¼ˆæºç ç¬¬ 43-204 è¡Œï¼‰                â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚ â”‚  â”‚  img (è§†é¢‘)  â”‚     â”‚  txt (LLaVA + ByT5 æ‹¼æ¥å)      â”‚                â”‚ â”‚
â”‚ â”‚  â”‚  tokens     â”‚     â”‚  = 1256 ä¸ª tokens               â”‚                â”‚ â”‚
â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚ â”‚         â”‚                             â”‚                                  â”‚ â”‚
â”‚ â”‚         â–¼                             â–¼                                  â”‚ â”‚
â”‚ â”‚   img_q, img_k, img_v          txt_q, txt_k, txt_v                       â”‚ â”‚
â”‚ â”‚         â”‚                             â”‚                                  â”‚ â”‚
â”‚ â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚ â”‚
â”‚ â”‚                       â–¼                                                  â”‚ â”‚
â”‚ â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚ â”‚
â”‚ â”‚         â”‚     parallel_attention()         â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  è”åˆè®¡ç®— img å’Œ txt çš„æ³¨æ„åŠ›     â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  img tokens å¯ä»¥ attend to:      â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚    - å…¶ä»– img tokens             â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚    - LLaVA text tokens           â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚    - ByT5 text tokens            â”‚                              â”‚ â”‚
â”‚ â”‚         â”‚  ï¼ˆæ‰€æœ‰ text tokens åœ¨åŒä¸€åºåˆ—ä¸­ï¼‰â”‚                              â”‚ â”‚
â”‚ â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚ â”‚
â”‚ â”‚                       â”‚                                                  â”‚ â”‚
â”‚ â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚ â”‚
â”‚ â”‚         â–¼                             â–¼                                  â”‚ â”‚
â”‚ â”‚   img_attn                      txt_attn                                 â”‚ â”‚
â”‚ â”‚         â”‚                             â”‚                                  â”‚ â”‚
â”‚ â”‚         â–¼                             â–¼                                  â”‚ â”‚
â”‚ â”‚   img + FFN                     txt + FFN                                â”‚ â”‚
â”‚ â”‚                                                                         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚ ã€å…³é”®æºç ç‰‡æ®µ - hunyuanvideo_1_5_transformer.pyã€‘                          â”‚
â”‚                                                                             â”‚
â”‚   ç¬¬ 751-762 è¡Œ - ByT5 å¤„ç†ä¸æ‹¼æ¥:                                          â”‚
â”‚   ```python                                                                 â”‚
â”‚   if self.glyph_byT5_v2:                                                    â”‚
â”‚       byt5_text_states = extra_kwargs["byt5_text_states"]                   â”‚
â”‚       byt5_text_mask = extra_kwargs["byt5_text_mask"]                       â”‚
â”‚       byt5_txt = self.byt5_in(byt5_text_states)  # æŠ•å½±åˆ° hidden_size       â”‚
â”‚       txt, text_mask = self.reorder_txt_token(                              â”‚
â”‚           byt5_txt, txt, byt5_text_mask, text_mask                          â”‚
â”‚       )  # â˜… å…³é”®ï¼šæ‹¼æ¥æˆä¸€ä¸ªåºåˆ—                                           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ç¬¬ 630-664 è¡Œ - reorder_txt_token() æ‹¼æ¥é€»è¾‘:                             â”‚
â”‚   ```python                                                                 â”‚
â”‚   # æ‹¼æ¥é¡ºåºï¼šæœ‰æ•ˆçš„ ByT5 + æœ‰æ•ˆçš„ LLaVA + padding                          â”‚
â”‚   reorder_txt_i = torch.cat([                                               â”‚
â”‚       byt5_txt_i[byt5_text_mask_i],   # ByT5 æœ‰æ•ˆ tokens                    â”‚
â”‚       txt_i[text_mask_i],             # LLaVA æœ‰æ•ˆ tokens                   â”‚
â”‚       pad_byt5,                       # ByT5 padding                        â”‚
â”‚       pad_text                        # LLaVA padding                       â”‚
â”‚   ], dim=0)                                                                 â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ç¬¬ 176-186 è¡Œ - è”åˆæ³¨æ„åŠ›è®¡ç®—:                                           â”‚
â”‚   ```python                                                                 â”‚
â”‚   attn = parallel_attention(                                                â”‚
â”‚       (img_q, txt_q),  # txt_q åŒ…å« LLaVA + ByT5                            â”‚
â”‚       (img_k, txt_k),                                                       â”‚
â”‚       (img_v, txt_v),                                                       â”‚
â”‚       text_mask=text_mask,  # mask ä¹Ÿæ˜¯æ‹¼æ¥åçš„                             â”‚
â”‚       ...                                                                   â”‚
â”‚   )                                                                         â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆç”¨æ‹¼æ¥è€Œä¸æ˜¯ä¸¤æ¬¡ Cross-Attentionï¼Ÿã€‘                                  â”‚
â”‚                                                                             â”‚
â”‚   1. æ•ˆç‡æ›´é«˜ï¼šä¸€æ¬¡æ³¨æ„åŠ›è®¡ç®— vs ä¸¤æ¬¡                                        â”‚
â”‚   2. æ›´è‡ªç„¶çš„äº¤äº’ï¼š                                                          â”‚
â”‚      - è§†é¢‘ tokens å¯ä»¥åŒæ—¶ attend to ä¸¤ç§æ–‡æœ¬                              â”‚
â”‚      - ä¸¤ç§æ–‡æœ¬ç‰¹å¾ä¹Ÿå¯ä»¥ç›¸äº’äº¤äº’                                           â”‚
â”‚   3. ç»Ÿä¸€çš„ mask å¤„ç†ï¼š                                                      â”‚
â”‚      - æœ‰æ•ˆ tokens æ”¾å‰é¢ï¼Œpadding æ”¾åé¢                                   â”‚
â”‚      - å¯ä»¥ç”¨åŒä¸€ä¸ª mask æ§åˆ¶æ³¨æ„åŠ›èŒƒå›´                                     â”‚
â”‚                                                                             â”‚
â”‚ ã€æ‹¼æ¥åçš„åºåˆ—ç»“æ„ã€‘                                                         â”‚
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  ByT5 æœ‰æ•ˆ   â”‚  LLaVA æœ‰æ•ˆ  â”‚  ByT5 pad  â”‚  LLaVA pad  â”‚       â”‚       â”‚
â”‚   â”‚  tokens      â”‚  tokens      â”‚            â”‚             â”‚       â”‚       â”‚
â”‚   â”‚  (~50-100)   â”‚  (~20-50)    â”‚  (~150)    â”‚  (~950)     â”‚       â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â†‘              â†‘              â†‘            â†‘                       â”‚
â”‚       å­—ç¬¦çº§         è¯­ä¹‰çº§        mask=0       mask=0                     â”‚
â”‚       ç»†èŠ‚           ç†è§£        (è¢«å¿½ç•¥)      (è¢«å¿½ç•¥)                     â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆæŠŠæ‰€æœ‰ padding éƒ½æ”¾åˆ°åé¢ï¼Ÿã€‘                                        â”‚
â”‚                                                                             â”‚
â”‚   è¿™ç§é‡æ’åºç­–ç•¥æœ‰å‡ ä¸ªé‡è¦åŸå› ï¼š                                             â”‚
â”‚                                                                             â”‚
â”‚   1. ä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—æ•ˆç‡                                                      â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚      åŸå§‹å¸ƒå±€ï¼ˆä¸é‡æ’ï¼‰:                                                     â”‚
â”‚        [ByT5æœ‰æ•ˆ, ByT5 pad, LLaVAæœ‰æ•ˆ, LLaVA pad]                          â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€256â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€1000â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”‚
â”‚                                                                             â”‚
â”‚      é—®é¢˜ï¼šæœ‰æ•ˆ tokens è¢« padding åˆ†éš”ï¼Œæ³¨æ„åŠ›è®¡ç®—æ—¶éœ€è¦é¢‘ç¹è·³è¿‡              â”‚
â”‚                                                                             â”‚
â”‚      é‡æ’åå¸ƒå±€:                                                             â”‚
â”‚        [ByT5æœ‰æ•ˆ, LLaVAæœ‰æ•ˆ, ByT5 pad, LLaVA pad]                          â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€æœ‰æ•ˆåŒºåŸŸâ”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€padding åŒºåŸŸâ”€â”€â”€â”€â”¤                        â”‚
â”‚                                                                             â”‚
â”‚      ä¼˜ç‚¹ï¼šæœ‰æ•ˆ tokens è¿ç»­ï¼Œå¯ä»¥æ›´é«˜æ•ˆåˆ©ç”¨ç¡¬ä»¶å¹¶è¡Œè®¡ç®—                       â”‚
â”‚                                                                             â”‚
â”‚   2. Block Mask / åˆ†å—æ³¨æ„åŠ›ä¼˜åŒ–                                             â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚      æºç æ³¨é‡Š (ç¬¬ 640-641 è¡Œ):                                              â”‚
â”‚      ```python                                                              â”‚
â”‚      # When using block mask with approximate computation,                  â”‚
â”‚      # set pad to zero to reduce error                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚      HunyuanVideo ä½¿ç”¨ "flex-block-attn" åˆ†å—æ³¨æ„åŠ›ï¼š                       â”‚
â”‚      - å°†åºåˆ—åˆ†æˆå›ºå®šå¤§å°çš„å— (å¦‚ tile_size=[6,8,8])                        â”‚
â”‚      - å—å†…è®¡ç®—æ³¨æ„åŠ›ï¼Œå—é—´ç”¨ç¨€ç–é‡‡æ ·                                        â”‚
â”‚                                                                             â”‚
â”‚      å¦‚æœæœ‰æ•ˆ tokens å’Œ padding äº¤é”™ï¼š                                       â”‚
â”‚        å— 1: [æœ‰æ•ˆ, æœ‰æ•ˆ, pad]    â† éœ€è¦å¤æ‚çš„ mask å¤„ç†                    â”‚
â”‚        å— 2: [æœ‰æ•ˆ, pad, pad]     â† å—å†…æ··åˆï¼Œå¢åŠ è®¡ç®—è¯¯å·®                   â”‚
â”‚                                                                             â”‚
â”‚      å¦‚æœ padding é›†ä¸­åˆ°åé¢ï¼š                                               â”‚
â”‚        å— 1: [æœ‰æ•ˆ, æœ‰æ•ˆ, æœ‰æ•ˆ]   â† å®Œæ•´çš„æœ‰æ•ˆå—                            â”‚
â”‚        å— N: [pad, pad, pad]      â† æ•´å—è¢«å¿½ç•¥                              â”‚
â”‚                                                                             â”‚
â”‚   3. SSTA (Sparse Spatial-Temporal Attention) ä¼˜åŒ–                          â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”‚
â”‚      HunyuanVideo ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›æ¥å¤„ç†é•¿åºåˆ—ï¼š                               â”‚
â”‚      - ssta_topk: åªé€‰æ‹© top-k é‡è¦çš„ tokens                                â”‚
â”‚      - ssta_sampling_type: 'importance' é‡è¦æ€§é‡‡æ ·                          â”‚
â”‚                                                                             â”‚
â”‚      æœ‰æ•ˆ tokens è¿ç»­æ’åˆ—ä½¿å¾—ï¼š                                              â”‚
â”‚      - é‡‡æ ·ç´¢å¼•è®¡ç®—æ›´ç®€å•                                                    â”‚
â”‚      - ä¸ä¼šæ„å¤–é‡‡æ ·åˆ° padding tokens                                        â”‚
â”‚      - å‡å°‘æ— æ•ˆè®¡ç®—                                                          â”‚
â”‚                                                                             â”‚
â”‚   4. å†…å­˜è®¿é—®ä¼˜åŒ–                                                            â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚
â”‚      GPU å†…å­˜è®¿é—®æ˜¯è¿ç»­çš„æ›´é«˜æ•ˆï¼š                                            â”‚
â”‚      - æœ‰æ•ˆ tokens è¿ç»­ â†’ ç¼“å­˜å‘½ä¸­ç‡é«˜                                      â”‚
â”‚      - padding åœ¨æœ«å°¾ â†’ å¯èƒ½æ•´ä¸ªä¸åŠ è½½                                      â”‚
â”‚                                                                             â”‚
â”‚   ã€æºç å®ç° - reorder_txt_token() ç¬¬ 630-664 è¡Œã€‘                          â”‚
â”‚                                                                             â”‚
â”‚   ```python                                                                 â”‚
â”‚   def reorder_txt_token(self, byt5_txt, txt, byt5_text_mask, text_mask):   â”‚
â”‚       for i in range(text_mask.shape[0]):                                   â”‚
â”‚           # ç”¨ mask ç­›é€‰æœ‰æ•ˆå’Œ padding tokens                               â”‚
â”‚           byt5_text_mask_i = byt5_text_mask[i].bool()                       â”‚
â”‚           text_mask_i = text_mask[i].bool()                                 â”‚
â”‚                                                                             â”‚
â”‚           # æ‹¼æ¥é¡ºåº: æœ‰æ•ˆä¼˜å…ˆï¼Œpadding åœ¨å                                â”‚
â”‚           reorder_txt_i = torch.cat([                                       â”‚
â”‚               byt5_txt_i[byt5_text_mask_i],    # ByT5 æœ‰æ•ˆ                  â”‚
â”‚               txt_i[text_mask_i],              # LLaVA æœ‰æ•ˆ                 â”‚
â”‚               byt5_txt_i[~byt5_text_mask_i],   # ByT5 padding               â”‚
â”‚               txt_i[~text_mask_i]              # LLaVA padding              â”‚
â”‚           ], dim=0)                                                         â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ã€PyTorch å¸ƒå°”ç´¢å¼•ï¼ˆBoolean Indexingï¼‰è¯­æ³•è¯¦è§£ã€‘                           â”‚
â”‚                                                                             â”‚
â”‚   è¿™ç§ tensor[mask] çš„å†™æ³•å«åš"å¸ƒå°”ç´¢å¼•"ï¼Œæ˜¯ NumPy/PyTorch çš„æ ¸å¿ƒç‰¹æ€§ï¼š     â”‚
â”‚                                                                             â”‚
â”‚   åŸºæœ¬æ¦‚å¿µ:                                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚   ```python                                                                 â”‚
â”‚   # å‡è®¾æœ‰ä¸€ä¸ª 2D tensorï¼Œshape: (5, 768)                                   â”‚
â”‚   txt = torch.tensor([                                                      â”‚
â”‚       [0.1, 0.2, ...],  # token 0 - "hello"                                 â”‚
â”‚       [0.3, 0.4, ...],  # token 1 - "world"                                 â”‚
â”‚       [0.0, 0.0, ...],  # token 2 - [PAD]                                   â”‚
â”‚       [0.0, 0.0, ...],  # token 3 - [PAD]                                   â”‚
â”‚       [0.0, 0.0, ...],  # token 4 - [PAD]                                   â”‚
â”‚   ])                                                                        â”‚
â”‚                                                                             â”‚
â”‚   # mask æ˜¯ä¸€ä¸ªå¸ƒå°”å‘é‡ï¼Œé•¿åº¦ä¸ txt çš„ç¬¬ä¸€ç»´ç›¸åŒ                             â”‚
â”‚   mask = torch.tensor([True, True, False, False, False])                    â”‚
â”‚                                                                             â”‚
â”‚   # å¸ƒå°”ç´¢å¼•ï¼šåªé€‰æ‹© mask ä¸º True çš„è¡Œ                                       â”‚
â”‚   valid_tokens = txt[mask]                                                  â”‚
â”‚   # ç»“æœ: shape (2, 768) - åªæœ‰ "hello" å’Œ "world"                          â”‚
â”‚                                                                             â”‚
â”‚   # å–åï¼šé€‰æ‹© mask ä¸º False çš„è¡Œ                                            â”‚
â”‚   padding_tokens = txt[~mask]                                               â”‚
â”‚   # ç»“æœ: shape (3, 768) - ä¸‰ä¸ª [PAD] tokens                                â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   åŸç†è§£æ:                                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚   tensor[bool_mask] ä¼šï¼š                                                     â”‚
â”‚   1. éå† bool_mask ä¸­æ¯ä¸ªä½ç½®                                               â”‚
â”‚   2. å¦‚æœè¯¥ä½ç½®æ˜¯ Trueï¼Œåˆ™ä¿ç•™å¯¹åº”çš„ tensor è¡Œ                               â”‚
â”‚   3. å¦‚æœæ˜¯ Falseï¼Œåˆ™è·³è¿‡è¯¥è¡Œ                                                â”‚
â”‚   4. è¿”å›ä¸€ä¸ªæ–°çš„ tensorï¼ŒåªåŒ…å«è¢«é€‰ä¸­çš„è¡Œ                                   â”‚
â”‚                                                                             â”‚
â”‚   å®é™…ä¾‹å­:                                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚   ```python                                                                 â”‚
â”‚   # å‡è®¾ prompt = "a cat"                                                   â”‚
â”‚   # LLaVA tokenize å: ["a", "cat", PAD, PAD, ..., PAD] (é•¿åº¦ 1000)         â”‚
â”‚                                                                             â”‚
â”‚   text_mask = torch.tensor([1, 1, 0, 0, ..., 0])  # å‰ä¸¤ä¸ªæ˜¯æœ‰æ•ˆçš„          â”‚
â”‚   text_mask_bool = text_mask.bool()                                         â”‚
â”‚   # â†’ [True, True, False, False, ..., False]                                â”‚
â”‚                                                                             â”‚
â”‚   txt_embeddings = torch.randn(1000, 3072)  # 1000 ä¸ª token embeddings      â”‚
â”‚                                                                             â”‚
â”‚   # åªå–æœ‰æ•ˆ tokens                                                          â”‚
â”‚   valid = txt_embeddings[text_mask_bool]                                    â”‚
â”‚   # â†’ shape: (2, 3072) åªæœ‰ "a" å’Œ "cat"                                    â”‚
â”‚                                                                             â”‚
â”‚   # å– padding tokens                                                        â”‚
â”‚   padding = txt_embeddings[~text_mask_bool]                                 â”‚
â”‚   # â†’ shape: (998, 3072) æ‰€æœ‰ PAD                                           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆè¿™ä¹ˆå†™ï¼Ÿ                                                             â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚
â”‚   1. ç®€æ´ï¼šä¸€è¡Œä»£ç å®Œæˆç­›é€‰ï¼Œä¸éœ€è¦å¾ªç¯                                      â”‚
â”‚   2. é«˜æ•ˆï¼šPyTorch å†…éƒ¨ä¼˜åŒ–ï¼Œæ¯” Python å¾ªç¯å¿«å¾—å¤š                            â”‚
â”‚   3. å†…å­˜å‹å¥½ï¼šè¿”å›è¿ç»­çš„æ–° tensorï¼Œé€‚åˆ GPU è®¡ç®—                            â”‚
â”‚   4. å¹¿æ’­å…¼å®¹ï¼šå¯ä»¥å’Œå…¶ä»–æ“ä½œæ— ç¼ç»“åˆ                                        â”‚
â”‚                                                                             â”‚
â”‚   å¸¸è§ç”¨æ³•:                                                                  â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚   ```python                                                                 â”‚
â”‚   # 1. ç­›é€‰æ»¡è¶³æ¡ä»¶çš„å…ƒç´                                                     â”‚
â”‚   x = torch.tensor([1, 5, 3, 8, 2])                                         â”‚
â”‚   big = x[x > 3]  # â†’ tensor([5, 8])                                        â”‚
â”‚                                                                             â”‚
â”‚   # 2. ç”¨ mask ç­›é€‰                                                          â”‚
â”‚   mask = torch.tensor([True, False, True, False, True])                     â”‚
â”‚   selected = x[mask]  # â†’ tensor([1, 3, 2])                                 â”‚
â”‚                                                                             â”‚
â”‚   # 3. å¤šç»´æƒ…å†µ                                                              â”‚
â”‚   y = torch.randn(100, 768)  # 100 ä¸ª tokens                                â”‚
â”‚   valid_mask = torch.zeros(100, dtype=torch.bool)                           â”‚
â”‚   valid_mask[:20] = True  # å‰ 20 ä¸ªæœ‰æ•ˆ                                    â”‚
â”‚   y_valid = y[valid_mask]  # â†’ shape (20, 768)                              â”‚
â”‚                                                                             â”‚
â”‚   # 4. å–å                                                                  â”‚
â”‚   y_padding = y[~valid_mask]  # â†’ shape (80, 768)                           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚ ã€âš ï¸ TPU ä¸Šçš„å…¼å®¹æ€§é—®é¢˜ã€‘                                                    â”‚
â”‚                                                                             â”‚
â”‚   å¸ƒå°”ç´¢å¼•åœ¨ TPU ä¸Šç¡®å®ä¸å¤ªå‹å¥½ï¼åŸå› ï¼š                                       â”‚
â”‚                                                                             â”‚
â”‚   1. åŠ¨æ€å½¢çŠ¶é—®é¢˜                                                            â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚      ```python                                                              â”‚
â”‚      # GPU ä¸Šæ²¡é—®é¢˜                                                          â”‚
â”‚      mask = torch.tensor([True, True, False, False, False])                 â”‚
â”‚      result = tensor[mask]  # â†’ shape (2, ...) åŠ¨æ€ç¡®å®š                     â”‚
â”‚                                                                             â”‚
â”‚      # TPU/XLA é—®é¢˜ï¼šç¼–è¯‘æ—¶ä¸çŸ¥é“æœ‰å¤šå°‘ä¸ª Trueï¼                             â”‚
â”‚      # XLA éœ€è¦é™æ€å½¢çŠ¶æ¥ä¼˜åŒ–è®¡ç®—å›¾                                          â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   2. TPU å¤„ç†æ–¹å¼:                                                           â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                        â”‚
â”‚      a) ä½¿ç”¨ torch.where() + é¢„åˆ†é…                                         â”‚
â”‚      ```python                                                              â”‚
â”‚      # ä¸ç”¨å¸ƒå°”ç´¢å¼•ï¼Œç”¨ where + gather                                       â”‚
â”‚      indices = torch.where(mask)[0]  # è·å– True çš„ç´¢å¼•                     â”‚
â”‚      # å¦‚æœçŸ¥é“æœ€å¤§æ•°é‡ï¼Œå¯ä»¥ pad åˆ°å›ºå®šé•¿åº¦                                 â”‚
â”‚      max_valid = 100                                                        â”‚
â”‚      indices_padded = F.pad(indices, (0, max_valid - len(indices)))         â”‚
â”‚      result = torch.index_select(tensor, 0, indices_padded)                 â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚      b) ä½¿ç”¨ä¹˜æ³• maskï¼ˆä¿æŒå½¢çŠ¶ä¸å˜ï¼‰                                        â”‚
â”‚      ```python                                                              â”‚
â”‚      # ä¸æ”¹å˜å½¢çŠ¶ï¼Œç”¨ä¹˜æ³•"å±è”½"                                              â”‚
â”‚      masked_tensor = tensor * mask.unsqueeze(-1).float()                    â”‚
â”‚      # shape ä¸å˜ï¼Œä½† mask=False çš„ä½ç½®å˜æˆ 0                               â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚      c) é¢„è®¡ç®—ç´¢å¼•ï¼ˆåœ¨ CPU ä¸Šï¼‰                                              â”‚
â”‚      ```python                                                              â”‚
â”‚      # CPU ä¸Šé¢„è®¡ç®—é‡æ’ç´¢å¼•                                                  â”‚
â”‚      reorder_indices = torch.cat([                                          â”‚
â”‚          torch.where(mask)[0],                                              â”‚
â”‚          torch.where(~mask)[0]                                              â”‚
â”‚      ])                                                                     â”‚
â”‚      # TPU ä¸Šç”¨å›ºå®šç´¢å¼• gather                                              â”‚
â”‚      reordered = tensor[reorder_indices]  # ç´¢å¼•æ˜¯å›ºå®šçš„ï¼Œå¯ä»¥ç¼–è¯‘          â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   3. HunyuanVideo TPU ç‰ˆæœ¬çš„å¤„ç†:                                            â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚      åœ¨ TPU ç‰ˆæœ¬ä¸­ï¼Œå¯èƒ½éœ€è¦ï¼š                                               â”‚
â”‚      - åœ¨ Stage 1 (CPU/GPU) é¢„è®¡ç®—é‡æ’ç´¢å¼•                                  â”‚
â”‚      - å°†å›ºå®šçš„ç´¢å¼•åºåˆ—ä¿å­˜å¹¶ä¼ é€’ç»™ Stage 2                                  â”‚
â”‚      - æˆ–è€…ç›´æ¥åœ¨ CPU ä¸Šå®Œæˆ reorderï¼Œå†ä¼ ç»™ TPU                             â”‚
â”‚                                                                             â”‚
â”‚      ç¤ºä¾‹ä¿®æ”¹:                                                               â”‚
â”‚      ```python                                                              â”‚
â”‚      # åŸå§‹ GPU ä»£ç                                                          â”‚
â”‚      txt, text_mask = self.reorder_txt_token(byt5_txt, txt, ...)            â”‚
â”‚                                                                             â”‚
â”‚      # TPU å‹å¥½ç‰ˆæœ¬                                                          â”‚
â”‚      def reorder_txt_token_tpu_friendly(byt5_txt, txt, byt5_mask, text_mask):â”‚
â”‚          # æ–¹æ¡ˆ1: åœ¨ CPU ä¸Šé¢„è®¡ç®—ç´¢å¼•                                        â”‚
â”‚          byt5_txt_cpu = byt5_txt.cpu()                                      â”‚
â”‚          txt_cpu = txt.cpu()                                                â”‚
â”‚          # ... åœ¨ CPU ä¸Šåšå¸ƒå°”ç´¢å¼• ...                                       â”‚
â”‚          result = result.to(device)  # ç§»å› TPU                             â”‚
â”‚                                                                             â”‚
â”‚          # æ–¹æ¡ˆ2: ä½¿ç”¨ä¹˜æ³• mask ä»£æ›¿ç´¢å¼•                                     â”‚
â”‚          # ä¸æ”¹å˜é¡ºåºï¼Œè€Œæ˜¯ç”¨ attention mask å±è”½ padding                    â”‚
â”‚          combined_txt = torch.cat([byt5_txt, txt], dim=1)                   â”‚
â”‚          combined_mask = torch.cat([byt5_mask, text_mask], dim=1)           â”‚
â”‚          # attention è®¡ç®—æ—¶ç”¨ mask è¿‡æ»¤                                      â”‚
â”‚          return combined_txt, combined_mask                                 â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   4. æœ€ä½³å®è·µ:                                                               â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                              â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚      â”‚ æ“ä½œç±»å‹          â”‚ GPU     â”‚ TPU                         â”‚        â”‚
â”‚      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”‚
â”‚      â”‚ å¸ƒå°”ç´¢å¼• [mask]   â”‚ âœ… å¿«   â”‚ âŒ å¯èƒ½å¤±è´¥æˆ–å›é€€åˆ° CPU     â”‚        â”‚
â”‚      â”‚ torch.where()     â”‚ âœ…      â”‚ âš ï¸ è¿”å›åŠ¨æ€å½¢çŠ¶ï¼Œéœ€å°å¿ƒ     â”‚        â”‚
â”‚      â”‚ ä¹˜æ³• mask         â”‚ âœ…      â”‚ âœ… æ¨èï¼Œå½¢çŠ¶ä¸å˜          â”‚        â”‚
â”‚      â”‚ gather å›ºå®šç´¢å¼•   â”‚ âœ…      â”‚ âœ… ç´¢å¼•é¢„è®¡ç®—åå¯ç”¨        â”‚        â”‚
â”‚      â”‚ attention mask    â”‚ âœ…      â”‚ âœ… æœ€ä½³æ–¹æ¡ˆ                â”‚        â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                             â”‚
â”‚   5. ä¸ºä»€ä¹ˆ GPU ä¸Šå¯ä»¥ç›´æ¥ç”¨ï¼Ÿ                                               â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚      - CUDA æ”¯æŒåŠ¨æ€å½¢çŠ¶                                                     â”‚
â”‚      - GPU kernel å¯ä»¥å³æ—¶å¤„ç†å˜é•¿è¾“å‡º                                       â”‚
â”‚      - æ²¡æœ‰åƒ XLA é‚£æ ·çš„é™æ€ç¼–è¯‘è¦æ±‚                                         â”‚
â”‚                                                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ ã€æ·±å…¥åˆ†æï¼šæ–¹æ¡ˆ3ï¼ˆç›´æ¥æ‹¼æ¥ + attention maskï¼‰çš„ä¼˜ç¼ºç‚¹ã€‘                       â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                             â”‚
â”‚   âœ… ä½ çš„ç›´è§‰å¾ˆå¯¹ï¼æ–¹æ¡ˆ3 æ˜¯ TPU ä¸Šæœ€ä¼˜é›…çš„è§£å†³æ–¹æ¡ˆã€‚                         â”‚
â”‚                                                                             â”‚
â”‚   ã€æ–¹æ¡ˆ3 å›é¡¾ã€‘                                                             â”‚
â”‚   ```python                                                                 â”‚
â”‚   # ä¸åšå¤æ‚é‡æ’ï¼Œç›´æ¥ç®€å•æ‹¼æ¥                                               â”‚
â”‚   combined_txt = torch.cat([byt5_txt, txt], dim=1)                          â”‚
â”‚   combined_mask = torch.cat([byt5_mask, text_mask], dim=1)                  â”‚
â”‚   # è®© attention è®¡ç®—æ—¶ç”¨ mask è¿‡æ»¤ padding                                 â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   ã€ä¼˜ç‚¹ã€‘                                                                   â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚   1. âœ… TPU å®Œå…¨å…¼å®¹                                                        â”‚
â”‚      - æ‰€æœ‰æ“ä½œéƒ½æ˜¯é™æ€å½¢çŠ¶ï¼ˆcat ä¸æ”¹å˜æ€»é•¿åº¦ï¼‰                              â”‚
â”‚      - æ— éœ€åŠ¨æ€ç´¢å¼•                                                          â”‚
â”‚      - XLA å¯ä»¥å®Œç¾ç¼–è¯‘                                                      â”‚
â”‚                                                                             â”‚
â”‚   2. âœ… ä»£ç ç®€å•æ¸…æ™°                                                        â”‚
â”‚      - åªéœ€è¦ torch.catï¼Œæ²¡æœ‰å¤æ‚çš„ç´¢å¼•æ“ä½œ                                  â”‚
â”‚      - æ›´å®¹æ˜“ç†è§£å’Œç»´æŠ¤                                                      â”‚
â”‚                                                                             â”‚
â”‚   3. âœ… æ•°å­¦ä¸Šç­‰ä»·                                                          â”‚
â”‚      - attention mask ä¼šå±è”½ padding ä½ç½®                                   â”‚
â”‚      - æœ€ç»ˆæ³¨æ„åŠ›ç»“æœç›¸åŒï¼ˆpadding ä½ç½®è´¡çŒ®ä¸º 0ï¼‰                            â”‚
â”‚                                                                             â”‚
â”‚   4. âœ… é¿å…æ•°æ®ç§»åŠ¨å¼€é”€                                                    â”‚
â”‚      - ä¸éœ€è¦æ ¹æ® mask é‡æ’æ•°æ®                                              â”‚
â”‚      - å‡å°‘å†…å­˜æ‹·è´                                                          â”‚
â”‚                                                                             â”‚
â”‚   ã€æ½œåœ¨å‰¯ä½œç”¨ã€‘                                                             â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                             â”‚
â”‚                                                                             â”‚
â”‚   1. âš ï¸ ç¨€ç–æ³¨æ„åŠ›ä¼˜åŒ–æ•ˆç‡é™ä½                                              â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚      HunyuanVideo ä½¿ç”¨ SSTA (Sparse Spatial-Temporal Attention)ï¼š           â”‚
â”‚                                                                             â”‚
â”‚      åŸå§‹é‡æ’åçš„å¸ƒå±€:                                                       â”‚
â”‚        [æœ‰æ•ˆ, æœ‰æ•ˆ, æœ‰æ•ˆ, ..., padding, padding, padding]                   â”‚
â”‚         â”œâ”€â”€â”€â”€â”€ å¯†é›†åŒºåŸŸ â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€ å¯è·³è¿‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                      â”‚
â”‚         â†’ SSTA topk é‡‡æ ·é«˜æ•ˆï¼Œåé¢æ•´å—è·³è¿‡                                   â”‚
â”‚                                                                             â”‚
â”‚      ç›´æ¥æ‹¼æ¥çš„å¸ƒå±€:                                                         â”‚
â”‚        [byt5æœ‰æ•ˆ, byt5 pad, llavaæœ‰æ•ˆ, llava pad]                           â”‚
â”‚         â†’ SSTA é‡‡æ ·å¯èƒ½é‡‡åˆ°ä¸­é—´çš„ padding                                   â”‚
â”‚         â†’ éœ€è¦ mask è¿‡æ»¤ï¼Œç¨å¾®å¢åŠ è®¡ç®—                                       â”‚
â”‚                                                                             â”‚
â”‚      å½±å“ç¨‹åº¦: â­â˜†â˜† (è½»å¾®)                                                   â”‚
â”‚      - å› ä¸ºæœ€ç»ˆ mask ä¼šè¿‡æ»¤ï¼Œåªæ˜¯æ•ˆç‡ç•¥ä½                                    â”‚
â”‚      - ç°ä»£ TPU çš„å¹¶è¡Œèƒ½åŠ›å¯ä»¥å¼¥è¡¥                                           â”‚
â”‚                                                                             â”‚
â”‚   2. âš ï¸ Block Attention è¿‘ä¼¼è¯¯å·®å¯èƒ½ç•¥å¢                                    â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚      æºç æ³¨é‡Š:                                                               â”‚
â”‚      ```python                                                              â”‚
â”‚      # When using block mask with approximate computation,                  â”‚
â”‚      # set pad to zero to reduce error                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚      Block attention å·¥ä½œæ–¹å¼:                                               â”‚
â”‚        åºåˆ—åˆ†æˆå›ºå®šå¤§å°çš„å—ï¼ˆå¦‚ 64 tokens ä¸€å—ï¼‰                             â”‚
â”‚        å—å†…åšç²¾ç¡®æ³¨æ„åŠ›ï¼Œå—é—´ç”¨è¿‘ä¼¼                                          â”‚
â”‚                                                                             â”‚
â”‚      é‡æ’å:                                                                 â”‚
â”‚        Block 1: [æœ‰æ•ˆ, æœ‰æ•ˆ, ..., æœ‰æ•ˆ]  â† çº¯æœ‰æ•ˆå—                         â”‚
â”‚        Block N: [pad, pad, ..., pad]     â† çº¯ padding å—ï¼ˆæ•´å—è·³è¿‡ï¼‰        â”‚
â”‚                                                                             â”‚
â”‚      ç›´æ¥æ‹¼æ¥:                                                               â”‚
â”‚        Block 1: [byt5æœ‰æ•ˆ, byt5 pad, ...]  â† æ··åˆå—                         â”‚
â”‚        Block 2: [byt5 pad, llavaæœ‰æ•ˆ, ...]  â† æ··åˆå—                        â”‚
â”‚        â†’ æ··åˆå—å†…çš„è¿‘ä¼¼è®¡ç®—è¯¯å·®å¯èƒ½ç•¥å¤§                                      â”‚
â”‚                                                                             â”‚
â”‚      å½±å“ç¨‹åº¦: â­â˜†â˜† (é€šå¸¸å¯å¿½ç•¥)                                             â”‚
â”‚      - åªè¦ padding å€¼è®¾ä¸º 0ï¼Œè¯¯å·®å¾ˆå°                                       â”‚
â”‚      - å¯¹æœ€ç»ˆç”Ÿæˆè´¨é‡å‡ ä¹æ²¡æœ‰å¯è§å½±å“                                        â”‚
â”‚                                                                             â”‚
â”‚   3. âš ï¸ å†…å­˜è®¿é—®å±€éƒ¨æ€§ç•¥å·®                                                  â”‚
â”‚      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚      è¿ç»­è®¿é—®æœ‰æ•ˆ tokens æ—¶:                                                 â”‚
â”‚      - é‡æ’å: æœ‰æ•ˆ tokens è¿ç»­ï¼Œç¼“å­˜å‘½ä¸­ç‡é«˜                                â”‚
â”‚      - ç›´æ¥æ‹¼æ¥: å¯èƒ½è·¨è¶Š padding åŒºåŸŸ                                       â”‚
â”‚                                                                             â”‚
â”‚      å½±å“ç¨‹åº¦: â­â˜†â˜† (ç°ä»£ç¡¬ä»¶å½±å“å¾ˆå°)                                       â”‚
â”‚      - TPU çš„ HBM å¸¦å®½å¾ˆé«˜                                                   â”‚
â”‚      - Transformer ä¸»è¦ç“¶é¢ˆåœ¨è®¡ç®—ä¸æ˜¯å†…å­˜                                    â”‚
â”‚                                                                             â”‚
â”‚   ã€ç»“è®ºï¼šæ–¹æ¡ˆ3 æ˜¯ TPU æœ€ä½³é€‰æ‹©ã€‘                                            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚                                                                             â”‚
â”‚   æƒè¡¡å¯¹æ¯”:                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚ æ–¹æ¡ˆ         â”‚ TPU å…¼å®¹æ€§ â”‚ æ•ˆç‡æŸå¤±  â”‚ å®ç°å¤æ‚åº¦ â”‚ æ¨è  â”‚         â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚   â”‚ åŸå§‹é‡æ’     â”‚ âŒ ä¸å…¼å®¹   â”‚ æ—         â”‚ å¤æ‚      â”‚       â”‚         â”‚
â”‚   â”‚ CPU é¢„è®¡ç®—   â”‚ âš ï¸ éœ€åŒæ­¥   â”‚ åŒæ­¥å¼€é”€  â”‚ ä¸­ç­‰      â”‚       â”‚         â”‚
â”‚   â”‚ æ–¹æ¡ˆ3 ç›´æ¥æ‹¼æ¥â”‚ âœ… å®Œç¾    â”‚ æå°      â”‚ ç®€å•      â”‚ âœ…    â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                             â”‚
â”‚   å®é™…å½±å“:                                                                  â”‚
â”‚   - ç”Ÿæˆè´¨é‡: å‡ ä¹æ— å·®å¼‚ï¼ˆæ•°å­¦ä¸Šç­‰ä»·ï¼‰                                       â”‚
â”‚   - æ¨ç†é€Ÿåº¦: å¯èƒ½æ…¢ 1-5%ï¼ˆå–å†³äº SSTA é…ç½®ï¼‰                                â”‚
â”‚   - ä»£ç ç»´æŠ¤: æ˜¾è‘—æ›´ç®€å•                                                     â”‚
â”‚                                                                             â”‚
â”‚   å»ºè®®:                                                                      â”‚
â”‚   ```python                                                                 â”‚
â”‚   # TPU ç‰ˆæœ¬çš„ reorder_txt_token                                            â”‚
â”‚   def reorder_txt_token_tpu(byt5_txt, txt, byt5_mask, text_mask):           â”‚
â”‚       # ç®€å•æ‹¼æ¥ï¼Œä¸é‡æ’                                                     â”‚
â”‚       combined_txt = torch.cat([byt5_txt, txt], dim=1)                      â”‚
â”‚       combined_mask = torch.cat([byt5_mask, text_mask], dim=1)              â”‚
â”‚                                                                             â”‚
â”‚       # ç¡®ä¿ padding ä½ç½®çš„å€¼ä¸º 0ï¼ˆå‡å°‘ block attention è¯¯å·®ï¼‰              â”‚
â”‚       combined_txt = combined_txt * combined_mask.unsqueeze(-1)             â”‚
â”‚                                                                             â”‚
â”‚       return combined_txt, combined_mask                                    â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ ã€å¥½é—®é¢˜ï¼šæ‹¼æ¥åå¦‚ä½•åŒºåˆ† ByT5 å’Œ LLaVAï¼Ÿ+ ä¸ºä»€ä¹ˆ ByT5 æ”¾å‰é¢ï¼Ÿã€‘              â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                             â”‚
â”‚ ã€Q1: æ‹¼æ¥åæ€ä¹ˆçŸ¥é“å“ªä¸ªæ˜¯ ByT5ï¼Œå“ªä¸ªæ˜¯ LLaVAï¼Ÿã€‘                            â”‚
â”‚                                                                             â”‚
â”‚   ç­”æ¡ˆï¼šé€šè¿‡ cond_type_embedding åŒºåˆ†ï¼                                      â”‚
â”‚                                                                             â”‚
â”‚   æºç ç¬¬ 551-559 è¡Œå®šä¹‰ï¼š                                                   â”‚
â”‚   ```python                                                                 â”‚
â”‚   if use_cond_type_embedding:                                               â”‚
â”‚       self.cond_type_embedding = nn.Embedding(3, self.hidden_size)          â”‚
â”‚       self.cond_type_embedding.weight.data.fill_(0)                         â”‚
â”‚       # 0: text_encoder feature (LLaVA)                                     â”‚
â”‚       # 1: byt5 feature                                                     â”‚
â”‚       # 2: vision_encoder feature                                           â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   å®é™…ä½¿ç”¨ï¼ˆæºç ç¬¬ 745-759 è¡Œï¼‰ï¼š                                           â”‚
â”‚   ```python                                                                 â”‚
â”‚   # ç»™ LLaVA tokens æ·»åŠ  type=0 çš„ embedding                                â”‚
â”‚   if self.cond_type_embedding is not None:                                  â”‚
â”‚       cond_emb = self.cond_type_embedding(                                  â”‚
â”‚           torch.zeros_like(txt[:, :, 0], dtype=torch.long)  # type=0       â”‚
â”‚       )                                                                     â”‚
â”‚       txt = txt + cond_emb                                                  â”‚
â”‚                                                                             â”‚
â”‚   # ç»™ ByT5 tokens æ·»åŠ  type=1 çš„ embedding                                 â”‚
â”‚   if self.glyph_byT5_v2:                                                    â”‚
â”‚       byt5_txt = self.byt5_in(byt5_text_states)                             â”‚
â”‚       if self.cond_type_embedding is not None:                              â”‚
â”‚           cond_emb = self.cond_type_embedding(                              â”‚
â”‚               torch.ones_like(byt5_txt[:, :, 0], dtype=torch.long)  # type=1â”‚
â”‚           )                                                                 â”‚
â”‚           byt5_txt = byt5_txt + cond_emb                                    â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   å·¥ä½œåŸç†ï¼š                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  åŸå§‹                                                                 â”‚  â”‚
â”‚   â”‚  ByT5 tokens: [b1, b2, b3, ...]     shape: (256, 3072)               â”‚  â”‚
â”‚   â”‚  LLaVA tokens: [l1, l2, l3, ...]    shape: (1000, 3072)              â”‚  â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚   â”‚  æ·»åŠ  type embedding å                                               â”‚  â”‚
â”‚   â”‚  ByT5 tokens: [b1+E1, b2+E1, b3+E1, ...]   (E1 = type 1 embedding)   â”‚  â”‚
â”‚   â”‚  LLaVA tokens: [l1+E0, l2+E0, l3+E0, ...]  (E0 = type 0 embedding)   â”‚  â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚   â”‚  æ‹¼æ¥å                                                               â”‚  â”‚
â”‚   â”‚  [b1+E1, b2+E1, ..., l1+E0, l2+E0, ...]                              â”‚  â”‚
â”‚   â”‚   â†‘ éšå¼æºå¸¦äº†ç±»å‹ä¿¡æ¯ï¼ŒTransformer å¯ä»¥å­¦ä¹ åŒºåˆ†                      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚   è¿™æ · Transformer å°±èƒ½é€šè¿‡å­¦ä¹ åˆ°çš„ type embedding å·®å¼‚æ¥åŒºåˆ†ä¸åŒæ¥æºï¼     â”‚
â”‚                                                                             â”‚
â”‚ ã€Q2: ä¸ºä»€ä¹ˆ ByT5 æ”¾åœ¨å‰é¢ï¼Ÿã€‘                                               â”‚
â”‚                                                                             â”‚
â”‚   åŸå›  1: æ³¨æ„åŠ›æ•ˆç‡ä¼˜åŒ–                                                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚   ByT5 tokens é€šå¸¸æ›´çŸ­ï¼ˆ256 vs 1000ï¼‰ä½†æ›´"å¯†é›†"ï¼ˆå­—ç¬¦çº§ç‰¹å¾ï¼‰               â”‚
â”‚                                                                             â”‚
â”‚   å¯¹äº SSTA (Sparse Attention) çš„ importance samplingï¼š                     â”‚
â”‚   - çŸ­ä¸”å¯†é›†çš„ç‰¹å¾æ”¾å‰é¢ â†’ topk é‡‡æ ·æ›´å®¹æ˜“å‘½ä¸­                              â”‚
â”‚   - å¦‚æœæ”¾åé¢ï¼Œè¢«ç¨€ç–é‡‡æ ·è·³è¿‡çš„æ¦‚ç‡æ›´é«˜                                    â”‚
â”‚                                                                             â”‚
â”‚   åŸå›  2: Block Attention çš„è¾¹ç•Œå¯¹é½                                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚   å‡è®¾ block_size = 64ï¼š                                                    â”‚
â”‚                                                                             â”‚
â”‚   ByT5 åœ¨å‰ï¼ˆ256 tokensï¼‰ï¼š                                                  â”‚
â”‚     Block 0-3: çº¯ ByT5 (64Ã—4 = 256)                                         â”‚
â”‚     Block 4+:  LLaVA                                                        â”‚
â”‚     â†’ ç±»å‹è¾¹ç•Œæ­£å¥½åœ¨ block è¾¹ç•Œï¼                                           â”‚
â”‚                                                                             â”‚
â”‚   ByT5 åœ¨åï¼š                                                                â”‚
â”‚     Block 15: [...llavaå°¾éƒ¨, byt5å¼€å¤´...]                                   â”‚
â”‚     â†’ ç±»å‹è¾¹ç•Œåœ¨ block å†…éƒ¨ï¼Œå¯èƒ½å¢åŠ è¯¯å·®                                   â”‚
â”‚                                                                             â”‚
â”‚   åŸå›  3: ç¼“å­˜å‹å¥½æ€§                                                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚   çŸ­åºåˆ—æ”¾å‰é¢ â†’ æ›´å¿«è¢«åŠ è½½åˆ°ç¼“å­˜                                           â”‚
â”‚   å­—ç¬¦çº§ç‰¹å¾å¯èƒ½æ›´å¸¸è¢« attention è®¿é—®                                       â”‚
â”‚                                                                             â”‚
â”‚   åŸå›  4: ä¹Ÿå¯èƒ½åªæ˜¯è®¾è®¡é€‰æ‹©                                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚   å¯¹äº self-attentionï¼Œç†è®ºä¸Šé¡ºåºä¸å½±å“ç»“æœï¼š                               â”‚
â”‚   - ä½ç½®ä¿¡æ¯é€šè¿‡ RoPE (Rotary Position Embedding) ç¼–ç                       â”‚
â”‚   - RoPE åªåº”ç”¨äºè§†é¢‘ tokensï¼Œæ–‡æœ¬ tokens ä¸å¸¦ä½ç½®ç¼–ç                       â”‚
â”‚   - æ‰€ä»¥ [ByT5, LLaVA] å’Œ [LLaVA, ByT5] æ•°å­¦ä¸Šç­‰ä»·                         â”‚
â”‚                                                                             â”‚
â”‚   ä½†ä¸€æ—¦é€‰å®šé¡ºåºï¼Œå°±éœ€è¦ä¿æŒä¸€è‡´ï¼ˆå› ä¸ºæ¨¡å‹æ˜¯è¿™æ ·è®­ç»ƒçš„ï¼‰                     â”‚
â”‚                                                                             â”‚
â”‚ ã€è¡¥å……ï¼šå¦‚æœæ²¡æœ‰ cond_type_embedding ä¼šæ€æ ·ï¼Ÿã€‘                              â”‚
â”‚                                                                             â”‚
â”‚   æŸ¥çœ‹é…ç½®ï¼š                                                                 â”‚
â”‚   ```python                                                                 â”‚
â”‚   use_cond_type_embedding: bool = False,  # é»˜è®¤æ˜¯å…³é—­çš„ï¼                  â”‚
â”‚   ```                                                                       â”‚
â”‚                                                                             â”‚
â”‚   å¦‚æœå…³é—­ï¼ŒTransformer ä»ç„¶å¯ä»¥å·¥ä½œï¼Œå› ä¸ºï¼š                                 â”‚
â”‚   1. ByT5 å’Œ LLaVA ä½¿ç”¨ä¸åŒçš„æŠ•å½±å±‚ï¼š                                       â”‚
â”‚      - LLaVA â†’ self.txt_in (SingleTokenRefiner)                             â”‚
â”‚      - ByT5 â†’ self.byt5_in (ByT5Mapper)                                     â”‚
â”‚   2. æŠ•å½±åçš„ç‰¹å¾ç©ºé—´åˆ†å¸ƒä¸åŒï¼ŒTransformer å¯ä»¥éšå¼å­¦ä¹ åŒºåˆ†                  â”‚
â”‚   3. ä½†æ•ˆæœå¯èƒ½ä¸å¦‚æ˜¾å¼ type embedding                                      â”‚
â”‚                                                                             â”‚
â”‚   åœ¨å®è·µä¸­ï¼Œtype embedding å¯¹äº i2v (Image-to-Video) æ›´é‡è¦ï¼š               â”‚
â”‚   - éœ€è¦åŒºåˆ† text tokens å’Œ vision tokens                                   â”‚
â”‚   - vision tokens ç”¨ type=2                                                 â”‚
â”‚                                                                             â”‚
â”‚                                                                             â”‚
â”‚ ã€å…·ä½“ä»£ç æµç¨‹ã€‘                                                             â”‚
â”‚                                                                             â”‚
â”‚   1. CFG å‡†å¤‡ï¼ˆåœ¨æ¨ç†å¾ªç¯ä¹‹å‰ï¼‰:                                              â”‚
â”‚      ```python                                                              â”‚
â”‚      # åˆå¹¶æ­£å‘å’Œè´Ÿå‘ embeddings                                             â”‚
â”‚      prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])     â”‚
â”‚      # shape: (2, 1000, 3584)                                               â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   2. ByT5 embeddings æ‰“åŒ…:                                                   â”‚
â”‚      ```python                                                              â”‚
â”‚      extra_kwargs = {                                                       â”‚
â”‚          "byt5_text_states": byt5_text_states,  # (2, 256, 1472)            â”‚
â”‚          "byt5_text_mask": byt5_text_mask,      # (2, 256)                  â”‚
â”‚      }                                                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚   3. Transformer è°ƒç”¨:                                                       â”‚
â”‚      ```python                                                              â”‚
â”‚      output = transformer(                                                  â”‚
â”‚          latent_model_input,      # è§†é¢‘ latents                            â”‚
â”‚          t_expand,                # æ—¶é—´æ­¥                                  â”‚
â”‚          prompt_embeds,           # LLaVA embeddings (ä¸»é€šé“)               â”‚
â”‚          prompt_embeds_2,         # è§ä¸‹æ–¹è¯¦è§£ â†“                            â”‚
â”‚          prompt_mask,             # LLaVA æ³¨æ„åŠ› mask                       â”‚
â”‚          ...                                                                â”‚
â”‚          extra_kwargs=extra_kwargs,  # ByT5 embeddings åœ¨è¿™é‡Œï¼             â”‚
â”‚      )                                                                      â”‚
â”‚      ```                                                                    â”‚
â”‚                                                                             â”‚
â”‚ ã€å…³äº prompt_embeds_2 å‚æ•°çš„å›°æƒ‘è§£ç­”ã€‘                                       â”‚
â”‚                                                                             â”‚
â”‚   è¿™ä¸ªå‘½åç¡®å®å®¹æ˜“æ··æ·†ï¼è®©æˆ‘æ¾„æ¸…ï¼š                                            â”‚
â”‚                                                                             â”‚
â”‚   prompt_embeds_2 (Transformer çš„ç¬¬4ä¸ªå‚æ•°):                                 â”‚
â”‚   â”œâ”€ è¿™æ˜¯ Transformer æ¥å£é¢„ç•™çš„è¾…åŠ©æ–‡æœ¬å‚æ•°ä½ç½®                             â”‚
â”‚   â”œâ”€ è®¾è®¡ç”¨äº CLIP æˆ–å…¶ä»–è¾…åŠ© text encoderï¼ˆé ByT5ï¼‰                        â”‚
â”‚   â”œâ”€ å¯¹äº 720p_t2v ç‰ˆæœ¬ï¼šè®¾ä¸º Noneï¼Œä¸ä½¿ç”¨                                   â”‚
â”‚   â””â”€ å¯¹äºå…¶ä»–ç‰ˆæœ¬ï¼ˆå¦‚ 1080pï¼‰ï¼šå¯èƒ½ä½¿ç”¨ CLIP embeddings                       â”‚
â”‚                                                                             â”‚
â”‚   extra_kwargs["byt5_text_states"] (ByT5 embeddings):                        â”‚
â”‚   â”œâ”€ è¿™æ‰æ˜¯ ByT5 çš„ embeddingsï¼                                            â”‚
â”‚   â”œâ”€ é€šè¿‡ extra_kwargs å­—å…¸ä¼ å…¥ï¼ˆä¸æ˜¯ä½ç½®å‚æ•°ï¼‰                               â”‚
â”‚   â”œâ”€ å‘½åä¸º byt5_text_states è€Œé prompt_embeds_2                            â”‚
â”‚   â””â”€ åœ¨ Transformer å†…éƒ¨ä¼šè¢«ç‰¹æ®Šå¤„ç†                                         â”‚
â”‚                                                                             â”‚
â”‚   ä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡ï¼Ÿ                                                           â”‚
â”‚   â”œâ”€ HunyuanVideo æ”¯æŒå¤šç§é…ç½®å’Œç‰ˆæœ¬                                         â”‚
â”‚   â”œâ”€ prompt_embeds_2 æ˜¯ç»™ CLIP ç­‰é¢„ç•™çš„"æ ‡å‡†"ä½ç½®                            â”‚
â”‚   â”œâ”€ ByT5 æ˜¯åæ¥æ·»åŠ çš„ç‰¹æ€§ï¼Œç”¨ extra_kwargs æ›´çµæ´»                           â”‚
â”‚   â””â”€ è¿™æ ·ä¸åŒç‰ˆæœ¬å¯ä»¥çµæ´»ç»„åˆä½¿ç”¨å“ªäº› text encoder                            â”‚
â”‚                                                                             â”‚
â”‚   å®é™…ä½¿ç”¨çš„ Text Encoder ç»„åˆ:                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚ ç‰ˆæœ¬            â”‚ ä¸» Text Encoder      â”‚ è¾…åŠ© Text Encoder   â”‚            â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚   â”‚ 720p_t2v       â”‚ LLaVA               â”‚ ByT5 (via extra)    â”‚            â”‚
â”‚   â”‚ 720p_i2v       â”‚ LLaVA               â”‚ ByT5 (via extra)    â”‚            â”‚
â”‚   â”‚ æŸäº›å…¶ä»–ç‰ˆæœ¬    â”‚ LLaVA               â”‚ CLIP (via param)    â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                             â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸¤ç§ Embedding çš„ä½œç”¨åˆ†å·¥ã€‘                                                 â”‚
â”‚                                                                             â”‚
â”‚   LLaVA (ä¸»):                                                                â”‚
â”‚   â”œâ”€ æä¾›é«˜å±‚è¯­ä¹‰ç†è§£                                                        â”‚
â”‚   â”œâ”€ "ä¸€åªçŒ«åœ¨èŠ±å›­é‡Œèµ°" â†’ ç†è§£åœºæ™¯ã€åŠ¨ä½œã€ä¸»ä½“                                â”‚
â”‚   â””â”€ ä¸»å¯¼è§†é¢‘çš„æ•´ä½“å†…å®¹ç”Ÿæˆ                                                  â”‚
â”‚                                                                             â”‚
â”‚   ByT5 (è¾…åŠ©):                                                               â”‚
â”‚   â”œâ”€ æä¾›å­—ç¬¦çº§åˆ«çš„ç²¾ç¡®ç†è§£                                                  â”‚
â”‚   â”œâ”€ å¸®åŠ©å‡†ç¡®æ¸²æŸ“æ–‡å­—ã€ç¬¦å·ã€å“ç‰Œåç­‰                                        â”‚
â”‚   â””â”€ ä¿®æ­£ LLM å¯èƒ½é—æ¼çš„ç»†èŠ‚                                                 â”‚
â”‚                                                                             â”‚
â”‚ ã€ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ç§ Embeddingï¼Ÿã€‘                                                â”‚
â”‚                                                                             â”‚
â”‚   å•çº¯ä½¿ç”¨ LLM çš„é—®é¢˜:                                                       â”‚
â”‚   - LLM ä»¥ token ä¸ºå•ä½ï¼Œå¯èƒ½ä¸¢å¤±å­—ç¬¦çº§ç»†èŠ‚                                   â”‚
â”‚   - ä¾‹å¦‚ "COCA-COLA" å¯èƒ½è¢«ç†è§£ä¸º"å¯ä¹å“ç‰Œ"ï¼Œä½†æ‹¼å†™å¯èƒ½æ¨¡ç³Š                   â”‚
â”‚                                                                             â”‚
â”‚   åŠ å…¥ ByT5 çš„å¥½å¤„:                                                          â”‚
â”‚   - æŒ‰å­—èŠ‚å¤„ç†ï¼Œä¿ç•™ç²¾ç¡®çš„å­—ç¬¦ä¿¡æ¯                                            â”‚
â”‚   - ç‰¹åˆ«é€‚åˆ: æ–‡å­—æ¸²æŸ“ã€ç‰¹å®šç¬¦å·ã€ä¸­æ–‡/æ—¥æ–‡ç­‰å¤æ‚å­—ç¬¦                          â”‚
â”‚                                                                             â”‚
â”‚   ä¸¤è€…ç»“åˆ = è¯­ä¹‰ç†è§£ + å­—ç¬¦ç²¾ç¡®æ€§                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Transformer / DiT (æ‰©æ•£å˜æ¢å™¨) â† å½“å‰æ–‡ä»¶                            â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ è¾“å…¥:                                                                        â”‚
â”‚   - Stage 1 çš„ text embeddings                                              â”‚
â”‚   - éšæœºå™ªå£° latents                                                         â”‚
â”‚                                                                             â”‚
â”‚ è¾“å‡º: å»å™ªåçš„ latents (è§†é¢‘çš„æ½œåœ¨ç©ºé—´è¡¨ç¤º)                                    â”‚
â”‚                                                                             â”‚
â”‚ æ ¸å¿ƒè¿‡ç¨‹: æ‰©æ•£å»å™ª (Diffusion Denoising)                                     â”‚
â”‚   é€šè¿‡å¤šæ­¥è¿­ä»£ï¼Œé€æ¸å°†éšæœºå™ªå£°è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„è§†é¢‘ latents                         â”‚
â”‚                                                                             â”‚
â”‚ å†…å­˜éœ€æ±‚: ~40GB+ (è¿™æ˜¯è®¡ç®—æœ€å¯†é›†çš„é˜¶æ®µ)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: VAE Decoder (å˜åˆ†è‡ªç¼–ç å™¨è§£ç )                                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ è¾“å…¥: Stage 2 çš„å»å™ª latents                                                 â”‚
â”‚ è¾“å‡º: å®é™…çš„è§†é¢‘å¸§ (RGB åƒç´ )                                                 â”‚
â”‚                                                                             â”‚
â”‚ ä½¿ç”¨æ¨¡å‹: VAE Decoder                                                        â”‚
â”‚   å°† latent ç©ºé—´çš„è¡¨ç¤ºè§£ç å›åƒç´ ç©ºé—´                                           â”‚
â”‚                                                                             â”‚
â”‚ å†…å­˜éœ€æ±‚: ~5-8GB                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
ğŸ¯ ä¸ºä»€ä¹ˆè¦åˆ†é˜¶æ®µï¼Ÿ
================================================================================

1. **å†…å­˜ä¼˜åŒ–**: 
   - å®Œæ•´ pipeline éœ€è¦åŒæ—¶åŠ è½½æ‰€æœ‰æ¨¡å‹ (>60GB)
   - åˆ†é˜¶æ®µå¯ä»¥åœ¨æ¯ä¸ªé˜¶æ®µç»“æŸåé‡Šæ”¾å†…å­˜
   - å¯¹äºæ˜¾å­˜æœ‰é™çš„ GPU å°¤å…¶é‡è¦

2. **çµæ´»æ€§**:
   - å¯ä»¥ä¸ºä¸åŒé˜¶æ®µä½¿ç”¨ä¸åŒçš„ç¡¬ä»¶ (å¦‚ TPU for Stage 1, GPU for Stage 2)
   - å¯ä»¥ç¼“å­˜ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
   - ä¾¿äºè°ƒè¯•å’Œå¼€å‘

3. **å¯æ‰©å±•æ€§**:
   - å¯ä»¥å¯¹åŒä¸€ä¸ª text embedding å°è¯•ä¸åŒçš„æ¨ç†å‚æ•°
   - å¯ä»¥æ‰¹é‡å¤„ç†å¤šä¸ª prompt

================================================================================
ğŸ”¬ æ ¸å¿ƒæ¦‚å¿µè§£é‡Š
================================================================================

1. **Latent Space (æ½œåœ¨ç©ºé—´)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   è§†é¢‘ä¸æ˜¯ç›´æ¥åœ¨åƒç´ ç©ºé—´ç”Ÿæˆçš„ï¼Œè€Œæ˜¯åœ¨ä¸€ä¸ªå‹ç¼©çš„"æ½œåœ¨ç©ºé—´"ä¸­ç”Ÿæˆã€‚
   
   åŸå§‹è§†é¢‘: (T, H, W, 3) â†’ VAE ç¼–ç  â†’ Latent: (T/4, H/16, W/16, C)
   
   è¿™å¤§å¤§å‡å°‘äº†è®¡ç®—é‡ï¼š
   - 720p è§†é¢‘ (1280x720) â†’ Latent (80x45)
   - æ—¶é—´ç»´åº¦ä¹Ÿå‹ç¼© 4 å€

2. **DiT (Diffusion Transformer)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   DiT æ˜¯ä¸€ç§ä½¿ç”¨ Transformer æ¶æ„çš„æ‰©æ•£æ¨¡å‹ï¼š
   
   ä¼ ç»Ÿ U-Net:  ä½¿ç”¨å·ç§¯å±‚ï¼Œå¯¹å›¾åƒç‰¹å¾è¿›è¡Œå¤„ç†
   DiT:         ä½¿ç”¨ Transformerï¼Œå°†å›¾åƒ/è§†é¢‘ patch åŒ–åç”¨æ³¨æ„åŠ›æœºåˆ¶å¤„ç†
   
   HunyuanVideo-1.5 ä½¿ç”¨çš„æ˜¯ä¸“é—¨ä¸ºè§†é¢‘è®¾è®¡çš„ DiTï¼š
   - æ”¯æŒ 3D æ³¨æ„åŠ› (æ—¶é—´ + ç©ºé—´)
   - æ”¯æŒå¤šç§ä»»åŠ¡ (t2v, i2v)

3. **Flow Matching (æµåŒ¹é…)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   è¿™æ˜¯ä¸€ç§æ›¿ä»£ä¼ ç»Ÿ DDPM çš„æ‰©æ•£è®­ç»ƒæ–¹æ³•ï¼š
   
   DDPM: é¢„æµ‹å™ªå£° Îµ
   Flow Matching: é¢„æµ‹ä»å™ªå£°åˆ°æ•°æ®çš„"æµ"å‘é‡
   
   ä¼˜ç‚¹ï¼š
   - è®­ç»ƒæ›´ç¨³å®š
   - æ¨ç†å¯ä»¥ç”¨æ›´å°‘çš„æ­¥æ•°
   - æ”¯æŒæ›´çµæ´»çš„è°ƒåº¦å™¨

4. **CFG (Classifier-Free Guidanceï¼Œæ— åˆ†ç±»å™¨å¼•å¯¼)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   CFG æ˜¯æé«˜ç”Ÿæˆè´¨é‡çš„å…³é”®æŠ€æœ¯ï¼š
   
   åŸç†ï¼š
   - åŒæ—¶è¿è¡Œä¸¤æ¬¡æ¨ç†ï¼šæœ‰æ¡ä»¶ï¼ˆwith textï¼‰å’Œæ— æ¡ä»¶ï¼ˆwithout textï¼‰
   - æœ€ç»ˆé¢„æµ‹ = æ— æ¡ä»¶é¢„æµ‹ + guidance_scale Ã— (æœ‰æ¡ä»¶é¢„æµ‹ - æ— æ¡ä»¶é¢„æµ‹)
   
   ä»£ç ä½“ç°ï¼š
   ```python
   noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)
   ```
   
   guidance_scale å‚æ•°ï¼š
   - å…¸å‹å€¼: 1.0 - 15.0
   - è¶Šé«˜ â†’ è¶Šç¬¦åˆ promptï¼Œä½†å¯èƒ½è¿‡æ‹Ÿåˆ
   - è¶Šä½ â†’ è¶Šè‡ªç„¶ï¼Œä½†å¯èƒ½åç¦» prompt

5. **Meanflow (å‡å€¼æµ)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   HunyuanVideo-1.5 çš„ç‹¬ç‰¹è®¾è®¡ï¼Œç”¨äºæ”¹å–„è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§ã€‚
   
   åœ¨æ¯ä¸ªå»å™ªæ­¥éª¤ï¼š
   - ä¸ä»…è€ƒè™‘å½“å‰æ—¶é—´æ­¥ t
   - è¿˜è€ƒè™‘ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ t_r (timestep_r)
   - è¿™æœ‰åŠ©äºå¹³æ»‘è§†é¢‘ä¸­çš„å¸§é—´è¿‡æ¸¡

6. **Sequence Parallelism (SPï¼Œåºåˆ—å¹¶è¡Œ)**
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   å¤š GPU å¹¶è¡Œç­–ç•¥ï¼š
   
   - å°†è§†é¢‘çš„æ—¶é—´åºåˆ—åˆ†å‰²åˆ°å¤šä¸ª GPU
   - æ¯ä¸ª GPU å¤„ç†ä¸€éƒ¨åˆ†å¸§
   - é€šè¿‡é€šä¿¡åŒæ­¥æ³¨æ„åŠ›è®¡ç®—
   
   è¿™ä½¿å¾—å¯ä»¥ç”Ÿæˆæ›´é•¿çš„è§†é¢‘

================================================================================
ğŸ“¦ æœ¬æ–‡ä»¶çš„ç»“æ„
================================================================================

1. æ¨¡å—åˆå§‹åŒ–
   â”œâ”€â”€ å¹¶è¡ŒçŠ¶æ€åˆå§‹åŒ– (parallel_state)
   â””â”€â”€ CUDA è®¾å¤‡è®¾ç½®

2. è¾…åŠ©å‡½æ•°
   â”œâ”€â”€ get_latent_size()     - è®¡ç®— latent å°ºå¯¸
   â”œâ”€â”€ get_task_mask()       - è·å–ä»»åŠ¡ç±»å‹ mask
   â”œâ”€â”€ prepare_latents()     - å‡†å¤‡éšæœºå™ªå£°
   â”œâ”€â”€ prepare_cond_latents() - å‡†å¤‡æ¡ä»¶ latents
   â””â”€â”€ get_closest_resolution() - è®¡ç®—æœ€ä½³åˆ†è¾¨ç‡

3. main() ä¸»å‡½æ•°
   â”œâ”€â”€ å‚æ•°è§£æ
   â”œâ”€â”€ åŠ è½½ Stage 1 ç»“æœ
   â”œâ”€â”€ åŠ è½½ Transformer
   â”œâ”€â”€ åˆå§‹åŒ– Scheduler
   â”œâ”€â”€ å‡†å¤‡è¾“å…¥å¼ é‡
   â”œâ”€â”€ Denoising Loop (æ ¸å¿ƒï¼)
   â””â”€â”€ ä¿å­˜è¾“å‡º

================================================================================
å…³é”®ä¿®å¤è¯´æ˜ï¼šæœ¬æ–‡ä»¶ç›´æ¥åŠ è½½ transformerï¼Œä¸ä½¿ç”¨ create_pipeline
é¿å…åŠ è½½ä¸éœ€è¦çš„ç»„ä»¶ï¼ˆtext encoder 14GBï¼‰å¯¼è‡´ OOM

ç”¨äº GPU H100 8å¡ç¯å¢ƒ
================================================================================
"""

import os
import sys

# ============================================================================
# ğŸ”§ æ¨¡å—çº§åˆ«åˆå§‹åŒ– - å¹¶è¡ŒçŠ¶æ€
# ============================================================================
# 
# ã€ä¸ºä»€ä¹ˆå¿…é¡»åœ¨æ¨¡å—çº§åˆ«åˆå§‹åŒ–ï¼Ÿã€‘
# 
# HunyuanVideo ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†ï¼Œéœ€è¦åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰è®¾ç½®å¥½å¹¶è¡ŒçŠ¶æ€ã€‚
# è¿™æ˜¯å› ä¸ºï¼š
# 1. æŸäº›æ¨¡å—ï¼ˆå¦‚ attentionï¼‰åœ¨å¯¼å…¥æ—¶ä¼šæ£€æŸ¥å¹¶è¡ŒçŠ¶æ€
# 2. CUDA è®¾å¤‡å¿…é¡»åœ¨ä»»ä½•å¼ é‡æ“ä½œä¹‹å‰è®¾ç½®
# 
# å®˜æ–¹ generate.py ç¬¬ 37-38 è¡Œå°±æ˜¯è¿™æ ·åšçš„ï¼š
#   parallel_dims = initialize_parallel_state(sp=int(os.environ.get('WORLD_SIZE', '1')))
#   torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', '0')))
#
# ã€ç¯å¢ƒå˜é‡è¯´æ˜ã€‘
# 
# WORLD_SIZE: æ€»è¿›ç¨‹æ•°ï¼ˆGPU æ•°é‡ï¼‰
# LOCAL_RANK: å½“å‰è¿›ç¨‹åœ¨æœ¬æœºçš„æ’åï¼ˆ0, 1, 2, ...ï¼‰
# RANK: å…¨å±€æ’å
# 
# å¯¹äºå• GPU: WORLD_SIZE=1, LOCAL_RANK=0, RANK=0
# å¯¹äº 8 GPU: WORLD_SIZE=8, LOCAL_RANK=0-7, RANK=0-7
# ============================================================================

# è®¾ç½® PyTorch CUDA å†…å­˜åˆ†é…ç­–ç•¥
# expandable_segments:True å…è®¸å†…å­˜æ®µåŠ¨æ€æ‰©å±•ï¼Œå‡å°‘ç¢ç‰‡åŒ–
if 'PYTORCH_CUDA_ALLOC_CONF' not in os.environ:
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# æ·»åŠ  HunyuanVideo-1.5-TPU åˆ° Python è·¯å¾„
# è¿™æ ·æˆ‘ä»¬æ‰èƒ½å¯¼å…¥ hyvideo æ¨¡å—
HUNYUAN_ROOT = os.path.expanduser("~/HunyuanVideo-1.5-TPU")
if HUNYUAN_ROOT not in sys.path:
    sys.path.insert(0, HUNYUAN_ROOT)

import torch
from hyvideo.commons.parallel_states import initialize_parallel_state

# ã€å…³é”®ã€‘æ¨¡å—çº§åˆ«åˆå§‹åŒ–å¹¶è¡ŒçŠ¶æ€
# sp å‚æ•°: Sequence Parallelism çš„å¹¶è¡Œåº¦ï¼ˆç­‰äº WORLD_SIZEï¼‰
parallel_dims = initialize_parallel_state(sp=int(os.environ.get('WORLD_SIZE', '1')))

# ã€å…³é”®ã€‘è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„ GPU
# LOCAL_RANK å†³å®šäº†å“ªä¸ª GPU
torch.cuda.set_device(int(os.environ.get('LOCAL_RANK', '0')))

# ç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯¼å…¥å…¶ä»–æ¨¡å—äº†
import time
import random
import argparse
import atexit
from types import SimpleNamespace
import numpy as np
from PIL import Image
from torch import distributed as dist

# ============================================================================
# ğŸ“¦ å¯¼å…¥æ ¸å¿ƒç»„ä»¶
# ============================================================================
# 
# ã€ä¸ºä»€ä¹ˆç›´æ¥å¯¼å…¥ Transformer è€Œä¸ç”¨ create_pipelineï¼Ÿã€‘
# 
# create_pipeline ä¼šåŠ è½½å®Œæ•´çš„ pipelineï¼ŒåŒ…æ‹¬ï¼š
# - Text Encoder (LLaVA): ~14GB
# - Text Encoder 2 (ByT5): ~5GB  
# - Transformer: ~13GB
# - VAE: ~1GB
# 
# ä½†æˆ‘ä»¬åªéœ€è¦ Transformerï¼å…¶ä»–ç»„ä»¶åœ¨ Stage 1 å’Œ Stage 3 ä½¿ç”¨ã€‚
# ç›´æ¥åŠ è½½ Transformer å¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ã€‚
# ============================================================================

# HunyuanVideo-1.5 çš„ DiT (Diffusion Transformer)
from hyvideo.models.transformers.hunyuanvideo_1_5_transformer import HunyuanVideo_1_5_DiffusionTransformer

# Flow Matching è°ƒåº¦å™¨
from hyvideo.schedulers.scheduling_flow_match_discrete import FlowMatchDiscreteScheduler

# æ¨ç†çŠ¶æ€ï¼ˆç”¨äºæ§åˆ¶ç¼“å­˜ã€ç¼–è¯‘ç­‰ä¼˜åŒ–ï¼‰
from hyvideo.commons.infer_state import initialize_infer_state

# å·¥å…·å‡½æ•°
from hyvideo.commons import auto_offload_model, PIPELINE_CONFIGS
from hyvideo.commons.parallel_states import get_parallel_state
from hyvideo.utils.multitask_utils import merge_tensor_by_mask

# æˆ‘ä»¬è‡ªå®šä¹‰çš„å·¥å…·å‡½æ•°ï¼ˆç”¨äº Stage é—´æ•°æ®ä¼ é€’ï¼‰
from utils import (
    load_embeddings_from_safetensors,
    save_latents_to_safetensors,
    load_generation_config,
    save_generation_config,
    get_default_paths,
)

# ============================================================================
# ğŸ§¹ æ³¨å†Œæ¸…ç†å‡½æ•°
# ============================================================================
# 
# åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†éœ€è¦åœ¨ç¨‹åºç»“æŸæ—¶æ­£ç¡®å…³é—­è¿›ç¨‹ç»„
# atexit.register ç¡®ä¿å³ä½¿ç¨‹åºå´©æºƒä¹Ÿä¼šæ‰§è¡Œæ¸…ç†
# ============================================================================

def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è¿›ç¨‹ç»„ï¼Œé¿å…åƒµå°¸è¿›ç¨‹"""
    if dist.is_initialized():
        dist.destroy_process_group()

atexit.register(cleanup_distributed)


# ============================================================================
# ğŸ› ï¸ è¾…åŠ©å‡½æ•°ï¼šè·å–è¿›ç¨‹æ’å
# ============================================================================

def get_rank():
    """
    è·å–å½“å‰è¿›ç¨‹çš„å…¨å±€æ’å
    
    Returns:
        int: è¿›ç¨‹æ’åã€‚å• GPU æ—¶è¿”å› 0
    
    ç”¨é€”ï¼š
    - åªæœ‰ rank 0 æ‰“å°æ—¥å¿—
    - åªæœ‰ rank 0 ä¿å­˜æ–‡ä»¶
    - é¿å…é‡å¤æ“ä½œ
    """
    return int(os.environ.get('RANK', '0'))


def print_rank0(msg):
    """
    åªåœ¨ rank 0 è¿›ç¨‹æ‰“å°æ¶ˆæ¯
    
    å¤š GPU æ—¶ï¼Œæ¯ä¸ª GPU éƒ½æ˜¯ç‹¬ç«‹è¿›ç¨‹ã€‚å¦‚æœæ‰€æœ‰è¿›ç¨‹éƒ½æ‰“å°ï¼š
    - æ—¥å¿—ä¼šé‡å¤ N æ¬¡
    - è¾“å‡ºæ··ä¹±
    
    Args:
        msg: è¦æ‰“å°çš„æ¶ˆæ¯
    """
    if get_rank() == 0:
        print(msg)


# ============================================================================
# ğŸ”¬ è¾…åŠ©å‡½æ•°ï¼šLatent å°ºå¯¸è®¡ç®—
# ============================================================================
# 
# ã€ä»€ä¹ˆæ˜¯ Latentï¼Ÿã€‘
# 
# Latent (æ½œåœ¨å‘é‡) æ˜¯è§†é¢‘åœ¨å‹ç¼©ç©ºé—´ä¸­çš„è¡¨ç¤ºï¼š
# 
#   åŸå§‹è§†é¢‘: (batch, channels, frames, height, width)
#              (1,     3,        49,     720,    1280)
#   
#   VAE ç¼–ç åçš„ Latent: (batch, latent_channels, latent_frames, latent_height, latent_width)
#                        (1,     16,              13,            45,            80)
#
# å‹ç¼©æ¯”ä¾‹ï¼š
# - æ—¶é—´: 49 â†’ 13 (å‹ç¼© 4 å€ï¼Œä½†ç¬¬ä¸€å¸§ç‰¹æ®Šå¤„ç†)
# - ç©ºé—´: 720Ã—1280 â†’ 45Ã—80 (å„å‹ç¼© 16 å€)
# ============================================================================

def get_latent_size(video_length, height, width, vae_temporal_ratio=4, vae_spatial_ratio=16):
    """
    è®¡ç®— latent çš„å°ºå¯¸
    
    Args:
        video_length: è§†é¢‘å¸§æ•° (å¦‚ 49)
        height: è§†é¢‘é«˜åº¦åƒç´  (å¦‚ 720)
        width: è§†é¢‘å®½åº¦åƒç´  (å¦‚ 1280)
        vae_temporal_ratio: VAE æ—¶é—´å‹ç¼©æ¯” (é»˜è®¤ 4)
        vae_spatial_ratio: VAE ç©ºé—´å‹ç¼©æ¯” (é»˜è®¤ 16)
    
    Returns:
        tuple: (latent_frames, latent_height, latent_width)
    
    è®¡ç®—å…¬å¼:
        latent_frames = (video_length - 1) // 4 + 1
        - ä¸ºä»€ä¹ˆæ˜¯ (n-1)//4+1 è€Œä¸æ˜¯ n//4ï¼Ÿ
        - å› ä¸ºç¬¬ä¸€å¸§æ˜¯å…³é”®å¸§ï¼Œéœ€è¦ç‰¹æ®Šä¿ç•™
        
        ä¾‹å¦‚: 49 å¸§ â†’ (49-1)//4+1 = 13 ä¸ª latent å¸§
              ç¬¬ä¸€å¸§å¯¹åº”ç¬¬ä¸€ä¸ª latentï¼Œåé¢æ¯ 4 å¸§ä¸€ä¸ª latent
    """
    video_length = (video_length - 1) // vae_temporal_ratio + 1
    height = height // vae_spatial_ratio
    width = width // vae_spatial_ratio
    return video_length, height, width


# ============================================================================
# ğŸ­ è¾…åŠ©å‡½æ•°ï¼šä»»åŠ¡ç±»å‹ Mask
# ============================================================================
# 
# ã€ä»»åŠ¡ç±»å‹è¯´æ˜ã€‘
# 
# HunyuanVideo-1.5 æ”¯æŒå¤šç§ä»»åŠ¡ï¼š
# - t2v (Text-to-Video): çº¯æ–‡æœ¬ç”Ÿæˆè§†é¢‘
# - i2v (Image-to-Video): å›¾ç‰‡ + æ–‡æœ¬ç”Ÿæˆè§†é¢‘
# 
# Mask ç”¨äºå‘Šè¯‰æ¨¡å‹å“ªäº›å¸§æ˜¯"å·²çŸ¥çš„"ï¼ˆæ¡ä»¶å¸§ï¼‰ï¼š
# - t2v: æ‰€æœ‰å¸§éƒ½æ˜¯æœªçŸ¥çš„ï¼Œmask å…¨ä¸º 0
# - i2v: ç¬¬ä¸€å¸§æ˜¯å·²çŸ¥çš„ï¼ˆè¾“å…¥å›¾ç‰‡ï¼‰ï¼Œmask[0] = 1
# ============================================================================

def get_task_mask(task_type, latent_target_length):
    """
    è·å–ä»»åŠ¡ç±»å‹å¯¹åº”çš„ mask
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ("t2v" æˆ– "i2v")
        latent_target_length: latent çš„æ—¶é—´é•¿åº¦
    
    Returns:
        torch.Tensor: shape (latent_target_length,)
            - 0.0 è¡¨ç¤ºè¯¥å¸§éœ€è¦ç”Ÿæˆ
            - 1.0 è¡¨ç¤ºè¯¥å¸§æ˜¯æ¡ä»¶å¸§ï¼ˆå¦‚ i2v çš„ç¬¬ä¸€å¸§ï¼‰
    
    t2v (Text-to-Video):
        mask = [0, 0, 0, ..., 0]  # æ‰€æœ‰å¸§éƒ½éœ€è¦ç”Ÿæˆ
    
    i2v (Image-to-Video):
        mask = [1, 0, 0, ..., 0]  # ç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å›¾ç‰‡
    """
    if task_type == "t2v":
        # t2v: æ‰€æœ‰å¸§éƒ½éœ€è¦ç”Ÿæˆ
        return torch.zeros(latent_target_length)
    elif task_type == "i2v":
        # i2v: ç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å¸§
        mask = torch.zeros(latent_target_length)
        mask[0] = 1.0
        return mask
    else:
        raise ValueError(f"{task_type} is not supported!")


# ============================================================================
# ğŸ² è¾…åŠ©å‡½æ•°ï¼šå‡†å¤‡åˆå§‹ Latents
# ============================================================================
# 
# ã€æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³ã€‘
# 
# æ‰©æ•£æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹æ˜¯"å»å™ª"ï¼š
# 
#   çº¯å™ªå£° â†’ å»å™ªæ­¥éª¤ 1 â†’ å»å™ªæ­¥éª¤ 2 â†’ ... â†’ å»å™ªæ­¥éª¤ N â†’ æ¸…æ™°ç»“æœ
#   z_T         z_{T-1}       z_{T-2}     ...      z_0
#
# æ‰€ä»¥æˆ‘ä»¬é¦–å…ˆéœ€è¦ä¸€ä¸ªéšæœºå™ªå£°ä½œä¸ºèµ·ç‚¹ã€‚
# 
# ã€ä¸ºä»€ä¹ˆåœ¨ CPU ç”Ÿæˆå†ç§»åˆ° GPUï¼Ÿã€‘
# 
# è¿™æ˜¯ä¸ºäº†ç¡®ä¿éšæœºæ•°çš„å¯é‡ç°æ€§ï¼š
# - CUDA çš„éšæœºæ•°ç”Ÿæˆå™¨åœ¨ä¸åŒç¡¬ä»¶ä¸Šå¯èƒ½æœ‰å·®å¼‚
# - CPU ç”Ÿæˆæ›´ç¨³å®šã€å¯é‡ç°
# ============================================================================

def prepare_latents(batch_size, num_channels, latent_height, latent_width, video_length,
                   dtype, device, generator):
    """
    å‡†å¤‡åˆå§‹çš„éšæœº latentsï¼ˆçº¯å™ªå£°ï¼‰
    
    Args:
        batch_size: æ‰¹æ¬¡å¤§å°ï¼Œé€šå¸¸ä¸º 1
        num_channels: latent é€šé“æ•°ï¼ŒHunyuanVideo ä½¿ç”¨ 16
        latent_height: latent é«˜åº¦
        latent_width: latent å®½åº¦
        video_length: latent æ—¶é—´é•¿åº¦ï¼ˆå¸§æ•°ï¼‰
        dtype: æ•°æ®ç±»å‹ (torch.bfloat16 æˆ– torch.float32)
        device: ç›®æ ‡è®¾å¤‡ (cuda)
        generator: éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆç”¨äºç§å­æ§åˆ¶ï¼‰
    
    Returns:
        torch.Tensor: shape (batch_size, num_channels, video_length, latent_height, latent_width)
                      ä¾‹å¦‚ (1, 16, 13, 45, 80) for 720p 49å¸§è§†é¢‘
    
    æ³¨æ„ï¼š
        latents çš„å½¢çŠ¶æ˜¯ (B, C, T, H, W)ï¼Œæ³¨æ„ T åœ¨ H, W ä¹‹å‰ï¼
        è¿™æ˜¯è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ ‡å‡†æ ¼å¼ã€‚
    """
    shape = (batch_size, num_channels, video_length, latent_height, latent_width)
    
    # åœ¨ CPU ä¸Šç”Ÿæˆéšæœºæ•°ï¼Œç¡®ä¿å¯é‡ç°æ€§
    latents = torch.randn(shape, generator=generator, device=torch.device('cpu'), dtype=dtype)
    
    # ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
    latents = latents.to(device)
    
    return latents


# ============================================================================
# ğŸ¯ è¾…åŠ©å‡½æ•°ï¼šå‡†å¤‡æ¡ä»¶ Latents
# ============================================================================
# 
# ã€ä»€ä¹ˆæ˜¯æ¡ä»¶ Latentsï¼Ÿã€‘
# 
# åœ¨ HunyuanVideo ä¸­ï¼Œæ¡ä»¶ latents ç”¨äºï¼š
# 1. i2v ä»»åŠ¡ï¼šæä¾›ç¬¬ä¸€å¸§çš„å›¾åƒä¿¡æ¯
# 2. æä¾›é¢å¤–çš„ç»“æ„ä¿¡æ¯ç»™ Transformer
# 
# æ¡ä»¶ latents ä¼šå’Œä¸» latents åœ¨é€šé“ç»´åº¦æ‹¼æ¥ï¼š
#   - ä¸» latents: (B, 16, T, H, W)
#   - æ¡ä»¶ latents: (B, 17, T, H, W)  # 16 é€šé“ + 1 é€šé“ mask
#   - æ‹¼æ¥å: (B, 33, T, H, W)
# ============================================================================

def prepare_cond_latents(task_type, image_cond, latents, multitask_mask):
    """
    å‡†å¤‡æ¡ä»¶ latentsï¼ˆç”¨äº i2v æˆ–æä¾›é¢å¤–ä¿¡æ¯ï¼‰
    
    Args:
        task_type: ä»»åŠ¡ç±»å‹ ("t2v" æˆ– "i2v")
        image_cond: å›¾åƒæ¡ä»¶ latent (i2v æ—¶ä¸ºå›¾åƒçš„ VAE ç¼–ç ï¼Œt2v æ—¶ä¸º None)
        latents: ä¸» latents
        multitask_mask: ä»»åŠ¡ maskï¼ŒæŒ‡ç¤ºå“ªäº›å¸§æ˜¯æ¡ä»¶å¸§
    
    Returns:
        torch.Tensor: æ¡ä»¶ latentsï¼Œshape (B, 17, T, H, W)
                      å‰ 16 é€šé“æ˜¯æ¡ä»¶ä¿¡æ¯
                      æœ€å 1 é€šé“æ˜¯ mask
    
    å¯¹äº t2v:
        - æ¡ä»¶ latents å…¨ä¸º 0ï¼ˆæ²¡æœ‰å›¾åƒæ¡ä»¶ï¼‰
        - mask é€šé“æ ¹æ® multitask_mask è®¾ç½®
    
    å¯¹äº i2v:
        - ç¬¬ä¸€å¸§æœ‰å›¾åƒæ¡ä»¶
        - å…¶ä»–å¸§ä¸º 0
        - mask æŒ‡ç¤ºç¬¬ä¸€å¸§æ˜¯æ¡ä»¶å¸§
    """
    if image_cond is not None and task_type == 'i2v':
        # i2v: ç”¨å›¾åƒæ¡ä»¶å¡«å……ç¬¬ä¸€å¸§ï¼Œå…¶ä»–å¸§ä¸º 0
        latents_concat = image_cond.repeat(1, 1, latents.shape[2], 1, 1)
        latents_concat[:, :, 1:, :, :] = 0.0  # é™¤ç¬¬ä¸€å¸§å¤–éƒ½æ¸…é›¶
    else:
        # t2v: æ²¡æœ‰å›¾åƒæ¡ä»¶ï¼Œå…¨ä¸º 0
        latents_concat = torch.zeros_like(latents)
    
    # åˆ›å»º mask é€šé“
    # mask_zeros: å…¨ 0 (éœ€è¦ç”Ÿæˆçš„å¸§)
    # mask_ones: å…¨ 1 (æ¡ä»¶å¸§)
    mask_zeros = torch.zeros(latents.shape[0], 1, latents.shape[2], latents.shape[3], latents.shape[4])
    mask_ones = torch.ones(latents.shape[0], 1, latents.shape[2], latents.shape[3], latents.shape[4])
    
    # æ ¹æ® multitask_mask åˆå¹¶ï¼šåœ¨æ¡ä»¶å¸§ä½ç½®ä½¿ç”¨ mask_ones
    mask_concat = merge_tensor_by_mask(
        mask_zeros.cpu(), 
        mask_ones.cpu(), 
        mask=multitask_mask.cpu(), 
        dim=2  # åœ¨æ—¶é—´ç»´åº¦åˆå¹¶
    ).to(device=latents.device)
    
    # æ‹¼æ¥ï¼š[æ¡ä»¶ latents (16 é€šé“), mask (1 é€šé“)]
    return torch.concat([latents_concat, mask_concat], dim=1)


# ============================================================================
# ğŸ“ è¾…åŠ©å‡½æ•°ï¼šè·å–æœ€æ¥è¿‘çš„åˆ†è¾¨ç‡
# ============================================================================
# 
# ã€ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªå‡½æ•°ï¼Ÿã€‘
# 
# 1. è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨ç‰¹å®šåˆ†è¾¨ç‡ä¸Šè®­ç»ƒ
# 2. å¿…é¡»ä½¿ç”¨ä¸è®­ç»ƒä¸€è‡´çš„åˆ†è¾¨ç‡æ‰èƒ½è·å¾—å¥½æ•ˆæœ
# 3. åˆ†è¾¨ç‡å¿…é¡»æ˜¯æŸäº›æ•°å­—çš„å€æ•°ï¼ˆå¦‚ 16ï¼‰ä»¥åŒ¹é… VAE
# 
# ã€Bucket ç³»ç»Ÿã€‘
# 
# HunyuanVideo ä½¿ç”¨ "bucket" ç³»ç»Ÿç®¡ç†åˆ†è¾¨ç‡ï¼š
# - å®šä¹‰ä¸€ç»„æ ‡å‡†åˆ†è¾¨ç‡
# - æ ¹æ®ç”¨æˆ·è¯·æ±‚çš„å®½é«˜æ¯”é€‰æ‹©æœ€æ¥è¿‘çš„åˆ†è¾¨ç‡
# ============================================================================

def get_closest_resolution(aspect_ratio, target_resolution):
    """
    æ ¹æ®å®½é«˜æ¯”è·å–æœ€æ¥è¿‘çš„æ ‡å‡†åˆ†è¾¨ç‡
    
    Args:
        aspect_ratio: å®½é«˜æ¯”å­—ç¬¦ä¸² (å¦‚ "16:9", "9:16", "1:1")
        target_resolution: ç›®æ ‡åˆ†è¾¨ç‡çº§åˆ« ("360p", "480p", "720p", "1080p")
    
    Returns:
        tuple: (height, width) æœ€æ¥è¿‘çš„æ ‡å‡†åˆ†è¾¨ç‡
    
    å·¥ä½œåŸç†ï¼š
    1. æ ¹æ® target_resolution ç¡®å®šåŸºç¡€å°ºå¯¸
    2. ç”Ÿæˆè¯¥åˆ†è¾¨ç‡ä¸‹æ‰€æœ‰å¯èƒ½çš„ (H, W) ç»„åˆ
    3. æ‰¾åˆ°å®½é«˜æ¯”æœ€æ¥è¿‘ç”¨æˆ·è¯·æ±‚çš„ç»„åˆ
    
    ä¾‹å¦‚:
        aspect_ratio="16:9", target_resolution="720p"
        â†’ è¿”å› (720, 1280) æˆ–æ¥è¿‘çš„å€¼
    """
    from hyvideo.utils.data_utils import generate_crop_size_list, get_closest_ratio
    
    # å„åˆ†è¾¨ç‡çº§åˆ«çš„é…ç½®
    # bucket_hw_base_size: åŸºç¡€å°ºå¯¸ï¼ˆç”¨äºç”Ÿæˆå€™é€‰åˆ†è¾¨ç‡ï¼‰
    # bucket_hw_bucket_stride: åˆ†è¾¨ç‡æ­¥é•¿ï¼ˆå¿…é¡»æ˜¯æ­¤æ•°çš„å€æ•°ï¼‰
    target_size_config = {
        "360p": {"bucket_hw_base_size": 480, "bucket_hw_bucket_stride": 16},
        "480p": {"bucket_hw_base_size": 640, "bucket_hw_bucket_stride": 16},
        "720p": {"bucket_hw_base_size": 960, "bucket_hw_bucket_stride": 16},
        "1080p": {"bucket_hw_base_size": 1440, "bucket_hw_bucket_stride": 16},
    }
    
    bucket_hw_base_size = target_size_config[target_resolution]["bucket_hw_base_size"]
    bucket_hw_bucket_stride = target_size_config[target_resolution]["bucket_hw_bucket_stride"]
    
    # è§£æå®½é«˜æ¯”
    if ":" in aspect_ratio:
        w_ratio, h_ratio = map(int, aspect_ratio.split(":"))
    else:
        # é»˜è®¤ 16:9
        w_ratio, h_ratio = 16, 9
    
    # ç”Ÿæˆæ‰€æœ‰å€™é€‰åˆ†è¾¨ç‡
    crop_size_list = generate_crop_size_list(bucket_hw_base_size, bucket_hw_bucket_stride)
    
    # è®¡ç®—æ¯ä¸ªå€™é€‰åˆ†è¾¨ç‡çš„å®½é«˜æ¯”
    aspect_ratios = np.array([round(float(h) / float(w), 5) for h, w in crop_size_list])
    
    # æ‰¾åˆ°æœ€æ¥è¿‘çš„åˆ†è¾¨ç‡
    closest_size, _ = get_closest_ratio(h_ratio, w_ratio, aspect_ratios, crop_size_list)
    
    return closest_size[0], closest_size[1]  # height, width


# ============================================================================
# ğŸš€ ä¸»å‡½æ•°
# ============================================================================
# 
# è¿™æ˜¯ Stage 2 çš„æ ¸å¿ƒé€»è¾‘ï¼š
# 1. åŠ è½½ Stage 1 çš„è¾“å‡ºï¼ˆtext embeddingsï¼‰
# 2. åŠ è½½ Transformer æ¨¡å‹
# 3. è¿è¡Œæ‰©æ•£å»å™ªå¾ªç¯
# 4. ä¿å­˜è¾“å‡ºçš„ latents
# ============================================================================

def main():
    # ========================================================================
    # ğŸ“‹ å‚æ•°è§£æ
    # ========================================================================
    parser = argparse.ArgumentParser(description='HunyuanVideo-1.5 Stage 2: Transformer')
    
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    parser.add_argument('--input_dir', type=str, default='./stage_outputs',
                       help='Stage 1 è¾“å‡ºç›®å½•ï¼ŒåŒ…å« embeddings å’Œ config')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼Œé»˜è®¤åŒ input_dir')
    
    # è§†é¢‘ç”Ÿæˆå‚æ•°
    parser.add_argument('--aspect_ratio', type=str, default='16:9',
                       help='è§†é¢‘å®½é«˜æ¯”ï¼Œå¦‚ 16:9, 9:16, 1:1')
    parser.add_argument('--video_length', type=int, default=49,
                       help='è§†é¢‘å¸§æ•° (æ¨è 49, 97, 145 ç­‰ 4n+1 çš„å€¼)')
    parser.add_argument('--num_inference_steps', type=int, default=50,
                       help='æ¨ç†æ­¥æ•°ï¼Œè¶Šå¤šè´¨é‡è¶Šå¥½ä½†è¶Šæ…¢')
    parser.add_argument('--guidance_scale', type=float, default=6.0,
                       help='CFG å¼•å¯¼å¼ºåº¦ï¼Œè¶Šé«˜è¶Šç¬¦åˆ prompt')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­ï¼Œç”¨äºå¤ç°ç»“æœ')
    
    args = parser.parse_args()
    
    # ========================================================================
    # âš¡ åˆå§‹åŒ–æ¨ç†çŠ¶æ€ (infer_state)
    # ========================================================================
    # 
    # infer_state æ§åˆ¶å„ç§æ¨ç†ä¼˜åŒ–ï¼š
    # 
    # - use_sageattn: æ˜¯å¦ä½¿ç”¨ SageAttentionï¼ˆä¸€ç§é«˜æ•ˆæ³¨æ„åŠ›å®ç°ï¼‰
    # - sage_blocks_range: å“ªäº› Transformer å—ä½¿ç”¨ SageAttention
    # - enable_torch_compile: æ˜¯å¦å¯ç”¨ torch.compile åŠ é€Ÿ
    # - enable_cache: æ˜¯å¦å¯ç”¨ DeepCacheï¼ˆè·³è¿‡éƒ¨åˆ†è®¡ç®—ï¼‰
    # - cache_type: ç¼“å­˜ç±»å‹
    # - no_cache_block_id: ä¸ç¼“å­˜çš„å— ID
    # - cache_start_step: ä»ç¬¬å‡ æ­¥å¼€å§‹ç¼“å­˜
    # - cache_end_step: ç¬¬å‡ æ­¥ç»“æŸç¼“å­˜
    # - cache_step_interval: ç¼“å­˜æ­¥é—´éš”
    # 
    # è¿™äº›ä¼˜åŒ–å¯ä»¥æ˜¾è‘—åŠ é€Ÿæ¨ç†ï¼Œä½†å¯èƒ½å½±å“è´¨é‡ã€‚
    # ========================================================================
    infer_args = SimpleNamespace(
        use_sageattn=False,              # ä¸ä½¿ç”¨ SageAttention
        sage_blocks_range="0-53",        # å¦‚æœä½¿ç”¨ï¼Œåº”ç”¨åˆ°æ‰€æœ‰ 53 ä¸ªå—
        enable_torch_compile=False,      # ä¸å¯ç”¨ç¼–è¯‘ï¼ˆè°ƒè¯•æ—¶å…³é—­ï¼‰
        enable_cache=False,              # ä¸å¯ç”¨ç¼“å­˜ï¼ˆä¿æŒæœ€é«˜è´¨é‡ï¼‰
        cache_type="deepcache",
        no_cache_block_id="53",
        cache_start_step=11,
        cache_end_step=45,
        total_steps=args.num_inference_steps,
        cache_step_interval=4,
    )
    initialize_infer_state(infer_args)
    
    # è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    output_dir = args.output_dir or args.input_dir
    input_paths = get_default_paths(args.input_dir)
    output_paths = get_default_paths(output_dir)
    
    print_rank0(f"\n{'='*60}")
    print_rank0("HunyuanVideo-1.5 Stage 2: Transformer (ç›´æ¥åŠ è½½ï¼Œæ—  text encoder)")
    print_rank0(f"{'='*60}")
    
    # ========================================================================
    # ğŸ“‚ åŠ è½½ Stage 1 çš„è¾“å‡º
    # ========================================================================
    # 
    # Stage 1 ç”Ÿæˆçš„æ–‡ä»¶ï¼š
    # - config.json: ç”Ÿæˆé…ç½®ï¼ˆpromptã€æ¨¡å‹è·¯å¾„ç­‰ï¼‰
    # - embeddings.safetensors: æ–‡æœ¬åµŒå…¥å‘é‡
    # 
    # æˆ‘ä»¬éœ€è¦è¿™äº›æ¥æŒ‡å¯¼ Transformer ç”Ÿæˆä»€ä¹ˆæ ·çš„è§†é¢‘ã€‚
    # ========================================================================
    
    print_rank0(f"\nåŠ è½½ Stage 1 é…ç½®: {input_paths['config']}")
    config = load_generation_config(input_paths['config'])
    
    print_rank0(f"åŠ è½½ Stage 1 embeddings: {input_paths['embeddings']}")
    embeddings_dict, _ = load_embeddings_from_safetensors(input_paths['embeddings'], device='cpu')
    
    # ç”¨å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
    config['aspect_ratio'] = args.aspect_ratio
    config['video_length'] = args.video_length
    config['num_inference_steps'] = args.num_inference_steps
    config['guidance_scale'] = args.guidance_scale
    config['seed'] = args.seed
    
    # ä»é…ç½®ä¸­æå–æ¨¡å‹ä¿¡æ¯
    model_path = config['model_path']
    transformer_version = config['transformer_version']
    resolution = config.get('resolution', '720p')
    task_type = config.get('task_type', 't2v')
    
    print_rank0(f"\né…ç½®:")
    print_rank0(f"  model_path: {model_path}")
    print_rank0(f"  transformer_version: {transformer_version}")
    print_rank0(f"  resolution: {resolution}")
    print_rank0(f"  task_type: {task_type}")
    print_rank0(f"  aspect_ratio: {args.aspect_ratio}")
    print_rank0(f"  video_length: {args.video_length}")
    print_rank0(f"  num_inference_steps: {args.num_inference_steps}")
    print_rank0(f"  guidance_scale: {args.guidance_scale}")
    print_rank0(f"  seed: {args.seed}")
    
    # ========================================================================
    # ğŸ¤– åŠ è½½ Transformer æ¨¡å‹
    # ========================================================================
    # 
    # ã€HunyuanVideo_1_5_DiffusionTransformerã€‘
    # 
    # è¿™æ˜¯ä¸€ä¸ªåŸºäº DiT (Diffusion Transformer) æ¶æ„çš„æ¨¡å‹ï¼š
    # 
    # ç»“æ„æ¦‚è§ˆï¼š
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Input: latents (B, 33, T, H, W)                          â”‚
    # â”‚        text embeddings (B, L, D)                         â”‚
    # â”‚        timestep (B,)                                     â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Patchify + Position Embedding                            â”‚
    # â”‚ å°†è§†é¢‘åˆ‡æˆ patchesï¼Œæ·»åŠ ä½ç½®ç¼–ç                           â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Transformer Blocks Ã— 53                                  â”‚
    # â”‚ æ¯ä¸ªå—åŒ…å«:                                               â”‚
    # â”‚   - Self-Attention (è§†é¢‘ patches ä¹‹é—´)                   â”‚
    # â”‚   - Cross-Attention (è§†é¢‘ â†” æ–‡æœ¬)                        â”‚
    # â”‚   - FFN (å‰é¦ˆç½‘ç»œ)                                       â”‚
    # â”‚   - Time Embedding æ³¨å…¥                                  â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    # â”‚ Unpatchify                                               â”‚
    # â”‚ å°† patches é‡ç»„ä¸ºè§†é¢‘ latents                             â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    #                          â–¼
    # â”‚ Output: noise prediction (B, 16, T, H, W)                â”‚
    # 
    # ã€ä¸ºä»€ä¹ˆç›´æ¥åŠ è½½è€Œä¸ç”¨ pipelineï¼Ÿã€‘
    # 
    # create_pipeline ä¼šåŠ è½½æ‰€æœ‰ç»„ä»¶ï¼Œä½†æˆ‘ä»¬åªéœ€è¦ Transformerï¼š
    # - Text Encoder: åœ¨ Stage 1 å·²ç»ç”¨è¿‡äº†
    # - VAE: åœ¨ Stage 3 æ‰ä¼šç”¨
    # - åªåŠ è½½éœ€è¦çš„å¯ä»¥èŠ‚çœ ~20GB å†…å­˜
    # ========================================================================
    
    print_rank0(f"\nç›´æ¥åŠ è½½ Transformerï¼ˆä¸åŠ è½½å…¶ä»–ç»„ä»¶ï¼‰...")
    
    # ç¡®å®šæ•°æ®ç±»å‹
    dtype = config.get('dtype', 'bf16')
    if dtype == 'bf16':
        transformer_dtype = torch.bfloat16  # æ¨èï¼šæ›´å¿«ã€å†…å­˜æ›´å°‘
    else:
        transformer_dtype = torch.float32
    
    # æ„å»º Transformer è·¯å¾„
    transformer_path = os.path.join(model_path, "transformer", transformer_version)
    print_rank0(f"  åŠ è½½è·¯å¾„: {transformer_path}")
    
    # åŠ è½½ Transformer
    transformer = HunyuanVideo_1_5_DiffusionTransformer.from_pretrained(
        transformer_path,
        torch_dtype=transformer_dtype,
        low_cpu_mem_usage=True,  # ä¼˜åŒ–å†…å­˜ä½¿ç”¨
    )
    
    # ç§»åŠ¨åˆ° GPU å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    device = torch.device('cuda')
    transformer = transformer.to(device)
    transformer.eval()  # å…³é—­ dropout ç­‰è®­ç»ƒä¸“ç”¨å±‚
    
    print_rank0(f"  âœ“ Transformer åŠ è½½å®Œæˆ")
    print_rank0(f"  attn_mode: {transformer.attn_mode}")  # æ³¨æ„åŠ›æ¨¡å¼
    print_rank0(f"  use_meanflow: {transformer.config.use_meanflow}")  # æ˜¯å¦ä½¿ç”¨ meanflow
    print_rank0(f"  dtype: {transformer.dtype}")
    
    # ========================================================================
    # â±ï¸ åŠ è½½ Schedulerï¼ˆè°ƒåº¦å™¨ï¼‰
    # ========================================================================
    # 
    # ã€ä»€ä¹ˆæ˜¯ Schedulerï¼Ÿã€‘
    # 
    # Scheduler æ§åˆ¶æ‰©æ•£è¿‡ç¨‹çš„"èŠ‚å¥"ï¼š
    # - å†³å®šæ¯ä¸€æ­¥æ·»åŠ /å»é™¤å¤šå°‘å™ªå£°
    # - å†³å®šæ—¶é—´æ­¥çš„åˆ†å¸ƒ
    # - ä¸åŒçš„ scheduler æœ‰ä¸åŒçš„é€Ÿåº¦/è´¨é‡æƒè¡¡
    # 
    # ã€FlowMatchDiscreteSchedulerã€‘
    # 
    # è¿™æ˜¯ä¸“é—¨ä¸º Flow Matching è®¾è®¡çš„è°ƒåº¦å™¨ï¼š
    # 
    # æ ¸å¿ƒæ¦‚å¿µï¼š
    # - ä¸ç›´æ¥é¢„æµ‹å™ªå£°ï¼Œè€Œæ˜¯é¢„æµ‹"æµ"ï¼ˆä»å™ªå£°åˆ°æ•°æ®çš„æ–¹å‘ï¼‰
    # - ä½¿ç”¨ ODE æ±‚è§£å™¨ï¼ˆå¦‚ Eulerï¼‰æ¥è¿­ä»£
    # 
    # å…³é”®å‚æ•°ï¼š
    # - shift (flow_shift): æ§åˆ¶æ—¶é—´æ­¥çš„åˆ†å¸ƒåç§»
    #   - è¾ƒå¤§çš„å€¼ï¼šåæœŸæ­¥éª¤æ›´å¯†é›†ï¼ˆæ›´æ³¨é‡ç»†èŠ‚ï¼‰
    #   - è¾ƒå°çš„å€¼ï¼šæ­¥éª¤æ›´å‡åŒ€åˆ†å¸ƒ
    # 
    # - reverse: True è¡¨ç¤ºä»å™ªå£°åˆ°æ•°æ®ï¼ˆæ¨ç†ï¼‰
    #            False è¡¨ç¤ºä»æ•°æ®åˆ°å™ªå£°ï¼ˆè®­ç»ƒï¼‰
    # 
    # - solver: ODE æ±‚è§£å™¨ç±»å‹
    #   - "euler": ä¸€é˜¶æ¬§æ‹‰æ³•ï¼ˆæœ€ç®€å•ã€æœ€å¿«ï¼‰
    #   - "heun": äºŒé˜¶æ–¹æ³•ï¼ˆæ›´å‡†ç¡®ã€ä½†æ…¢ï¼‰
    # ========================================================================
    
    scheduler_path = os.path.join(model_path, "scheduler")
    scheduler = FlowMatchDiscreteScheduler.from_pretrained(scheduler_path)
    
    # è·å– pipeline é…ç½®ä¸­çš„è°ƒåº¦å™¨å‚æ•°
    # PIPELINE_CONFIGS åŒ…å«å„ç‰ˆæœ¬çš„é»˜è®¤é…ç½®
    pipeline_config = PIPELINE_CONFIGS.get(transformer_version, PIPELINE_CONFIGS['720p_t2v'])
    flow_shift = pipeline_config['flow_shift']  # æ—¶é—´æ­¥åç§»
    default_guidance_scale = pipeline_config['guidance_scale']  # é»˜è®¤ CFG å¼ºåº¦
    
    print_rank0(f"  flow_shift: {flow_shift}")
    print_rank0(f"  default_guidance_scale: {default_guidance_scale}")
    
    # ä½¿ç”¨æ­£ç¡®çš„ flow_shift é‡å»º scheduler
    scheduler = FlowMatchDiscreteScheduler(
        shift=flow_shift,     # æ—¶é—´æ­¥åç§»
        reverse=True,         # æ¨ç†æ¨¡å¼ï¼ˆä»å™ªå£°åˆ°æ•°æ®ï¼‰
        solver="euler",       # ä½¿ç”¨æ¬§æ‹‰æ±‚è§£å™¨
    )
    
    # ========================================================================
    # ğŸ“ è®¾ç½®ç”Ÿæˆå‚æ•°
    # ========================================================================
    
    guidance_scale = args.guidance_scale
    seed = args.seed
    
    # CFG (Classifier-Free Guidance) åˆ¤æ–­
    # å½“ guidance_scale > 1.0 æ—¶å¯ç”¨ CFG
    # guidance_scale = 1.0 æ„å‘³ç€ä¸ä½¿ç”¨å¼•å¯¼ï¼ˆçº¯æ— æ¡ä»¶ç”Ÿæˆï¼‰
    do_classifier_free_guidance = guidance_scale > 1.0
    
    # Meanflow è®¾ç½®
    use_meanflow = transformer.config.use_meanflow
    
    target_dtype = transformer_dtype
    
    # è®¡ç®—å®é™…åˆ†è¾¨ç‡
    height, width = get_closest_resolution(args.aspect_ratio, resolution)
    print_rank0(f"\nåˆ†è¾¨ç‡: {width}x{height}")
    
    # ========================================================================
    # ğŸŒ± è®¾ç½®éšæœºç§å­
    # ========================================================================
    # 
    # ã€ä¸ºä»€ä¹ˆéœ€è¦åŒæ­¥ç§å­ï¼Ÿã€‘
    # 
    # åœ¨å¤š GPU (Sequence Parallelism) æ¨¡å¼ä¸‹ï¼š
    # - æ¯ä¸ª GPU éœ€è¦ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­
    # - å¦åˆ™ç”Ÿæˆçš„å™ªå£°ä¼šä¸ä¸€è‡´
    # - å¯¼è‡´è§†é¢‘åœ¨ä¸åŒ GPU çš„ç‰‡æ®µä¸è¿è´¯
    # 
    # é€šè¿‡ broadcast_object_list ä» rank 0 å¹¿æ’­ç§å­åˆ°æ‰€æœ‰è¿›ç¨‹
    # ========================================================================
    
    if get_parallel_state().sp_enabled:
        if dist.is_initialized():
            obj_list = [seed]
            # è·å– SP ç»„çš„æº rankï¼ˆrank 0ï¼‰
            group_src_rank = dist.get_global_rank(get_parallel_state().sp_group, 0)
            # å¹¿æ’­ç§å­åˆ°æ‰€æœ‰è¿›ç¨‹
            dist.broadcast_object_list(obj_list, src=group_src_rank, group=get_parallel_state().sp_group)
            seed = obj_list[0]
    
    # åˆ›å»º CPU ä¸Šçš„éšæœºæ•°ç”Ÿæˆå™¨ï¼ˆä¸ºäº†å¯é‡ç°æ€§ï¼‰
    generator = torch.Generator(device=torch.device('cpu')).manual_seed(seed)
    
    # ========================================================================
    # ğŸ“ è®¡ç®— Latent å°ºå¯¸å’Œ Token æ•°é‡
    # ========================================================================
    
    video_length = args.video_length
    
    # è®¡ç®— latent å°ºå¯¸
    latent_target_length, latent_height, latent_width = get_latent_size(video_length, height, width)
    
    # Token æ•°é‡ = T Ã— H Ã— Wï¼ˆæ¯ä¸ª latent ä½ç½®æ˜¯ä¸€ä¸ª tokenï¼‰
    n_tokens = latent_target_length * latent_height * latent_width
    
    print_rank0(f"Latent å°ºå¯¸: {latent_target_length}x{latent_height}x{latent_width}")
    print_rank0(f"Token æ•°é‡: {n_tokens}")
    
    # ========================================================================
    # â° è®¾ç½®æ—¶é—´æ­¥
    # ========================================================================
    # 
    # ã€æ—¶é—´æ­¥å¦‚ä½•å·¥ä½œï¼Ÿã€‘
    # 
    # æ‰©æ•£æ¨¡å‹çš„æ¨ç†æ˜¯ä» t=Tï¼ˆçº¯å™ªå£°ï¼‰åˆ° t=0ï¼ˆæ¸…æ™°å›¾åƒï¼‰çš„è¿‡ç¨‹ã€‚
    # 
    # set_timesteps åšçš„äº‹æƒ…ï¼š
    # 1. æ ¹æ®æ¨ç†æ­¥æ•°å°† [0, 1] åŒºé—´åˆ†æˆ N ä»½
    # 2. åº”ç”¨ flow_shift è°ƒæ•´åˆ†å¸ƒ
    # 3. ç”Ÿæˆæ¯ä¸€æ­¥çš„æ—¶é—´å€¼
    # 
    # n_tokens å‚æ•°ç”¨äºæŸäº›è‡ªé€‚åº”è°ƒåº¦å™¨
    # ========================================================================
    
    scheduler.set_timesteps(args.num_inference_steps, device=device, n_tokens=n_tokens)
    timesteps = scheduler.timesteps
    
    # è·å–ä»»åŠ¡ç±»å‹ mask
    multitask_mask = get_task_mask(task_type, latent_target_length)
    
    # ========================================================================
    # ğŸ“ å‡†å¤‡ Text Embeddings
    # ========================================================================
    # 
    # ã€Embeddings çš„ç»“æ„ã€‘
    # 
    # Stage 1 ç”Ÿæˆäº†ä¸¤ç±»æ–‡æœ¬åµŒå…¥ï¼š
    # 
    # 1. LLM (LLaVA) Embeddings:
    #    - prompt_embeds: æ­£å‘æç¤ºè¯çš„åµŒå…¥ (B, seq_len, hidden_dim)
    #    - negative_prompt_embeds: è´Ÿå‘æç¤ºè¯çš„åµŒå…¥
    #    - prompt_embeds_mask: æ³¨æ„åŠ› mask
    # 
    # 2. ByT5 Embeddings (å¯é€‰):
    #    - prompt_embeds_2: ByT5 ç¼–ç çš„æç¤ºè¯
    #    - ç”¨äºæä¾›å­—ç¬¦çº§åˆ«çš„æ–‡æœ¬ç†è§£
    # 
    # ã€CFG çš„ Embedding å¤„ç†ã€‘
    # 
    # å¯ç”¨ CFG æ—¶ï¼Œéœ€è¦åŒæ—¶å¤„ç†æœ‰æ¡ä»¶å’Œæ— æ¡ä»¶çš„æ¨ç†ï¼š
    # - å°† negative å’Œ positive embeddings æ‹¼æ¥
    # - batch ç»´åº¦åŠ å€ï¼š[negative_embeds, positive_embeds]
    # - åç»­æ¨¡å‹ä¼šè¾“å‡ºä¸¤ä¸ªé¢„æµ‹ï¼Œç”¨äº CFG å…¬å¼
    # ========================================================================
    
    print_rank0(f"\nå‡†å¤‡ embeddings...")
    
    # åŠ è½½ LLM embeddings
    prompt_embeds = embeddings_dict['prompt_embeds'].to(device=device, dtype=transformer_dtype)
    negative_prompt_embeds = embeddings_dict['negative_prompt_embeds'].to(device=device, dtype=transformer_dtype)
    prompt_mask = embeddings_dict['prompt_embeds_mask'].to(device=device)
    negative_prompt_mask = embeddings_dict['negative_prompt_embeds_mask'].to(device=device)
    
    # åŠ è½½ ByT5 embeddingsï¼ˆå¯èƒ½ä¸º Noneï¼‰
    prompt_embeds_2 = embeddings_dict.get('prompt_embeds_2')
    negative_prompt_embeds_2 = embeddings_dict.get('negative_prompt_embeds_2')
    prompt_embeds_mask_2 = embeddings_dict.get('prompt_embeds_mask_2')
    negative_prompt_embeds_mask_2 = embeddings_dict.get('negative_prompt_embeds_mask_2')
    
    # CFG: åˆå¹¶æ­£å‘å’Œè´Ÿå‘ embeddings
    if do_classifier_free_guidance:
        # æ‹¼æ¥é¡ºåºï¼š[negative, positive]
        # è¿™æ ·åç»­ chunk(2) æ—¶ä¼šå¾—åˆ° [negative_pred, positive_pred]
        prompt_embeds = torch.cat([negative_prompt_embeds, prompt_embeds])
        prompt_mask = torch.cat([negative_prompt_mask, prompt_mask])
    
    # å‡†å¤‡ ByT5 embeddingsï¼ˆå¦‚æœæœ‰ï¼‰
    extra_kwargs = {}
    if prompt_embeds_2 is not None:
        # ByT5 ä½¿ç”¨ float32 ç²¾åº¦ï¼ˆæ›´é«˜ç²¾åº¦çš„å­—ç¬¦çº§ç†è§£ï¼‰
        prompt_embeds_2 = prompt_embeds_2.to(device=device, dtype=torch.float32)
        prompt_embeds_mask_2 = prompt_embeds_mask_2.to(device=device)
        
        if do_classifier_free_guidance:
            negative_prompt_embeds_2 = negative_prompt_embeds_2.to(device=device, dtype=torch.float32)
            negative_prompt_embeds_mask_2 = negative_prompt_embeds_mask_2.to(device=device)
            byt5_text_states = torch.cat([negative_prompt_embeds_2, prompt_embeds_2])
            byt5_text_mask = torch.cat([negative_prompt_embeds_mask_2, prompt_embeds_mask_2])
        else:
            byt5_text_states = prompt_embeds_2
            byt5_text_mask = prompt_embeds_mask_2
        
        extra_kwargs = {
            "byt5_text_states": byt5_text_states,
            "byt5_text_mask": byt5_text_mask,
        }
    
    print_rank0(f"  prompt_embeds shape: {prompt_embeds.shape}")
    print_rank0(f"  prompt_mask shape: {prompt_mask.shape}")
    if byt5_text_states is not None:
        print_rank0(f"  byt5_text_states shape: {byt5_text_states.shape}")
    
    # 720p_t2v ä¸ä½¿ç”¨é¢å¤–çš„ prompt_embeds_2 è¾“å…¥
    # ï¼ˆByT5 embeddings é€šè¿‡ extra_kwargs ä¼ é€’ï¼‰
    prompt_embeds_2 = None
    
    # ========================================================================
    # ğŸ² å‡†å¤‡ Latents
    # ========================================================================
    
    # è·å– latent é€šé“æ•°ï¼ˆä» Transformer é…ç½®ï¼‰
    num_channels_latents = transformer.config.in_channels  # é€šå¸¸æ˜¯ 16
    
    # ç”Ÿæˆéšæœºå™ªå£° latents
    latents = prepare_latents(
        1,                    # batch_size
        num_channels_latents, # é€šé“æ•° (16)
        latent_height,        # latent é«˜åº¦
        latent_width,         # latent å®½åº¦
        latent_target_length, # latent æ—¶é—´é•¿åº¦
        target_dtype,
        device,
        generator,
    )
    
    # å‡†å¤‡æ¡ä»¶ latents
    cond_latents = prepare_cond_latents(task_type, None, latents, multitask_mask)
    
    # ========================================================================
    # ğŸ‘ï¸ å‡†å¤‡ Vision States
    # ========================================================================
    # 
    # ã€ä»€ä¹ˆæ˜¯ Vision Statesï¼Ÿã€‘
    # 
    # Vision states æ˜¯æ¥è‡ªè§†è§‰ç¼–ç å™¨çš„ç‰¹å¾ï¼ˆå¦‚ CLIP ViTï¼‰ï¼š
    # - ç”¨äº i2v (Image-to-Video) ä»»åŠ¡
    # - ä¸ºæ¨¡å‹æä¾›è§†è§‰ä¸Šä¸‹æ–‡
    # 
    # å¯¹äº t2v (Text-to-Video)ï¼š
    # - æ²¡æœ‰è¾“å…¥å›¾åƒ
    # - ä½¿ç”¨å…¨é›¶å‘é‡ä½œä¸ºå ä½ç¬¦
    # 
    # å‚æ•°:
    # - vision_num_tokens: è§†è§‰ tokens æ•°é‡ (729 = 27Ã—27 for ViT-L/14)
    # - vision_dim: è§†è§‰ç‰¹å¾ç»´åº¦ (1152)
    # ========================================================================
    
    vision_num_tokens = 729  # 27Ã—27 patches
    vision_dim = 1152        # è§†è§‰ç‰¹å¾ç»´åº¦
    
    # t2v æ¨¡å¼ï¼šä½¿ç”¨é›¶å‘é‡
    vision_states = torch.zeros(
        latents.shape[0],     # batch_size
        vision_num_tokens,    # token æ•°é‡
        vision_dim            # ç‰¹å¾ç»´åº¦
    ).to(device=device, dtype=target_dtype)
    
    # CFG æ¨¡å¼éœ€è¦åŠ å€
    if do_classifier_free_guidance:
        vision_states = vision_states.repeat(2, 1, 1)
    
    print_rank0(f"  latents shape: {latents.shape}")
    print_rank0(f"  cond_latents shape: {cond_latents.shape}")
    print_rank0(f"  vision_states shape: {vision_states.shape}")
    
    # ========================================================================
    # ğŸ”„ Denoising Loopï¼ˆå»å™ªå¾ªç¯ï¼‰- æ ¸å¿ƒï¼
    # ========================================================================
    # 
    # è¿™æ˜¯æ‰©æ•£æ¨¡å‹æ¨ç†çš„æ ¸å¿ƒï¼šé€æ­¥å°†å™ªå£°è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„å†…å®¹ã€‚
    # 
    # ã€å·¥ä½œæµç¨‹ã€‘
    # 
    # for t in timesteps (ä» T åˆ° 0):
    #     1. å‡†å¤‡è¾“å…¥
    #        - æ‹¼æ¥ latents å’Œæ¡ä»¶ latents
    #        - å¯¹äº CFGï¼Œå¤åˆ¶è¾“å…¥
    #        - ç¼©æ”¾è¾“å…¥ï¼ˆscheduler è¦æ±‚ï¼‰
    #     
    #     2. Transformer å‰å‘ä¼ æ’­
    #        - è¾“å…¥: latents, timestep, text embeddings
    #        - è¾“å‡º: noise predictionï¼ˆé¢„æµ‹çš„å™ªå£°/æµï¼‰
    #     
    #     3. åº”ç”¨ CFG
    #        - noise = uncond + scale Ã— (cond - uncond)
    #     
    #     4. Scheduler æ›´æ–°
    #        - ä½¿ç”¨é¢„æµ‹æ›´æ–° latents
    #        - latents = scheduler.step(noise, t, latents)
    # 
    # ã€Meanflow ç‰¹æ®Šå¤„ç†ã€‘
    # 
    # å¦‚æœå¯ç”¨ meanflowï¼Œè¿˜éœ€è¦ä¼ é€’ timestep_rï¼š
    # - è¿™æ˜¯ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥
    # - ç”¨äºæ”¹å–„è§†é¢‘çš„æ—¶é—´è¿è´¯æ€§
    # ========================================================================
    
    print_rank0(f"\nå¼€å§‹ Transformer æ¨ç†...")
    print_rank0(f"  ä½¿ç”¨ Meanflow: {use_meanflow}")
    print_rank0(f"  ä½¿ç”¨ CFG: {do_classifier_free_guidance}")
    print_rank0(f"  SP çŠ¶æ€: sp_enabled={get_parallel_state().sp_enabled}, sp_size={get_parallel_state().sp}")
    
    # æ‰“å° GPU å†…å­˜ä½¿ç”¨ï¼ˆè°ƒè¯•ç”¨ï¼‰
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024**3)
        reserved = torch.cuda.memory_reserved() / (1024**3)
        print_rank0(f"  GPU å†…å­˜: allocated={allocated:.2f}GB, reserved={reserved:.2f}GB")
    
    start_time = time.perf_counter()
    num_inference_steps = len(timesteps)
    
    # ä½¿ç”¨ no_grad() ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†ä¸éœ€è¦æ¢¯åº¦ï¼‰
    with torch.no_grad():
        for i, t in enumerate(timesteps):
            # è¿›åº¦æ—¥å¿—
            if i % 10 == 0 or i == 0:
                print_rank0(f"  æ­¥éª¤ {i+1}/{num_inference_steps}")
                if torch.cuda.is_available():
                    allocated = torch.cuda.memory_allocated() / (1024**3)
                    print_rank0(f"    GPU allocated: {allocated:.2f}GB")
            
            # ================================================================
            # æ­¥éª¤ 1: å‡†å¤‡æ¨¡å‹è¾“å…¥
            # ================================================================
            
            # æ‹¼æ¥ä¸» latents å’Œæ¡ä»¶ latents
            # ç»“æœ: (B, 33, T, H, W)  [16 é€šé“ + 17 é€šé“]
            latents_concat = torch.concat([latents, cond_latents], dim=1)
            
            # CFG: å¤åˆ¶è¾“å…¥ï¼ˆæ— æ¡ä»¶ + æœ‰æ¡ä»¶ï¼‰
            if do_classifier_free_guidance:
                latent_model_input = torch.cat([latents_concat] * 2)  # (2B, 33, T, H, W)
            else:
                latent_model_input = latents_concat
            
            # Scheduler ç¼©æ”¾ï¼ˆæŸäº› scheduler éœ€è¦ï¼‰
            latent_model_input = scheduler.scale_model_input(latent_model_input, t)
            
            # æ‰©å±• timestep åˆ° batch ç»´åº¦
            t_expand = t.repeat(latent_model_input.shape[0])
            
            # ================================================================
            # æ­¥éª¤ 2: Meanflow timestep_r å¤„ç†
            # ================================================================
            #
            # Meanflow æŠ€æœ¯éœ€è¦çŸ¥é“"ä¸‹ä¸€ä¸ª"æ—¶é—´æ­¥
            # è¿™å¸®åŠ©æ¨¡å‹ç†è§£æ—¶é—´æµçš„æ–¹å‘
            #
            # æœ€åä¸€æ­¥ç‰¹æ®Šå¤„ç†ï¼šä¸‹ä¸€æ­¥æ˜¯ t=0ï¼ˆå®Œå…¨æ¸…æ™°ï¼‰
            
            if use_meanflow:
                if i == len(timesteps) - 1:
                    # æœ€åä¸€æ­¥ï¼šç›®æ ‡æ˜¯ t=0
                    timesteps_r = torch.tensor([0.0], device=device)
                else:
                    # å…¶ä»–æ­¥ï¼šä½¿ç”¨ä¸‹ä¸€ä¸ª timestep
                    timesteps_r = timesteps[i + 1]
                timesteps_r = timesteps_r.repeat(latent_model_input.shape[0])
            else:
                timesteps_r = None
            
            # ================================================================
            # æ­¥éª¤ 3: Embedded Guidance
            # ================================================================
            #
            # æŸäº›æ¨¡å‹æ”¯æŒ "embedded guidance"ï¼š
            # - å°† guidance scale ä½œä¸ºè¾“å…¥ä¼ ç»™æ¨¡å‹
            # - è®©æ¨¡å‹å†…éƒ¨å¤„ç† CFG
            #
            # HunyuanVideo-1.5 ç›®å‰ä¸ä½¿ç”¨æ­¤åŠŸèƒ½
            guidance_expand = None
            
            # ================================================================
            # æ­¥éª¤ 4: Transformer å‰å‘ä¼ æ’­
            # ================================================================
            #
            # ã€è¾“å…¥å‚æ•°è¯¦è§£ã€‘
            #
            # latent_model_input: è¾“å…¥ latents
            #   - shape: (B, 33, T, H, W) æˆ– CFG æ—¶ (2B, 33, T, H, W)
            #   - åŒ…å«ä¸» latents (16é€šé“) + æ¡ä»¶ latents (17é€šé“)
            #
            # t_expand: æ—¶é—´æ­¥
            #   - shape: (B,) æˆ– (2B,)
            #   - å½“å‰æ‰©æ•£æ—¶é—´æ­¥
            #
            # prompt_embeds: æ–‡æœ¬åµŒå…¥ï¼ˆä¸»ï¼‰
            #   - shape: (B, seq_len, hidden_dim) æˆ– CFG æ—¶ (2B, ...)
            #   - æ¥è‡ª LLaVA çš„æ–‡æœ¬ç†è§£
            #
            # prompt_embeds_2: æ–‡æœ¬åµŒå…¥ï¼ˆè¾…åŠ©ï¼‰
            #   - å¯¹äº 720p_t2v ä¸º None
            #   - å…¶ä»–ç‰ˆæœ¬å¯èƒ½ä½¿ç”¨ CLIP
            #
            # prompt_mask: æ³¨æ„åŠ› mask
            #   - æŒ‡ç¤ºå“ªäº› token æ˜¯çœŸå®çš„ï¼ˆé paddingï¼‰
            #
            # timestep_r: ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼ˆMeanflowï¼‰
            #
            # vision_states: è§†è§‰ç‰¹å¾
            #   - t2v æ—¶ä¸ºé›¶å‘é‡
            #   - i2v æ—¶ä¸ºå›¾åƒ CLIP ç‰¹å¾
            #
            # mask_type: ä»»åŠ¡ç±»å‹æ ‡è¯†
            #
            # guidance: embedded guidanceï¼ˆæœªä½¿ç”¨ï¼‰
            #
            # extra_kwargs: é¢å¤–å‚æ•°
            #   - åŒ…å« ByT5 embeddings
            #
            # ã€è¾“å‡ºã€‘
            #
            # output[0]: noise prediction
            #   - shape: (B, 16, T, H, W) æˆ– (2B, ...)
            #   - é¢„æµ‹çš„å™ªå£°/æµå‘é‡
            
            with torch.autocast(device_type="cuda", dtype=target_dtype, enabled=True):
                output = transformer(
                    latent_model_input,   # è¾“å…¥ latents
                    t_expand,             # æ—¶é—´æ­¥
                    prompt_embeds,        # LLM æ–‡æœ¬åµŒå…¥
                    prompt_embeds_2,      # è¾…åŠ©æ–‡æœ¬åµŒå…¥ (None for 720p_t2v)
                    prompt_mask,          # æ³¨æ„åŠ› mask
                    timestep_r=timesteps_r,        # Meanflow æ—¶é—´æ­¥
                    vision_states=vision_states,   # è§†è§‰ç‰¹å¾
                    mask_type=task_type,           # ä»»åŠ¡ç±»å‹
                    guidance=guidance_expand,      # Embedded guidance (None)
                    return_dict=False,             # è¿”å›å…ƒç»„è€Œéå­—å…¸
                    extra_kwargs=extra_kwargs,     # ByT5 ç­‰é¢å¤–å‚æ•°
                )
                noise_pred = output[0]
            
            # ================================================================
            # æ­¥éª¤ 5: åº”ç”¨ CFG (Classifier-Free Guidance)
            # ================================================================
            #
            # CFG å…¬å¼:
            #   output = uncond + scale Ã— (cond - uncond)
            #
            # ç›´è§‰è§£é‡Š:
            # - uncond: æ¨¡å‹"è‡ªç”±å‘æŒ¥"çš„é¢„æµ‹
            # - cond: æ¨¡å‹"éµå¾ªæç¤ºè¯"çš„é¢„æµ‹
            # - (cond - uncond): æç¤ºè¯å¸¦æ¥çš„"æ–¹å‘"
            # - scale: æ”¾å¤§è¿™ä¸ªæ–¹å‘
            #
            # æ•ˆæœ:
            # - scale = 1.0: ç­‰äºæ™®é€šæ¡ä»¶ç”Ÿæˆ
            # - scale = 7.0: æ›´å¼ºè°ƒæç¤ºè¯
            # - scale > 15: å¯èƒ½è¿‡åº¦ï¼Œäº§ç”Ÿä¼ªå½±
            
            if do_classifier_free_guidance:
                # åˆ†ç¦»æ— æ¡ä»¶å’Œæœ‰æ¡ä»¶çš„é¢„æµ‹
                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
                # åº”ç”¨ CFG å…¬å¼
                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)
            
            # ================================================================
            # æ­¥éª¤ 6: Scheduler æ›´æ–° Latents
            # ================================================================
            #
            # ã€scheduler.step() åšäº†ä»€ä¹ˆï¼Ÿã€‘
            #
            # ä½¿ç”¨é¢„æµ‹çš„å™ªå£°/æµæ¥æ›´æ–° latentsï¼š
            #
            # å¯¹äº Flow Matching (Euler solver):
            #   z_{t-1} = z_t + Î”t Ã— flow_prediction
            #
            # å…¶ä¸­:
            # - z_t: å½“å‰ latents
            # - Î”t: æ—¶é—´æ­¥é•¿
            # - flow_prediction: æ¨¡å‹é¢„æµ‹çš„"æµ"æ–¹å‘
            #
            # è¿”å›å€¼:
            # - [0]: æ›´æ–°åçš„ latents
            # - [1]: å¯é€‰çš„å…¶ä»–ä¿¡æ¯ï¼ˆæˆ‘ä»¬ä¸ä½¿ç”¨ï¼‰
            
            latents = scheduler.step(noise_pred, t, latents, generator=generator, return_dict=False)[0]
    
    # è®°å½•æ¨ç†æ—¶é—´
    elapsed = time.perf_counter() - start_time
    print_rank0(f"\nâœ“ Transformer æ¨ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f} ç§’")
    print_rank0(f"  Latents shape: {latents.shape}")
    print_rank0(f"  Latents dtype: {latents.dtype}")
    
    # ========================================================================
    # ğŸ’¾ ä¿å­˜è¾“å‡º
    # ========================================================================
    #
    # åªæœ‰ rank 0 ä¿å­˜æ–‡ä»¶ï¼ˆé¿å…å¤šè¿›ç¨‹å†™å…¥å†²çªï¼‰
    #
    # è¾“å‡ºå†…å®¹:
    # 1. latents.safetensors: å»å™ªåçš„ latents
    # 2. config.json: æ›´æ–°çš„ç”Ÿæˆé…ç½®
    # ========================================================================
    
    if get_rank() == 0:
        print_rank0(f"\nä¿å­˜ latents åˆ°: {output_paths['latents']}")
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            'height': str(height),
            'width': str(width),
            'video_length': str(video_length),
            'num_inference_steps': str(args.num_inference_steps),
            'guidance_scale': str(guidance_scale),
            'seed': str(seed),
            'elapsed_time': str(elapsed),
        }
        
        # ä¿å­˜ latents
        save_latents_to_safetensors(latents.cpu(), output_paths['latents'], metadata)
        
        # æ›´æ–°å¹¶ä¿å­˜é…ç½®
        config['height'] = height
        config['width'] = width
        config['stage2_elapsed_time'] = elapsed
        save_generation_config(config, output_paths['config'])
        
        print_rank0(f"\n{'='*60}")
        print_rank0("Stage 2 å®Œæˆï¼")
        print_rank0(f"{'='*60}")
        print_rank0(f"è¾“å‡º: {output_paths['latents']}")
        print_rank0(f"ä¸‹ä¸€æ­¥: è¿è¡Œ stage3_vae_decoder.py")
    
    # ========================================================================
    # ğŸ§¹ æ¸…ç†èµ„æº
    # ========================================================================
    
    del transformer
    torch.cuda.empty_cache()
    
    print_rank0("\nâœ“ Stage 2 æ‰§è¡Œå®Œæˆ")


# ============================================================================
# ğŸ“š é™„å½•ï¼šå…³é”®æ¦‚å¿µæ·±å…¥è§£é‡Š
# ============================================================================
#
# ã€A. æ‰©æ•£æ¨¡å‹ (Diffusion Model) åŸºç¡€ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³æ˜¯å­¦ä¹ é€†è½¬"åŠ å™ª"è¿‡ç¨‹ï¼š
#
# å‰å‘è¿‡ç¨‹ï¼ˆè®­ç»ƒæ—¶ï¼‰:
#   x_0 â†’ x_1 â†’ x_2 â†’ ... â†’ x_T
#   æ¸…æ™°     é€æ¸åŠ å™ª        çº¯å™ªå£°
#
# é€†å‘è¿‡ç¨‹ï¼ˆæ¨ç†æ—¶ï¼‰:
#   x_T â†’ x_{T-1} â†’ ... â†’ x_1 â†’ x_0
#   çº¯å™ªå£°   é€æ¸å»å™ª        æ¸…æ™°
#
# æ¨¡å‹å­¦ä¹ çš„æ˜¯ï¼šç»™å®šå½“å‰çŠ¶æ€ x_t å’Œæ—¶é—´ tï¼Œé¢„æµ‹ä¸‹ä¸€æ­¥åº”è¯¥å‡å»å¤šå°‘å™ªå£°ã€‚
#
#
# ã€B. Flow Matching vs DDPMã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# ä¼ ç»Ÿ DDPM:
#   - é¢„æµ‹æ¯ä¸€æ­¥æ·»åŠ çš„å™ªå£° Îµ
#   - x_{t-1} = (x_t - Î²_t Ã— Îµ) / âˆš(1-Î²_t) + å™ªå£°
#   - æ•°å­¦è¾ƒå¤æ‚
#
# Flow Matching:
#   - ç›´æ¥å­¦ä¹ ä» x_T åˆ° x_0 çš„"æµ"ï¼ˆvelocity fieldï¼‰
#   - x_{t-Î”t} = x_t + Î”t Ã— v(x_t, t)
#   - æ›´ç®€æ´ï¼Œå¯ä»¥ç”¨ç®€å•çš„ ODE æ±‚è§£å™¨
#
# HunyuanVideo ä½¿ç”¨ Flow Matchingï¼Œå› æ­¤ scheduler æ˜¯ FlowMatchDiscreteSchedulerã€‚
#
#
# ã€C. ä¸ºä»€ä¹ˆä½¿ç”¨ Transformer è€Œä¸æ˜¯ U-Netï¼Ÿã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# ä¼ ç»Ÿå›¾åƒæ‰©æ•£ï¼ˆå¦‚ Stable Diffusionï¼‰ä½¿ç”¨ U-Netï¼š
#   - ä¼˜ç‚¹ï¼šå¼ºå¤§çš„å¤šå°ºåº¦ç‰¹å¾æå–
#   - ç¼ºç‚¹ï¼šéš¾ä»¥æ‰©å±•ï¼Œé•¿è·ç¦»ä¾èµ–æœ‰é™
#
# DiT (Diffusion Transformer):
#   - ä¼˜ç‚¹ï¼š
#     * å…¨å±€æ³¨æ„åŠ›ï¼Œæ— è§†è·ç¦»
#     * æ›´å¥½çš„å¯æ‰©å±•æ€§
#     * ä¸ LLM æŠ€æœ¯æ ˆä¸€è‡´
#   - ç¼ºç‚¹ï¼š
#     * è®¡ç®—é‡å¤§
#     * éœ€è¦æ›´å¤šæ˜¾å­˜
#
# å¯¹äºè§†é¢‘ç”Ÿæˆï¼ŒTransformer çš„å…¨å±€æ³¨æ„åŠ›ç‰¹åˆ«é‡è¦ï¼š
#   - å¯ä»¥å»ºæ¨¡è·¨å¸§çš„æ—¶é—´ä¾èµ–
#   - ç¡®ä¿è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§
#
#
# ã€D. Sequence Parallelism (SP) è¯¦è§£ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# å½“è§†é¢‘å¤ªé•¿/åˆ†è¾¨ç‡å¤ªé«˜æ—¶ï¼Œå•å¡æ”¾ä¸ä¸‹ã€‚SP è§£å†³æ–¹æ¡ˆï¼š
#
#   è§†é¢‘åºåˆ—: [å¸§1, å¸§2, å¸§3, å¸§4, å¸§5, å¸§6, å¸§7, å¸§8]
#              â”œâ”€â”€â”€â”€GPU 0â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€GPU 1â”€â”€â”€â”€â”¤
#
# å·¥ä½œæµç¨‹ï¼š
# 1. æ¯ä¸ª GPU åªå¤„ç†éƒ¨åˆ†å¸§
# 2. è‡ªæ³¨æ„åŠ›è®¡ç®—æ—¶ï¼Œé€šè¿‡é€šä¿¡å…±äº« KV
# 3. æœ€åæ”¶é›†ç»“æœ
#
# å¥½å¤„ï¼š
# - å¯ä»¥ç”Ÿæˆæ›´é•¿çš„è§†é¢‘
# - å¯ä»¥ä½¿ç”¨æ›´é«˜çš„åˆ†è¾¨ç‡
# - å¤šå¡å¹¶è¡ŒåŠ é€Ÿ
#
#
# ã€E. ä¸ºä»€ä¹ˆ Latent æ˜¯ 5D å¼ é‡ï¼Ÿã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# è§†é¢‘ latent shape: (B, C, T, H, W)
#
# - B (Batch): æ‰¹æ¬¡å¤§å°ï¼Œé€šå¸¸ä¸º 1
# - C (Channels): æ½œåœ¨é€šé“æ•°ï¼Œ16
# - T (Time/Frames): æ—¶é—´ç»´åº¦ï¼ˆå¸§æ•°ï¼‰
# - H (Height): ç©ºé—´é«˜åº¦
# - W (Width): ç©ºé—´å®½åº¦
#
# ç›¸æ¯”å›¾åƒ (B, C, H, W)ï¼Œå¤šäº†æ—¶é—´ç»´åº¦ Tã€‚
#
# Transformer å†…éƒ¨ä¼šå°† (T, H, W) å±•å¹³ä¸º token åºåˆ—ï¼š
#   tokens = T Ã— H Ã— W
#   ä¾‹å¦‚: 13 Ã— 45 Ã— 80 = 46,800 tokens
#
#
# ã€F. ByT5 çš„ä½œç”¨ã€‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# HunyuanVideo-1.5 ä½¿ç”¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼š
#
# 1. LLaVA (ä¸»):
#    - å¤§å‹è¯­è¨€æ¨¡å‹
#    - ç†è§£è¯­ä¹‰å«ä¹‰
#    - "ä¸€åªçŒ«åœ¨èŠ±å›­é‡Œ" â†’ ç†è§£åœºæ™¯
#
# 2. ByT5 (è¾…åŠ©):
#    - å­—èŠ‚çº§æ–‡æœ¬ç¼–ç å™¨
#    - æ•æ‰å­—ç¬¦çº§ç»†èŠ‚
#    - å¯¹æ‹¼å†™ã€æ ¼å¼æ•æ„Ÿ
#    - å¸®åŠ©ç”Ÿæˆå‡†ç¡®çš„æ–‡å­—/ç¬¦å·
#
# ä¸¤è€…ç»“åˆå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œå¤æ‚çš„æç¤ºè¯ã€‚
#
# ============================================================================

if __name__ == "__main__":
    main()