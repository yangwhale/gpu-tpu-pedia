============================================================
TPU版本图像处理测试 - 运行5次以观察tracing和缓存效果
============================================================
JAX配置完成
检测到 8 个TPU设备

目的：
1. 测试torch下常规的tensor数学和逻辑计算（crop_based_on_mask_torch方法中体现）
2. 测试TorchVision的图像处理算法（resize和gaussian_blur方法中体现）
3. 所有计算在TPU上执行
4. 第1次运行包含代码tracing时间，后续运行使用缓存


============================================================
第 1 次运行
============================================================

--- 预处理阶段 ---
开始在TPU上执行crop操作...
TPU crop time: 0.3345 秒
开始在TPU上执行resize操作...
TPU resize time: 0.3411 秒

--- 后处理阶段 ---
开始在TPU上执行gaussian_blur操作...
TPU gaussian_blur time: 0.1864 秒

第 1 次运行总耗时: 0.9724 秒
(包含代码tracing和编译缓存扫描时间)

============================================================
第 2 次运行
============================================================

--- 预处理阶段 ---
开始在TPU上执行crop操作...
TPU crop time: 0.0153 秒
开始在TPU上执行resize操作...
TPU resize time: 0.0432 秒

--- 后处理阶段 ---
开始在TPU上执行gaussian_blur操作...
TPU gaussian_blur time: 0.0135 秒

第 2 次运行总耗时: 0.1498 秒
(使用缓存，无需重新tracing)

============================================================
第 3 次运行
============================================================

--- 预处理阶段 ---
开始在TPU上执行crop操作...
TPU crop time: 0.0160 秒
开始在TPU上执行resize操作...
TPU resize time: 0.0438 秒

--- 后处理阶段 ---
开始在TPU上执行gaussian_blur操作...
TPU gaussian_blur time: 0.0134 秒

第 3 次运行总耗时: 0.1430 秒
(使用缓存，无需重新tracing)

============================================================
第 4 次运行
============================================================

--- 预处理阶段 ---
开始在TPU上执行crop操作...
TPU crop time: 0.0149 秒
开始在TPU上执行resize操作...
TPU resize time: 0.0430 秒

--- 后处理阶段 ---
开始在TPU上执行gaussian_blur操作...
TPU gaussian_blur time: 0.0133 秒

第 4 次运行总耗时: 0.1413 秒
(使用缓存，无需重新tracing)

============================================================
第 5 次运行
============================================================

--- 预处理阶段 ---
开始在TPU上执行crop操作...
TPU crop time: 0.0145 秒
开始在TPU上执行resize操作...
TPU resize time: 0.0430 秒

--- 后处理阶段 ---
开始在TPU上执行gaussian_blur操作...
TPU gaussian_blur time: 0.0131 秒

第 5 次运行总耗时: 0.1394 秒
(使用缓存，无需重新tracing)

============================================================
性能总结
============================================================

各次运行时间：
  第 1 次: 0.9724 秒
  第 2 次: 0.1498 秒
  第 3 次: 0.1430 秒
  第 4 次: 0.1413 秒
  第 5 次: 0.1394 秒

第1次运行（含tracing）: 0.9724 秒
后续运行平均时间: 0.1433 秒
加速比: 6.78x

说明：
- 第1次运行包含PyTorch代码tracing和编译缓存扫描
- 后续运行直接使用缓存的编译结果，速度更快

============================================================
测试完成
============================================================
